#!/usr/bin/env python3
"""
ä¸´æ—¶æ–‡ä»¶æ¸…ç†è„šæœ¬

æ¸…ç†HIkyuu-UIé¡¹ç›®ä¸­çš„ä¸´æ—¶æ–‡ä»¶å’Œæ— æ•ˆæ–‡ä»¶
"""

import os
import logging
from pathlib import Path
from typing import List

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')
logger = logging.getLogger(__name__)

project_root = Path(__file__).parent


def cleanup_temp_files():
    """æ¸…ç†ä¸´æ—¶æ–‡ä»¶"""
    logger.info("å¼€å§‹æ¸…ç†ä¸´æ—¶æ–‡ä»¶...")

    # å®šä¹‰éœ€è¦æ¸…ç†çš„ä¸´æ—¶æ–‡ä»¶å’Œç›®å½•
    temp_patterns = [
        # Pythonç¼“å­˜æ–‡ä»¶
        '**/__pycache__',
        '**/*.pyc',
        '**/*.pyo',
        '**/*.pyd',

        # ç³»ç»Ÿä¸´æ—¶æ–‡ä»¶
        '**/.DS_Store',
        '**/Thumbs.db',
        '**/*.tmp',
        '**/*.temp',

        # ç¼–è¾‘å™¨ä¸´æ—¶æ–‡ä»¶
        '**/*~',
        '**/*.swp',
        '**/*.swo',
        '**/.vscode/settings.json',

        # æ—¥å¿—æ–‡ä»¶
        '**/logs/*.log',
        '**/*.log',

        # æµ‹è¯•æ–‡ä»¶
        '**/.pytest_cache',
        '**/test_*.py.bak',

        # å¤§å‹åˆ†ææŠ¥å‘Šï¼ˆä¿ç•™æœ€æ–°çš„ï¼‰
        'SYSTEM_ANALYSIS_REPORT.json',  # å¤ªå¤§ï¼Œå¯ä»¥åˆ é™¤
        'REGRESSION_VALIDATION_REPORT.json'  # å¯ä»¥åˆ é™¤ï¼Œå·²æœ‰æœ€ç»ˆæŠ¥å‘Š
    ]

    # ç‰¹å®šçš„ä¸´æ—¶æµ‹è¯•æ–‡ä»¶
    specific_temp_files = [
        'test_model_types_validation.py',
        'test_model_types_simple.py',
        'test_config_only.py',
        'test_model_accuracy_validation.py',
        'test_model_standalone_validation.py',
        'test_enhanced_model_validation.py',
        'test_config_integration.py',
        'professional_ai_trading_validation.py',
        'regression_validation.py'  # ä¿ç•™final_validation.py
    ]

    deleted_files = []
    deleted_dirs = []

    # æ¸…ç†æ¨¡å¼åŒ¹é…çš„æ–‡ä»¶
    for pattern in temp_patterns:
        for path in project_root.glob(pattern):
            try:
                if path.is_file():
                    path.unlink()
                    deleted_files.append(str(path.relative_to(project_root)))
                    logger.info(f"åˆ é™¤æ–‡ä»¶: {path.relative_to(project_root)}")
                elif path.is_dir() and path.name == '__pycache__':
                    import shutil
                    shutil.rmtree(path)
                    deleted_dirs.append(str(path.relative_to(project_root)))
                    logger.info(f"åˆ é™¤ç›®å½•: {path.relative_to(project_root)}")
            except Exception as e:
                logger.warning(f"åˆ é™¤å¤±è´¥ {path}: {e}")

    # æ¸…ç†ç‰¹å®šä¸´æ—¶æ–‡ä»¶
    for file_name in specific_temp_files:
        file_path = project_root / file_name
        if file_path.exists():
            try:
                file_path.unlink()
                deleted_files.append(file_name)
                logger.info(f"åˆ é™¤ä¸´æ—¶æ–‡ä»¶: {file_name}")
            except Exception as e:
                logger.warning(f"åˆ é™¤å¤±è´¥ {file_name}: {e}")

    return deleted_files, deleted_dirs


def cleanup_duplicate_reports():
    """æ¸…ç†é‡å¤çš„æŠ¥å‘Šæ–‡ä»¶ï¼Œä¿ç•™æœ€æ–°çš„"""
    logger.info("æ¸…ç†é‡å¤æŠ¥å‘Šæ–‡ä»¶...")

    # ä¿ç•™æœ€é‡è¦çš„æŠ¥å‘Šï¼Œåˆ é™¤ä¸­é—´ç‰ˆæœ¬
    reports_to_keep = [
        'æœ€ç»ˆä¿®å¤æ€»ç»“æŠ¥å‘Š.md',
        'FINAL_VALIDATION_REPORT.json',
        'PERFORMANCE_OPTIMIZATION_GUIDE.md',
        'å‰©ä½™é…ç½®æ¨¡å—ä¼˜åŒ–åˆ†ææŠ¥å‘Š.md'
    ]

    reports_to_remove = [
        'ç³»ç»ŸåŠŸèƒ½ä¿®å¤æ€»ç»“æŠ¥å‘Š.md'  # å·²æœ‰æœ€ç»ˆç‰ˆæœ¬
    ]

    deleted_reports = []

    for report_name in reports_to_remove:
        report_path = project_root / report_name
        if report_path.exists():
            try:
                report_path.unlink()
                deleted_reports.append(report_name)
                logger.info(f"åˆ é™¤é‡å¤æŠ¥å‘Š: {report_name}")
            except Exception as e:
                logger.warning(f"åˆ é™¤å¤±è´¥ {report_name}: {e}")

    return deleted_reports


def cleanup_old_backups():
    """æ¸…ç†æ—§çš„å¤‡ä»½æ–‡ä»¶"""
    logger.info("æ¸…ç†æ—§å¤‡ä»½æ–‡ä»¶...")

    backup_patterns = [
        '**/*.bak',
        '**/*.backup',
        '**/*_backup.py',
        '**/backup_*',
        # æ¸…ç†å·²çŸ¥çš„å¤‡ä»½ç›®å½•ä¸­çš„æ—§æ–‡ä»¶ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    ]

    deleted_backups = []

    for pattern in backup_patterns:
        for path in project_root.glob(pattern):
            if path.is_file():
                try:
                    path.unlink()
                    deleted_backups.append(str(path.relative_to(project_root)))
                    logger.info(f"åˆ é™¤å¤‡ä»½æ–‡ä»¶: {path.relative_to(project_root)}")
                except Exception as e:
                    logger.warning(f"åˆ é™¤å¤±è´¥ {path}: {e}")

    return deleted_backups


def get_project_size():
    """è·å–é¡¹ç›®å¤§å°"""
    total_size = 0
    file_count = 0

    for path in project_root.rglob('*'):
        if path.is_file():
            try:
                size = path.stat().st_size
                total_size += size
                file_count += 1
            except:
                pass

    return total_size, file_count


def format_size(size_bytes):
    """æ ¼å¼åŒ–æ–‡ä»¶å¤§å°"""
    if size_bytes < 1024:
        return f"{size_bytes} B"
    elif size_bytes < 1024 * 1024:
        return f"{size_bytes / 1024:.1f} KB"
    elif size_bytes < 1024 * 1024 * 1024:
        return f"{size_bytes / (1024 * 1024):.1f} MB"
    else:
        return f"{size_bytes / (1024 * 1024 * 1024):.1f} GB"


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ§¹ HIkyuu-UI ä¸´æ—¶æ–‡ä»¶æ¸…ç†å·¥å…·")
    print("=" * 50)

    # è·å–æ¸…ç†å‰çš„é¡¹ç›®å¤§å°
    size_before, files_before = get_project_size()
    logger.info(f"æ¸…ç†å‰: {files_before} ä¸ªæ–‡ä»¶, æ€»å¤§å°: {format_size(size_before)}")

    # æ‰§è¡Œæ¸…ç†
    deleted_files, deleted_dirs = cleanup_temp_files()
    deleted_reports = cleanup_duplicate_reports()
    deleted_backups = cleanup_old_backups()

    # è·å–æ¸…ç†åçš„é¡¹ç›®å¤§å°
    size_after, files_after = get_project_size()
    size_saved = size_before - size_after
    files_deleted = files_before - files_after

    # æ˜¾ç¤ºæ¸…ç†ç»“æœ
    print(f"\nğŸ“Š æ¸…ç†ç»“æœç»Ÿè®¡:")
    print(f"   åˆ é™¤æ–‡ä»¶: {len(deleted_files)} ä¸ª")
    print(f"   åˆ é™¤ç›®å½•: {len(deleted_dirs)} ä¸ª")
    print(f"   åˆ é™¤æŠ¥å‘Š: {len(deleted_reports)} ä¸ª")
    print(f"   åˆ é™¤å¤‡ä»½: {len(deleted_backups)} ä¸ª")
    print(f"   æ€»åˆ é™¤: {files_deleted} ä¸ªæ–‡ä»¶")
    print(f"   èŠ‚çœç©ºé—´: {format_size(size_saved)}")

    print(f"\nğŸ“ˆ é¡¹ç›®çŠ¶æ€:")
    print(f"   æ¸…ç†å‰: {files_before} ä¸ªæ–‡ä»¶, {format_size(size_before)}")
    print(f"   æ¸…ç†å: {files_after} ä¸ªæ–‡ä»¶, {format_size(size_after)}")

    # æ˜¾ç¤ºä¿ç•™çš„é‡è¦æ–‡ä»¶
    important_files = [
        'db/models/ai_config_models.py',
        'gui/widgets/analysis_tabs/pattern_tab_pro.py',
        'system_code_chain_analysis.py',
        'fix_syntax_errors.py',
        'enhance_config_modules.py',
        'final_validation.py',
        'æœ€ç»ˆä¿®å¤æ€»ç»“æŠ¥å‘Š.md',
        'FINAL_VALIDATION_REPORT.json',
        'PERFORMANCE_OPTIMIZATION_GUIDE.md'
    ]

    print(f"\nğŸ“‹ ä¿ç•™çš„é‡è¦æ–‡ä»¶:")
    for file_path in important_files:
        if (project_root / file_path).exists():
            print(f"   âœ… {file_path}")
        else:
            print(f"   âŒ {file_path}")

    print(f"\nâœ… æ¸…ç†å®Œæˆ!")
    logger.info("ä¸´æ—¶æ–‡ä»¶æ¸…ç†å®Œæˆ")


if __name__ == "__main__":
    main()
