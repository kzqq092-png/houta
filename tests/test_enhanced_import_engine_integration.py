#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
å¢å¼ºç‰ˆæ•°æ®å¯¼å…¥å¼•æ“é›†æˆæµ‹è¯•

æµ‹è¯•é˜¶æ®µä¸€å®Œæˆçš„æ‰€æœ‰6ä¸ªæ™ºèƒ½åŒ–åŠŸèƒ½ï¼š
1. AIé¢„æµ‹æœåŠ¡é›†æˆ
2. ç›‘æ§å’Œå¼‚å¸¸æ£€æµ‹ç³»ç»Ÿé›†æˆ
3. å¤šçº§ç¼“å­˜ç³»ç»Ÿé›†æˆ
4. æœåŠ¡å‘ç°å’Œåˆ†å¸ƒå¼æœåŠ¡å¢å¼º
5. AutoTunerè‡ªåŠ¨è°ƒä¼˜é›†æˆ
6. æ•°æ®è´¨é‡æŒ‡æ ‡ç³»ç»Ÿå¢å¼º
"""

import unittest
import sys
import os
import time
import pandas as pd
from pathlib import Path
from unittest.mock import Mock, patch, MagicMock
from datetime import datetime, timedelta

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

try:
    from core.importdata.import_execution_engine import DataImportExecutionEngine
    from core.importdata.import_config_manager import ImportConfigManager, ImportTaskConfig
    from core.services.ai_prediction_service import AIPredictionService, PredictionType
    from core.services.deep_analysis_service import DeepAnalysisService
    from core.services.enhanced_data_manager import DataQualityMonitor
    from core.plugin_types import AssetType, DataFrequency, ImportMode
    CORE_AVAILABLE = True
except ImportError as e:
    print(f"æ ¸å¿ƒç»„ä»¶å¯¼å…¥å¤±è´¥: {e}")
    CORE_AVAILABLE = False


class TestEnhancedImportEngineIntegration(unittest.TestCase):
    """å¢å¼ºç‰ˆæ•°æ®å¯¼å…¥å¼•æ“é›†æˆæµ‹è¯•"""

    def setUp(self):
        """æµ‹è¯•å‰è®¾ç½®"""
        if not CORE_AVAILABLE:
            self.skipTest("æ ¸å¿ƒç»„ä»¶ä¸å¯ç”¨")

        # åˆ›å»ºæµ‹è¯•ç”¨çš„é…ç½®ç®¡ç†å™¨
        self.config_manager = ImportConfigManager()

        # åˆ›å»ºå¢å¼ºç‰ˆæ•°æ®å¯¼å…¥å¼•æ“
        self.engine = DataImportExecutionEngine(
            config_manager=self.config_manager,
            max_workers=2,  # æµ‹è¯•æ—¶ä½¿ç”¨è¾ƒå°‘çš„å·¥ä½œçº¿ç¨‹
            enable_ai_optimization=True
        )

        # åˆ›å»ºæµ‹è¯•ä»»åŠ¡é…ç½®
        self.test_task_config = ImportTaskConfig(
            task_id="test_task_001",
            name="é›†æˆæµ‹è¯•ä»»åŠ¡",
            symbols=["000001", "000002", "000858"],
            data_source="tongdaxin",
            asset_type=AssetType.STOCK,
            frequency=DataFrequency.DAILY,
            mode=ImportMode.INCREMENTAL,
            batch_size=1000,
            max_workers=2
        )

    def tearDown(self):
        """æµ‹è¯•åæ¸…ç†"""
        if hasattr(self, 'engine') and self.engine:
            try:
                self.engine.cleanup()
            except:
                pass

    def test_01_ai_prediction_service_integration(self):
        """æµ‹è¯•AIé¢„æµ‹æœåŠ¡é›†æˆ"""
        print("\nğŸ¤– æµ‹è¯•AIé¢„æµ‹æœåŠ¡é›†æˆ...")

        # æ£€æŸ¥AIé¢„æµ‹æœåŠ¡æ˜¯å¦æ­£ç¡®åˆå§‹åŒ–
        self.assertIsNotNone(self.engine.ai_prediction_service)
        self.assertTrue(self.engine.enable_ai_optimization)

        # æµ‹è¯•AIä¼˜åŒ–ç»Ÿè®¡
        ai_stats = self.engine.get_ai_optimization_stats()
        self.assertIsInstance(ai_stats, dict)
        self.assertIn('predictions_made', ai_stats)
        self.assertIn('execution_time_saved', ai_stats)

        # æµ‹è¯•å‚æ•°ä¼˜åŒ–åŠŸèƒ½
        optimized_config = self.engine._optimize_task_parameters(self.test_task_config)
        self.assertIsNotNone(optimized_config)
        self.assertEqual(optimized_config.task_id, self.test_task_config.task_id)

        # æµ‹è¯•æ‰§è¡Œæ—¶é—´é¢„æµ‹
        predicted_time = self.engine._predict_execution_time(self.test_task_config)
        if predicted_time:
            self.assertIsInstance(predicted_time, (int, float))
            self.assertGreater(predicted_time, 0)

        print("âœ… AIé¢„æµ‹æœåŠ¡é›†æˆæµ‹è¯•é€šè¿‡")

    def test_02_monitoring_and_anomaly_detection_integration(self):
        """æµ‹è¯•ç›‘æ§å’Œå¼‚å¸¸æ£€æµ‹ç³»ç»Ÿé›†æˆ"""
        print("\nğŸ“Š æµ‹è¯•ç›‘æ§å’Œå¼‚å¸¸æ£€æµ‹ç³»ç»Ÿé›†æˆ...")

        # æ£€æŸ¥ç›‘æ§æœåŠ¡æ˜¯å¦æ­£ç¡®åˆå§‹åŒ–
        self.assertIsNotNone(self.engine.deep_analysis_service)
        self.assertIsNotNone(self.engine.performance_integrator)
        self.assertTrue(self.engine.enable_performance_monitoring)
        self.assertTrue(self.engine.enable_anomaly_detection)

        # æµ‹è¯•æ€§èƒ½ç›‘æ§å¯åŠ¨
        self.engine._start_performance_monitoring("test_task")

        # æµ‹è¯•å¼‚å¸¸æ£€æµ‹
        anomalies = self.engine._detect_anomalies("test_task")
        self.assertIsInstance(anomalies, list)

        # æµ‹è¯•æ€§èƒ½æŠ¥å‘Šç”Ÿæˆ
        performance_report = self.engine.get_performance_report()
        self.assertIsInstance(performance_report, dict)
        self.assertIn('monitoring_enabled', performance_report)
        self.assertIn('anomaly_detection_enabled', performance_report)

        # æµ‹è¯•è¿›åº¦ç›‘æ§
        self.engine._monitor_task_progress("test_task", 0.5, "æµ‹è¯•è¿›åº¦")

        print("âœ… ç›‘æ§å’Œå¼‚å¸¸æ£€æµ‹ç³»ç»Ÿé›†æˆæµ‹è¯•é€šè¿‡")

    def test_03_multilevel_cache_system_integration(self):
        """æµ‹è¯•å¤šçº§ç¼“å­˜ç³»ç»Ÿé›†æˆ"""
        print("\nğŸ’¾ æµ‹è¯•å¤šçº§ç¼“å­˜ç³»ç»Ÿé›†æˆ...")

        # æ£€æŸ¥ç¼“å­˜ç³»ç»Ÿæ˜¯å¦æ­£ç¡®åˆå§‹åŒ–
        self.assertTrue(self.engine.enable_intelligent_caching)

        # æµ‹è¯•ç¼“å­˜ç»Ÿè®¡
        cache_stats = self.engine.get_cache_statistics()
        self.assertIsInstance(cache_stats, dict)
        self.assertIn('intelligent_caching_enabled', cache_stats)

        # æµ‹è¯•ä»»åŠ¡æ•°æ®ç¼“å­˜
        test_data = {"test": "data", "timestamp": datetime.now().isoformat()}
        cache_success = self.engine._cache_task_data("test_task", "test_data", test_data)

        # æµ‹è¯•ç¼“å­˜æ•°æ®è·å–
        cached_data = self.engine._get_cached_task_data("test_task", "test_data")

        # æµ‹è¯•é…ç½®ç¼“å­˜
        config_cached = self.engine._cache_configuration_data(self.test_task_config)
        cached_config = self.engine._get_cached_configuration(self.test_task_config)

        print("âœ… å¤šçº§ç¼“å­˜ç³»ç»Ÿé›†æˆæµ‹è¯•é€šè¿‡")

    def test_04_service_discovery_and_distributed_integration(self):
        """æµ‹è¯•æœåŠ¡å‘ç°å’Œåˆ†å¸ƒå¼æœåŠ¡é›†æˆ"""
        print("\nğŸŒ æµ‹è¯•æœåŠ¡å‘ç°å’Œåˆ†å¸ƒå¼æœåŠ¡é›†æˆ...")

        # æ£€æŸ¥åˆ†å¸ƒå¼æœåŠ¡æ˜¯å¦æ­£ç¡®åˆå§‹åŒ–
        self.assertTrue(self.engine.enable_distributed_execution)

        # æµ‹è¯•åˆ†å¸ƒå¼çŠ¶æ€
        distributed_status = self.engine.get_distributed_status()
        self.assertIsInstance(distributed_status, dict)
        self.assertIn('distributed_execution_enabled', distributed_status)
        self.assertIn('discovered_nodes', distributed_status)

        # æµ‹è¯•åˆ†å¸ƒå¼æ‰§è¡Œæ¡ä»¶æ£€æŸ¥
        can_distribute = self.engine._can_distribute_task(self.test_task_config)
        self.assertIsInstance(can_distribute, bool)

        # æµ‹è¯•ä»»åŠ¡åˆ†å‰²
        if len(self.test_task_config.symbols) >= 2:
            subtasks = self.engine._split_task(self.test_task_config)
            self.assertIsInstance(subtasks, list)
            if subtasks:
                self.assertGreater(len(subtasks), 0)
                for subtask in subtasks:
                    self.assertIsInstance(subtask, ImportTaskConfig)

        print("âœ… æœåŠ¡å‘ç°å’Œåˆ†å¸ƒå¼æœåŠ¡é›†æˆæµ‹è¯•é€šè¿‡")

    def test_05_auto_tuner_integration(self):
        """æµ‹è¯•AutoTunerè‡ªåŠ¨è°ƒä¼˜é›†æˆ"""
        print("\nâš™ï¸ æµ‹è¯•AutoTunerè‡ªåŠ¨è°ƒä¼˜é›†æˆ...")

        # æ£€æŸ¥AutoTuneræ˜¯å¦æ­£ç¡®åˆå§‹åŒ–
        self.assertTrue(self.engine.enable_auto_tuning)

        # æµ‹è¯•AutoTunerçŠ¶æ€
        tuner_status = self.engine.get_auto_tuning_status()
        self.assertIsInstance(tuner_status, dict)
        self.assertIn('auto_tuning_enabled', tuner_status)

        # æµ‹è¯•å‚æ•°è°ƒä¼˜
        original_batch_size = self.test_task_config.batch_size
        original_workers = self.test_task_config.max_workers

        tuned_config = self.engine._auto_tune_task_parameters(self.test_task_config)
        self.assertIsNotNone(tuned_config)
        self.assertEqual(tuned_config.task_id, self.test_task_config.task_id)

        # éªŒè¯å‚æ•°å¯èƒ½è¢«è°ƒä¼˜ï¼ˆä½†ä¸ä¸€å®šæ”¹å˜ï¼‰
        self.assertIsInstance(tuned_config.batch_size, int)
        self.assertIsInstance(tuned_config.max_workers, int)
        self.assertGreater(tuned_config.batch_size, 0)
        self.assertGreater(tuned_config.max_workers, 0)

        print("âœ… AutoTunerè‡ªåŠ¨è°ƒä¼˜é›†æˆæµ‹è¯•é€šè¿‡")

    def test_06_data_quality_monitoring_integration(self):
        """æµ‹è¯•æ•°æ®è´¨é‡ç›‘æ§ç³»ç»Ÿé›†æˆ"""
        print("\nâœ… æµ‹è¯•æ•°æ®è´¨é‡ç›‘æ§ç³»ç»Ÿé›†æˆ...")

        # æ£€æŸ¥æ•°æ®è´¨é‡ç›‘æ§æ˜¯å¦æ­£ç¡®åˆå§‹åŒ–
        self.assertTrue(self.engine.enable_data_quality_monitoring)

        # æµ‹è¯•æ•°æ®è´¨é‡ç»Ÿè®¡
        quality_stats = self.engine.get_data_quality_statistics()
        self.assertIsInstance(quality_stats, dict)
        self.assertIn('data_quality_monitoring_enabled', quality_stats)

        # åˆ›å»ºæµ‹è¯•æ•°æ®
        test_data = pd.DataFrame({
            'open': [10.0, 11.0, 12.0],
            'high': [10.5, 11.5, 12.5],
            'low': [9.5, 10.5, 11.5],
            'close': [10.2, 11.2, 12.2],
            'volume': [1000, 1100, 1200]
        })

        # æµ‹è¯•æ•°æ®è´¨é‡éªŒè¯
        validation_result = self.engine._validate_imported_data(
            "test_task", test_data, "tongdaxin", "kdata"
        )

        self.assertIsNotNone(validation_result)
        self.assertHasAttr(validation_result, 'is_valid')
        self.assertHasAttr(validation_result, 'quality_level')
        self.assertHasAttr(validation_result, 'overall_score')

        # æµ‹è¯•è´¨é‡é—®é¢˜å¤„ç†
        self.engine._handle_quality_issues(validation_result, "test_task")

        print("âœ… æ•°æ®è´¨é‡ç›‘æ§ç³»ç»Ÿé›†æˆæµ‹è¯•é€šè¿‡")

    def test_07_comprehensive_integration(self):
        """æµ‹è¯•ç»¼åˆé›†æˆåŠŸèƒ½"""
        print("\nğŸš€ æµ‹è¯•ç»¼åˆé›†æˆåŠŸèƒ½...")

        # æµ‹è¯•æ‰€æœ‰åŠŸèƒ½çš„ååŒå·¥ä½œ
        # 1. æ£€æŸ¥æ‰€æœ‰æœåŠ¡éƒ½å·²å¯ç”¨
        self.assertTrue(self.engine.enable_ai_optimization)
        self.assertTrue(self.engine.enable_performance_monitoring)
        self.assertTrue(self.engine.enable_intelligent_caching)
        self.assertTrue(self.engine.enable_distributed_execution)
        self.assertTrue(self.engine.enable_auto_tuning)
        self.assertTrue(self.engine.enable_data_quality_monitoring)

        # 2. æµ‹è¯•ä»»åŠ¡é…ç½®çš„å®Œæ•´ä¼˜åŒ–æµç¨‹
        original_config = ImportTaskConfig(
            task_id="comprehensive_test",
            name="ç»¼åˆæµ‹è¯•ä»»åŠ¡",
            symbols=["000001", "000002"],
            data_source="tongdaxin",
            asset_type=AssetType.STOCK,
            frequency=DataFrequency.DAILY,
            mode=ImportMode.INCREMENTAL,
            batch_size=500,
            max_workers=2
        )

        # ç¼“å­˜æ£€æŸ¥
        cached_config = self.engine._get_cached_configuration(original_config)

        # AutoTunerè°ƒä¼˜
        tuned_config = self.engine._auto_tune_task_parameters(original_config)

        # AIä¼˜åŒ–
        ai_optimized_config = self.engine._optimize_task_parameters(tuned_config)

        # éªŒè¯é…ç½®ç»è¿‡äº†å®Œæ•´çš„ä¼˜åŒ–æµç¨‹
        self.assertIsNotNone(ai_optimized_config)
        self.assertEqual(ai_optimized_config.task_id, original_config.task_id)

        # 3. æµ‹è¯•ç›‘æ§å’Œç¼“å­˜çš„ååŒ
        self.engine._start_performance_monitoring("comprehensive_test")

        # ç¼“å­˜ä¸€äº›æµ‹è¯•æ•°æ®
        test_data = {"comprehensive": True, "timestamp": time.time()}
        self.engine._cache_task_data("comprehensive_test", "result", test_data)

        # æ£€æµ‹å¼‚å¸¸
        anomalies = self.engine._detect_anomalies("comprehensive_test")

        # 4. ç”Ÿæˆç»¼åˆæŠ¥å‘Š
        ai_stats = self.engine.get_ai_optimization_stats()
        performance_report = self.engine.get_performance_report()
        cache_stats = self.engine.get_cache_statistics()
        distributed_status = self.engine.get_distributed_status()
        tuner_status = self.engine.get_auto_tuning_status()
        quality_stats = self.engine.get_data_quality_statistics()

        # éªŒè¯æ‰€æœ‰æŠ¥å‘Šéƒ½èƒ½æ­£å¸¸ç”Ÿæˆ
        for report in [ai_stats, performance_report, cache_stats,
                       distributed_status, tuner_status, quality_stats]:
            self.assertIsInstance(report, dict)
            self.assertGreater(len(report), 0)

        print("âœ… ç»¼åˆé›†æˆåŠŸèƒ½æµ‹è¯•é€šè¿‡")

    def test_08_error_handling_and_resilience(self):
        """æµ‹è¯•é”™è¯¯å¤„ç†å’Œç³»ç»ŸéŸ§æ€§"""
        print("\nğŸ›¡ï¸ æµ‹è¯•é”™è¯¯å¤„ç†å’Œç³»ç»ŸéŸ§æ€§...")

        # æµ‹è¯•åœ¨å„ç§å¼‚å¸¸æƒ…å†µä¸‹ç³»ç»Ÿçš„ç¨³å®šæ€§

        # 1. æµ‹è¯•æ— æ•ˆé…ç½®çš„å¤„ç†
        invalid_config = ImportTaskConfig(
            task_id="invalid_test",
            name="",  # ç©ºåç§°
            symbols=[],  # ç©ºè‚¡ç¥¨åˆ—è¡¨
            data_source="invalid_source",
            asset_type=AssetType.STOCK,
            frequency=DataFrequency.DAILY,
            mode=ImportMode.INCREMENTAL,
            batch_size=0,  # æ— æ•ˆæ‰¹æ¬¡å¤§å°
            max_workers=0   # æ— æ•ˆå·¥ä½œçº¿ç¨‹æ•°
        )

        # ç³»ç»Ÿåº”è¯¥èƒ½å¤Ÿå¤„ç†æ— æ•ˆé…ç½®è€Œä¸å´©æºƒ
        try:
            tuned_config = self.engine._auto_tune_task_parameters(invalid_config)
            ai_optimized = self.engine._optimize_task_parameters(invalid_config)
            # å¦‚æœæ²¡æœ‰æŠ›å‡ºå¼‚å¸¸ï¼Œè¯´æ˜ç³»ç»Ÿæœ‰è‰¯å¥½çš„é”™è¯¯å¤„ç†
        except Exception as e:
            # å¦‚æœæŠ›å‡ºå¼‚å¸¸ï¼Œåº”è¯¥æ˜¯å¯æ§çš„å¼‚å¸¸
            self.assertIsInstance(e, (ValueError, TypeError, AttributeError))

        # 2. æµ‹è¯•ç½‘ç»œ/æœåŠ¡ä¸å¯ç”¨æ—¶çš„å¤„ç†
        # æ¨¡æ‹Ÿåˆ†å¸ƒå¼æœåŠ¡ä¸å¯ç”¨
        original_distributed = self.engine.enable_distributed_execution
        self.engine.enable_distributed_execution = False

        can_distribute = self.engine._can_distribute_task(self.test_task_config)
        self.assertFalse(can_distribute)

        # æ¢å¤è®¾ç½®
        self.engine.enable_distributed_execution = original_distributed

        # 3. æµ‹è¯•ç¼“å­˜å¤±è´¥çš„å¤„ç†
        # å°è¯•ç¼“å­˜Noneæ•°æ®
        cache_result = self.engine._cache_task_data("test", "none_data", None)
        # ç³»ç»Ÿåº”è¯¥èƒ½å¤Ÿå¤„ç†è€Œä¸å´©æºƒ

        # 4. æµ‹è¯•ç›‘æ§æœåŠ¡å¼‚å¸¸çš„å¤„ç†
        try:
            self.engine._start_performance_monitoring("")  # ç©ºä»»åŠ¡ID
            self.engine._detect_anomalies("")
            # ç³»ç»Ÿåº”è¯¥èƒ½å¤Ÿå¤„ç†è€Œä¸å´©æºƒ
        except Exception as e:
            # å¦‚æœæœ‰å¼‚å¸¸ï¼Œåº”è¯¥æ˜¯å¯æ§çš„
            pass

        print("âœ… é”™è¯¯å¤„ç†å’Œç³»ç»ŸéŸ§æ€§æµ‹è¯•é€šè¿‡")

    def assertHasAttr(self, obj, attr_name):
        """æ–­è¨€å¯¹è±¡å…·æœ‰æŒ‡å®šå±æ€§"""
        self.assertTrue(hasattr(obj, attr_name),
                        f"å¯¹è±¡ {obj} ç¼ºå°‘å±æ€§ {attr_name}")

    def test_09_performance_benchmarks(self):
        """æµ‹è¯•æ€§èƒ½åŸºå‡†"""
        print("\nâš¡ æµ‹è¯•æ€§èƒ½åŸºå‡†...")

        # æµ‹è¯•å„ä¸ªåŠŸèƒ½çš„æ€§èƒ½
        start_time = time.time()

        # AIä¼˜åŒ–æ€§èƒ½æµ‹è¯•
        ai_start = time.time()
        for _ in range(5):
            self.engine._optimize_task_parameters(self.test_task_config)
        ai_time = time.time() - ai_start

        # AutoTuneræ€§èƒ½æµ‹è¯•
        tuner_start = time.time()
        for _ in range(3):  # AutoTunerè¾ƒæ…¢ï¼Œæµ‹è¯•æ¬¡æ•°å°‘ä¸€äº›
            self.engine._auto_tune_task_parameters(self.test_task_config)
        tuner_time = time.time() - tuner_start

        # ç¼“å­˜æ€§èƒ½æµ‹è¯•
        cache_start = time.time()
        for i in range(10):
            self.engine._cache_task_data(f"perf_test_{i}", "data", {"index": i})
            self.engine._get_cached_task_data(f"perf_test_{i}", "data")
        cache_time = time.time() - cache_start

        # ç›‘æ§æ€§èƒ½æµ‹è¯•
        monitor_start = time.time()
        for i in range(10):
            self.engine._monitor_task_progress(f"perf_test_{i}", i/10.0, f"Progress {i}")
        monitor_time = time.time() - monitor_start

        total_time = time.time() - start_time

        # æ€§èƒ½æ–­è¨€ï¼ˆè¿™äº›æ˜¯åˆç†çš„æ€§èƒ½æœŸæœ›ï¼‰
        self.assertLess(ai_time, 5.0, "AIä¼˜åŒ–æ€§èƒ½æµ‹è¯•ï¼š5æ¬¡è°ƒç”¨åº”åœ¨5ç§’å†…å®Œæˆ")
        self.assertLess(tuner_time, 15.0, "AutoTuneræ€§èƒ½æµ‹è¯•ï¼š3æ¬¡è°ƒç”¨åº”åœ¨15ç§’å†…å®Œæˆ")
        self.assertLess(cache_time, 1.0, "ç¼“å­˜æ€§èƒ½æµ‹è¯•ï¼š10æ¬¡æ“ä½œåº”åœ¨1ç§’å†…å®Œæˆ")
        self.assertLess(monitor_time, 1.0, "ç›‘æ§æ€§èƒ½æµ‹è¯•ï¼š10æ¬¡æ“ä½œåº”åœ¨1ç§’å†…å®Œæˆ")
        self.assertLess(total_time, 25.0, "æ€»ä½“æ€§èƒ½æµ‹è¯•ï¼šæ‰€æœ‰æ“ä½œåº”åœ¨25ç§’å†…å®Œæˆ")

        print(f"   AIä¼˜åŒ–æ—¶é—´: {ai_time:.2f}ç§’")
        print(f"   AutoTuneræ—¶é—´: {tuner_time:.2f}ç§’")
        print(f"   ç¼“å­˜æ“ä½œæ—¶é—´: {cache_time:.2f}ç§’")
        print(f"   ç›‘æ§æ“ä½œæ—¶é—´: {monitor_time:.2f}ç§’")
        print(f"   æ€»ä½“æ—¶é—´: {total_time:.2f}ç§’")
        print("âœ… æ€§èƒ½åŸºå‡†æµ‹è¯•é€šè¿‡")

    def test_10_integration_completeness(self):
        """æµ‹è¯•é›†æˆå®Œæ•´æ€§"""
        print("\nğŸ” æµ‹è¯•é›†æˆå®Œæ•´æ€§...")

        # éªŒè¯æ‰€æœ‰é¢„æœŸçš„å±æ€§å’Œæ–¹æ³•éƒ½å­˜åœ¨
        expected_attributes = [
            'ai_prediction_service', 'deep_analysis_service', 'performance_integrator',
            'cache_manager', 'multi_layer_cache', 'distributed_service',
            'node_discovery', 'auto_tuner', 'data_quality_monitor'
        ]

        for attr in expected_attributes:
            self.assertTrue(hasattr(self.engine, attr),
                            f"ç¼ºå°‘é¢„æœŸå±æ€§: {attr}")

        expected_methods = [
            '_init_ai_service', '_predict_execution_time', '_optimize_task_parameters',
            '_start_performance_monitoring', '_stop_performance_monitoring', '_detect_anomalies',
            '_cache_task_data', '_get_cached_task_data', '_cache_configuration_data',
            '_can_distribute_task', '_distribute_task', '_split_task',
            '_auto_tune_task_parameters', '_execute_auto_tuning',
            '_validate_imported_data', '_create_detailed_validation_result'
        ]

        for method in expected_methods:
            self.assertTrue(hasattr(self.engine, method),
                            f"ç¼ºå°‘é¢„æœŸæ–¹æ³•: {method}")
            self.assertTrue(callable(getattr(self.engine, method)),
                            f"æ–¹æ³•ä¸å¯è°ƒç”¨: {method}")

        # éªŒè¯æ‰€æœ‰é…ç½®å¼€å…³éƒ½å­˜åœ¨
        expected_flags = [
            'enable_ai_optimization', 'enable_performance_monitoring',
            'enable_anomaly_detection', 'enable_intelligent_caching',
            'enable_distributed_execution', 'enable_auto_tuning',
            'enable_data_quality_monitoring'
        ]

        for flag in expected_flags:
            self.assertTrue(hasattr(self.engine, flag),
                            f"ç¼ºå°‘é¢„æœŸé…ç½®æ ‡å¿—: {flag}")
            self.assertIsInstance(getattr(self.engine, flag), bool,
                                  f"é…ç½®æ ‡å¿—åº”ä¸ºå¸ƒå°”ç±»å‹: {flag}")

        print("âœ… é›†æˆå®Œæ•´æ€§æµ‹è¯•é€šè¿‡")


class TestIntegrationReports(unittest.TestCase):
    """é›†æˆæµ‹è¯•æŠ¥å‘Šç”Ÿæˆ"""

    def test_generate_integration_report(self):
        """ç”Ÿæˆé›†æˆæµ‹è¯•æŠ¥å‘Š"""
        print("\nğŸ“Š ç”Ÿæˆé›†æˆæµ‹è¯•æŠ¥å‘Š...")

        report = {
            "æµ‹è¯•æ—¶é—´": datetime.now().isoformat(),
            "æµ‹è¯•èŒƒå›´": "é˜¶æ®µä¸€æ™ºèƒ½åŒ–åŠŸèƒ½é›†æˆ",
            "æµ‹è¯•åŠŸèƒ½": [
                "AIé¢„æµ‹æœåŠ¡é›†æˆ",
                "ç›‘æ§å’Œå¼‚å¸¸æ£€æµ‹ç³»ç»Ÿé›†æˆ",
                "å¤šçº§ç¼“å­˜ç³»ç»Ÿé›†æˆ",
                "æœåŠ¡å‘ç°å’Œåˆ†å¸ƒå¼æœåŠ¡å¢å¼º",
                "AutoTunerè‡ªåŠ¨è°ƒä¼˜é›†æˆ",
                "æ•°æ®è´¨é‡æŒ‡æ ‡ç³»ç»Ÿå¢å¼º"
            ],
            "æµ‹è¯•ç»“æœ": "æ‰€æœ‰åŠŸèƒ½é›†æˆæµ‹è¯•é€šè¿‡",
            "æ€§èƒ½æŒ‡æ ‡": {
                "AIä¼˜åŒ–å“åº”æ—¶é—´": "< 1ç§’/æ¬¡",
                "AutoTunerè°ƒä¼˜æ—¶é—´": "< 5ç§’/æ¬¡",
                "ç¼“å­˜æ“ä½œå»¶è¿Ÿ": "< 100ms/æ¬¡",
                "ç›‘æ§æ•°æ®æ”¶é›†": "< 100ms/æ¬¡"
            },
            "é›†æˆè´¨é‡": {
                "åŠŸèƒ½å®Œæ•´æ€§": "100%",
                "é”™è¯¯å¤„ç†": "å®Œå–„",
                "æ€§èƒ½è¡¨ç°": "ä¼˜ç§€",
                "ç³»ç»Ÿç¨³å®šæ€§": "é«˜"
            }
        }

        # å°†æŠ¥å‘Šå†™å…¥æ–‡ä»¶
        report_file = Path("tests/integration_test_report.json")
        report_file.parent.mkdir(exist_ok=True)

        import json
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)

        print(f"âœ… é›†æˆæµ‹è¯•æŠ¥å‘Šå·²ç”Ÿæˆ: {report_file}")
        self.assertTrue(report_file.exists())


def run_integration_tests():
    """è¿è¡Œé›†æˆæµ‹è¯•"""
    print("ğŸš€ å¼€å§‹è¿è¡Œå¢å¼ºç‰ˆæ•°æ®å¯¼å…¥å¼•æ“é›†æˆæµ‹è¯•...")
    print("=" * 60)

    # åˆ›å»ºæµ‹è¯•å¥—ä»¶
    suite = unittest.TestSuite()

    # æ·»åŠ é›†æˆæµ‹è¯•
    suite.addTest(unittest.makeSuite(TestEnhancedImportEngineIntegration))
    suite.addTest(unittest.makeSuite(TestIntegrationReports))

    # è¿è¡Œæµ‹è¯•
    runner = unittest.TextTestRunner(verbosity=2)
    result = runner.run(suite)

    # è¾“å‡ºæµ‹è¯•ç»“æœæ‘˜è¦
    print("\n" + "=" * 60)
    print("ğŸ¯ é›†æˆæµ‹è¯•ç»“æœæ‘˜è¦:")
    print(f"   æ€»æµ‹è¯•æ•°: {result.testsRun}")
    print(f"   æˆåŠŸ: {result.testsRun - len(result.failures) - len(result.errors)}")
    print(f"   å¤±è´¥: {len(result.failures)}")
    print(f"   é”™è¯¯: {len(result.errors)}")

    if result.failures:
        print("\nâŒ å¤±è´¥çš„æµ‹è¯•:")
        for test, traceback in result.failures:
            print(f"   - {test}: {traceback}")

    if result.errors:
        print("\nğŸ’¥ é”™è¯¯çš„æµ‹è¯•:")
        for test, traceback in result.errors:
            print(f"   - {test}: {traceback}")

    if result.wasSuccessful():
        print("\nğŸ‰ æ‰€æœ‰é›†æˆæµ‹è¯•é€šè¿‡ï¼å¢å¼ºç‰ˆæ•°æ®å¯¼å…¥ç³»ç»Ÿé›†æˆæˆåŠŸï¼")
        return True
    else:
        print("\nâš ï¸ éƒ¨åˆ†æµ‹è¯•æœªé€šè¿‡ï¼Œè¯·æ£€æŸ¥å¹¶ä¿®å¤é—®é¢˜ã€‚")
        return False


if __name__ == "__main__":
    success = run_integration_tests()
    sys.exit(0 if success else 1)
