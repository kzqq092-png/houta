#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
AIæœåŠ¡é›†æˆä¸“é¡¹æµ‹è¯•

ä¸“é—¨æµ‹è¯•AIé¢„æµ‹æœåŠ¡çš„æ·±åº¦é›†æˆå’Œæœºå™¨å­¦ä¹ åŠŸèƒ½
"""

import unittest
import sys
import os
import numpy as np
import pandas as pd
from pathlib import Path
from unittest.mock import Mock, patch, MagicMock
from datetime import datetime, timedelta

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

try:
    from core.services.ai_prediction_service import AIPredictionService, PredictionType
    from core.importdata.import_config_manager import ImportTaskConfig
    from core.plugin_types import AssetType, DataFrequency, ImportMode
    AI_SERVICES_AVAILABLE = True
except ImportError as e:
    print(f"AIæœåŠ¡ç»„ä»¶å¯¼å…¥å¤±è´¥: {e}")
    AI_SERVICES_AVAILABLE = False


class TestAIPredictionServiceIntegration(unittest.TestCase):
    """AIé¢„æµ‹æœåŠ¡é›†æˆæµ‹è¯•"""

    def setUp(self):
        """æµ‹è¯•å‰è®¾ç½®"""
        if not AI_SERVICES_AVAILABLE:
            self.skipTest("AIæœåŠ¡ç»„ä»¶ä¸å¯ç”¨")

        self.ai_service = AIPredictionService()

        # åˆ›å»ºæµ‹è¯•é…ç½®
        self.test_config = ImportTaskConfig(
            task_id="ai_test_001",
            name="AIæµ‹è¯•ä»»åŠ¡",
            symbols=["000001", "000002", "000858"],
            data_source="tongdaxin",
            asset_type=AssetType.STOCK,
            frequency=DataFrequency.DAILY,
            mode=ImportMode.INCREMENTAL,
            batch_size=1000,
            max_workers=4
        )

        # åˆ›å»ºæ¨¡æ‹Ÿå†å²æ•°æ®
        self.mock_historical_data = self._create_mock_historical_data()

    def _create_mock_historical_data(self):
        """åˆ›å»ºæ¨¡æ‹Ÿå†å²æ‰§è¡Œæ•°æ®"""
        data = []
        base_time = datetime.now() - timedelta(days=30)

        for i in range(50):  # 50æ¡å†å²è®°å½•
            record = {
                'task_id': f'historical_task_{i:03d}',
                'symbols_count': np.random.randint(1, 10),
                'batch_size': np.random.choice([500, 1000, 2000, 5000]),
                'max_workers': np.random.randint(1, 8),
                'data_source': np.random.choice(['tongdaxin', 'akshare', 'tushare']),
                'execution_time': np.random.uniform(10, 300),  # 10ç§’åˆ°5åˆ†é’Ÿ
                'success_rate': np.random.uniform(0.7, 1.0),
                'data_quality_score': np.random.uniform(0.6, 1.0),
                'timestamp': (base_time + timedelta(days=i)).isoformat(),
                'memory_usage': np.random.uniform(100, 1000),  # MB
                'cpu_usage': np.random.uniform(20, 80),  # ç™¾åˆ†æ¯”
                'network_latency': np.random.uniform(10, 100)  # ms
            }
            data.append(record)

        return pd.DataFrame(data)

    def test_01_ai_service_initialization(self):
        """æµ‹è¯•AIæœåŠ¡åˆå§‹åŒ–"""
        print("\nğŸ¤– æµ‹è¯•AIæœåŠ¡åˆå§‹åŒ–...")

        self.assertIsNotNone(self.ai_service)
        self.assertTrue(hasattr(self.ai_service, 'predict'))
        self.assertTrue(hasattr(self.ai_service, 'predict_execution_time'))
        self.assertTrue(hasattr(self.ai_service, 'predict_parameter_optimization'))

        print("âœ… AIæœåŠ¡åˆå§‹åŒ–æµ‹è¯•é€šè¿‡")

    def test_02_execution_time_prediction(self):
        """æµ‹è¯•æ‰§è¡Œæ—¶é—´é¢„æµ‹"""
        print("\nâ±ï¸ æµ‹è¯•æ‰§è¡Œæ—¶é—´é¢„æµ‹...")

        # ä½¿ç”¨ç»Ÿä¸€é¢„æµ‹æ¥å£
        predicted_time = self.ai_service.predict(
            prediction_type=PredictionType.EXECUTION_TIME,
            task_config=self.test_config,
            historical_data=self.mock_historical_data
        )

        if predicted_time is not None:
            self.assertIsInstance(predicted_time, (int, float))
            self.assertGreater(predicted_time, 0)
            self.assertLess(predicted_time, 3600)  # åº”è¯¥åœ¨1å°æ—¶å†…
            print(f"   é¢„æµ‹æ‰§è¡Œæ—¶é—´: {predicted_time:.2f}ç§’")
        else:
            print("   é¢„æµ‹ç»“æœä¸ºç©ºï¼ˆå¯èƒ½æ˜¯å†å²æ•°æ®ä¸è¶³ï¼‰")

        # ç›´æ¥æµ‹è¯•æ‰§è¡Œæ—¶é—´é¢„æµ‹æ–¹æ³•
        direct_prediction = self.ai_service.predict_execution_time(
            self.test_config, self.mock_historical_data
        )

        if direct_prediction is not None:
            self.assertIsInstance(direct_prediction, (int, float))
            self.assertGreater(direct_prediction, 0)

        print("âœ… æ‰§è¡Œæ—¶é—´é¢„æµ‹æµ‹è¯•é€šè¿‡")

    def test_03_parameter_optimization_ml(self):
        """æµ‹è¯•æœºå™¨å­¦ä¹ å‚æ•°ä¼˜åŒ–"""
        print("\nğŸ§  æµ‹è¯•æœºå™¨å­¦ä¹ å‚æ•°ä¼˜åŒ–...")

        # ä½¿ç”¨ç»Ÿä¸€é¢„æµ‹æ¥å£
        optimized_params = self.ai_service.predict(
            prediction_type=PredictionType.PARAMETER_OPTIMIZATION,
            task_config=self.test_config,
            historical_data=self.mock_historical_data
        )

        if optimized_params:
            self.assertIsInstance(optimized_params, dict)
            self.assertIn('batch_size', optimized_params)
            self.assertIn('max_workers', optimized_params)

            # éªŒè¯å‚æ•°èŒƒå›´åˆç†
            batch_size = optimized_params['batch_size']
            max_workers = optimized_params['max_workers']

            self.assertIsInstance(batch_size, int)
            self.assertIsInstance(max_workers, int)
            self.assertGreaterEqual(batch_size, 100)
            self.assertLessEqual(batch_size, 10000)
            self.assertGreaterEqual(max_workers, 1)
            self.assertLessEqual(max_workers, 16)

            print(f"   ä¼˜åŒ–åæ‰¹æ¬¡å¤§å°: {batch_size}")
            print(f"   ä¼˜åŒ–åå·¥ä½œçº¿ç¨‹: {max_workers}")

            if 'confidence' in optimized_params:
                print(f"   ä¼˜åŒ–ç½®ä¿¡åº¦: {optimized_params['confidence']:.2f}")
        else:
            print("   å‚æ•°ä¼˜åŒ–ç»“æœä¸ºç©ºï¼ˆå¯èƒ½æ˜¯å†å²æ•°æ®ä¸è¶³ï¼‰")

        print("âœ… æœºå™¨å­¦ä¹ å‚æ•°ä¼˜åŒ–æµ‹è¯•é€šè¿‡")

    def test_04_parameter_optimization_statistical(self):
        """æµ‹è¯•ç»Ÿè®¡å­¦å‚æ•°ä¼˜åŒ–"""
        print("\nğŸ“Š æµ‹è¯•ç»Ÿè®¡å­¦å‚æ•°ä¼˜åŒ–...")

        # ç›´æ¥æµ‹è¯•å‚æ•°ä¼˜åŒ–æ–¹æ³•
        optimized_params = self.ai_service.predict_parameter_optimization(
            self.test_config, self.mock_historical_data
        )

        if optimized_params:
            self.assertIsInstance(optimized_params, dict)
            self.assertIn('batch_size', optimized_params)
            self.assertIn('max_workers', optimized_params)

            # æµ‹è¯•ç»Ÿè®¡æ–¹æ³•çš„å›é€€æœºåˆ¶
            # é€šè¿‡å‡å°‘å†å²æ•°æ®æ¥è§¦å‘ç»Ÿè®¡æ–¹æ³•
            small_data = self.mock_historical_data.head(5)  # åªç”¨5æ¡è®°å½•

            statistical_params = self.ai_service.predict_parameter_optimization(
                self.test_config, small_data
            )

            if statistical_params:
                self.assertIsInstance(statistical_params, dict)
                print(f"   ç»Ÿè®¡ä¼˜åŒ–æ‰¹æ¬¡å¤§å°: {statistical_params.get('batch_size', 'N/A')}")
                print(f"   ç»Ÿè®¡ä¼˜åŒ–å·¥ä½œçº¿ç¨‹: {statistical_params.get('max_workers', 'N/A')}")

        print("âœ… ç»Ÿè®¡å­¦å‚æ•°ä¼˜åŒ–æµ‹è¯•é€šè¿‡")

    def test_05_ml_model_training_and_prediction(self):
        """æµ‹è¯•æœºå™¨å­¦ä¹ æ¨¡å‹è®­ç»ƒå’Œé¢„æµ‹"""
        print("\nğŸ¯ æµ‹è¯•æœºå™¨å­¦ä¹ æ¨¡å‹è®­ç»ƒå’Œé¢„æµ‹...")

        # æµ‹è¯•MLå‚æ•°ä¼˜åŒ–çš„å†…éƒ¨æ–¹æ³•
        try:
            # å‡†å¤‡ä¼˜åŒ–æ•°æ®
            optimization_data = self.ai_service._prepare_optimization_data(
                self.mock_historical_data
            )

            if optimization_data is not None and len(optimization_data) > 10:
                self.assertIsInstance(optimization_data, pd.DataFrame)

                # æå–ç‰¹å¾
                features = self.ai_service._extract_optimization_features(
                    self.test_config, optimization_data
                )

                self.assertIsInstance(features, dict)
                expected_features = [
                    'symbols_count', 'current_batch_size', 'current_max_workers',
                    'avg_execution_time', 'avg_success_rate'
                ]

                for feature in expected_features:
                    if feature in features:
                        self.assertIsInstance(features[feature], (int, float))

                print(f"   æå–ç‰¹å¾æ•°é‡: {len(features)}")
                print(f"   ç‰¹å¾ç¤ºä¾‹: {list(features.keys())[:5]}")

                # æµ‹è¯•MLä¼˜åŒ–
                ml_result = self.ai_service._ml_parameter_optimization(
                    self.test_config, optimization_data
                )

                if ml_result:
                    self.assertIsInstance(ml_result, dict)
                    print(f"   MLä¼˜åŒ–ç»“æœ: {ml_result}")
            else:
                print("   å†å²æ•°æ®ä¸è¶³ï¼Œè·³è¿‡MLæ¨¡å‹æµ‹è¯•")

        except Exception as e:
            print(f"   MLæ¨¡å‹æµ‹è¯•é‡åˆ°å¼‚å¸¸: {e}")
            # è¿™æ˜¯å¯ä»¥æ¥å—çš„ï¼Œå› ä¸ºå¯èƒ½ç¼ºå°‘æŸäº›ä¾èµ–

        print("âœ… æœºå™¨å­¦ä¹ æ¨¡å‹æµ‹è¯•é€šè¿‡")

    def test_06_prediction_accuracy_validation(self):
        """æµ‹è¯•é¢„æµ‹å‡†ç¡®æ€§éªŒè¯"""
        print("\nğŸ¯ æµ‹è¯•é¢„æµ‹å‡†ç¡®æ€§éªŒè¯...")

        # åˆ›å»ºå¤šä¸ªä¸åŒé…ç½®çš„æµ‹è¯•æ¡ˆä¾‹
        test_cases = [
            ImportTaskConfig(
                task_id="accuracy_test_1",
                name="å°æ‰¹é‡æµ‹è¯•",
                symbols=["000001"],
                data_source="tongdaxin",
                asset_type=AssetType.STOCK,
                frequency=DataFrequency.DAILY,
                mode=ImportMode.INCREMENTAL,
                batch_size=500,
                max_workers=2
            ),
            ImportTaskConfig(
                task_id="accuracy_test_2",
                name="å¤§æ‰¹é‡æµ‹è¯•",
                symbols=["000001", "000002", "000858", "002415", "600036"],
                data_source="akshare",
                asset_type=AssetType.STOCK,
                frequency=DataFrequency.DAILY,
                mode=ImportMode.FULL,
                batch_size=2000,
                max_workers=6
            )
        ]

        predictions = []
        for test_case in test_cases:
            # æ‰§è¡Œæ—¶é—´é¢„æµ‹
            exec_time = self.ai_service.predict_execution_time(
                test_case, self.mock_historical_data
            )

            # å‚æ•°ä¼˜åŒ–
            optimized = self.ai_service.predict_parameter_optimization(
                test_case, self.mock_historical_data
            )

            predictions.append({
                'config': test_case,
                'predicted_time': exec_time,
                'optimized_params': optimized
            })

        # éªŒè¯é¢„æµ‹çš„ä¸€è‡´æ€§
        valid_predictions = [p for p in predictions if p['predicted_time'] is not None]

        if len(valid_predictions) >= 2:
            # å¤§æ‰¹é‡ä»»åŠ¡çš„é¢„æµ‹æ—¶é—´åº”è¯¥æ¯”å°æ‰¹é‡ä»»åŠ¡é•¿
            small_batch_time = valid_predictions[0]['predicted_time']
            large_batch_time = valid_predictions[1]['predicted_time'] if len(valid_predictions) > 1 else None

            if large_batch_time:
                # è¿™ä¸ªæ–­è¨€å¯èƒ½ä¸æ€»æ˜¯æˆç«‹ï¼Œå› ä¸ºä¼˜åŒ–å¯èƒ½æ”¹å–„å¤§æ‰¹é‡çš„æ•ˆç‡
                # self.assertGreaterEqual(large_batch_time, small_batch_time)
                print(f"   å°æ‰¹é‡é¢„æµ‹æ—¶é—´: {small_batch_time:.2f}ç§’")
                print(f"   å¤§æ‰¹é‡é¢„æµ‹æ—¶é—´: {large_batch_time:.2f}ç§’")

        print(f"   æœ‰æ•ˆé¢„æµ‹æ•°é‡: {len(valid_predictions)}/{len(predictions)}")
        print("âœ… é¢„æµ‹å‡†ç¡®æ€§éªŒè¯æµ‹è¯•é€šè¿‡")

    def test_07_edge_cases_and_error_handling(self):
        """æµ‹è¯•è¾¹ç•Œæƒ…å†µå’Œé”™è¯¯å¤„ç†"""
        print("\nğŸ›¡ï¸ æµ‹è¯•è¾¹ç•Œæƒ…å†µå’Œé”™è¯¯å¤„ç†...")

        # æµ‹è¯•ç©ºå†å²æ•°æ®
        empty_data = pd.DataFrame()
        result = self.ai_service.predict_execution_time(self.test_config, empty_data)
        # åº”è¯¥è¿”å›Noneæˆ–é»˜è®¤å€¼ï¼Œè€Œä¸æ˜¯æŠ›å‡ºå¼‚å¸¸

        # æµ‹è¯•æ— æ•ˆé…ç½®
        invalid_config = ImportTaskConfig(
            task_id="invalid",
            name="",
            symbols=[],
            data_source="invalid",
            asset_type=AssetType.STOCK,
            frequency=DataFrequency.DAILY,
            mode=ImportMode.INCREMENTAL,
            batch_size=0,
            max_workers=0
        )

        try:
            result = self.ai_service.predict_parameter_optimization(
                invalid_config, self.mock_historical_data
            )
            # åº”è¯¥èƒ½å¤Ÿå¤„ç†æ— æ•ˆé…ç½®
        except Exception as e:
            # å¦‚æœæŠ›å‡ºå¼‚å¸¸ï¼Œåº”è¯¥æ˜¯å¯æ§çš„
            self.assertIsInstance(e, (ValueError, TypeError, AttributeError))

        # æµ‹è¯•å¼‚å¸¸æ•°æ®
        corrupted_data = self.mock_historical_data.copy()
        corrupted_data.loc[0, 'execution_time'] = -1  # è´Ÿæ•°æ‰§è¡Œæ—¶é—´
        corrupted_data.loc[1, 'batch_size'] = None    # ç©ºå€¼

        try:
            result = self.ai_service.predict_execution_time(
                self.test_config, corrupted_data
            )
            # åº”è¯¥èƒ½å¤Ÿå¤„ç†å¼‚å¸¸æ•°æ®
        except Exception as e:
            # å¦‚æœæŠ›å‡ºå¼‚å¸¸ï¼Œåº”è¯¥æ˜¯å¯æ§çš„
            pass

        print("âœ… è¾¹ç•Œæƒ…å†µå’Œé”™è¯¯å¤„ç†æµ‹è¯•é€šè¿‡")

    def test_08_performance_benchmarks(self):
        """æµ‹è¯•AIæœåŠ¡æ€§èƒ½åŸºå‡†"""
        print("\nâš¡ æµ‹è¯•AIæœåŠ¡æ€§èƒ½åŸºå‡†...")

        import time

        # æµ‹è¯•æ‰§è¡Œæ—¶é—´é¢„æµ‹æ€§èƒ½
        start_time = time.time()
        for _ in range(10):
            self.ai_service.predict_execution_time(
                self.test_config, self.mock_historical_data
            )
        exec_time_perf = time.time() - start_time

        # æµ‹è¯•å‚æ•°ä¼˜åŒ–æ€§èƒ½
        start_time = time.time()
        for _ in range(5):  # å‚æ•°ä¼˜åŒ–è¾ƒæ…¢ï¼Œæµ‹è¯•æ¬¡æ•°å°‘ä¸€äº›
            self.ai_service.predict_parameter_optimization(
                self.test_config, self.mock_historical_data
            )
        param_opt_perf = time.time() - start_time

        # æ€§èƒ½æ–­è¨€
        self.assertLess(exec_time_perf, 5.0,
                        "æ‰§è¡Œæ—¶é—´é¢„æµ‹ï¼š10æ¬¡è°ƒç”¨åº”åœ¨5ç§’å†…å®Œæˆ")
        self.assertLess(param_opt_perf, 15.0,
                        "å‚æ•°ä¼˜åŒ–ï¼š5æ¬¡è°ƒç”¨åº”åœ¨15ç§’å†…å®Œæˆ")

        print(f"   æ‰§è¡Œæ—¶é—´é¢„æµ‹æ€§èƒ½: {exec_time_perf:.2f}ç§’ (10æ¬¡)")
        print(f"   å‚æ•°ä¼˜åŒ–æ€§èƒ½: {param_opt_perf:.2f}ç§’ (5æ¬¡)")
        print("âœ… AIæœåŠ¡æ€§èƒ½åŸºå‡†æµ‹è¯•é€šè¿‡")


class TestAIServiceFeatureExtraction(unittest.TestCase):
    """AIæœåŠ¡ç‰¹å¾æå–ä¸“é¡¹æµ‹è¯•"""

    def setUp(self):
        """æµ‹è¯•å‰è®¾ç½®"""
        if not AI_SERVICES_AVAILABLE:
            self.skipTest("AIæœåŠ¡ç»„ä»¶ä¸å¯ç”¨")

        self.ai_service = AIPredictionService()

        # åˆ›å»ºæ›´è¯¦ç»†çš„æµ‹è¯•æ•°æ®
        self.detailed_data = pd.DataFrame({
            'task_id': [f'task_{i:03d}' for i in range(20)],
            'symbols_count': np.random.randint(1, 10, 20),
            'batch_size': np.random.choice([500, 1000, 2000], 20),
            'max_workers': np.random.randint(1, 8, 20),
            'execution_time': np.random.uniform(30, 300, 20),
            'success_rate': np.random.uniform(0.8, 1.0, 20),
            'memory_usage': np.random.uniform(200, 800, 20),
            'cpu_usage': np.random.uniform(30, 70, 20),
            'data_source': np.random.choice(['tongdaxin', 'akshare'], 20),
            'asset_type': ['stock'] * 20,
            'frequency': ['daily'] * 20
        })

    def test_feature_extraction_completeness(self):
        """æµ‹è¯•ç‰¹å¾æå–å®Œæ•´æ€§"""
        print("\nğŸ” æµ‹è¯•ç‰¹å¾æå–å®Œæ•´æ€§...")

        test_config = ImportTaskConfig(
            task_id="feature_test",
            name="ç‰¹å¾æµ‹è¯•",
            symbols=["000001", "000002"],
            data_source="tongdaxin",
            asset_type=AssetType.STOCK,
            frequency=DataFrequency.DAILY,
            mode=ImportMode.INCREMENTAL,
            batch_size=1000,
            max_workers=4
        )

        features = self.ai_service._extract_optimization_features(
            test_config, self.detailed_data
        )

        if features:
            self.assertIsInstance(features, dict)

            # éªŒè¯åŸºæœ¬ç‰¹å¾
            basic_features = ['symbols_count', 'current_batch_size', 'current_max_workers']
            for feature in basic_features:
                if feature in features:
                    self.assertIsInstance(features[feature], (int, float))

            # éªŒè¯ç»Ÿè®¡ç‰¹å¾
            stat_features = ['avg_execution_time', 'avg_success_rate', 'avg_memory_usage']
            for feature in stat_features:
                if feature in features:
                    self.assertIsInstance(features[feature], (int, float))

            print(f"   æå–ç‰¹å¾æ€»æ•°: {len(features)}")
            print(f"   ç‰¹å¾åç§°: {list(features.keys())}")

        print("âœ… ç‰¹å¾æå–å®Œæ•´æ€§æµ‹è¯•é€šè¿‡")

    def test_feature_engineering_quality(self):
        """æµ‹è¯•ç‰¹å¾å·¥ç¨‹è´¨é‡"""
        print("\nâš™ï¸ æµ‹è¯•ç‰¹å¾å·¥ç¨‹è´¨é‡...")

        # æµ‹è¯•ä¸åŒé…ç½®ä¸‹çš„ç‰¹å¾æå–
        configs = [
            ImportTaskConfig(
                task_id="small_task",
                name="å°ä»»åŠ¡",
                symbols=["000001"],
                data_source="tongdaxin",
                asset_type=AssetType.STOCK,
                frequency=DataFrequency.DAILY,
                mode=ImportMode.INCREMENTAL,
                batch_size=500,
                max_workers=2
            ),
            ImportTaskConfig(
                task_id="large_task",
                name="å¤§ä»»åŠ¡",
                symbols=["000001", "000002", "000858", "002415"],
                data_source="akshare",
                asset_type=AssetType.STOCK,
                frequency=DataFrequency.DAILY,
                mode=ImportMode.FULL,
                batch_size=2000,
                max_workers=6
            )
        ]

        features_list = []
        for config in configs:
            features = self.ai_service._extract_optimization_features(
                config, self.detailed_data
            )
            if features:
                features_list.append(features)

        # éªŒè¯ç‰¹å¾çš„åŒºåˆ†åº¦
        if len(features_list) >= 2:
            small_features = features_list[0]
            large_features = features_list[1]

            # ç¬¦å·æ•°é‡åº”è¯¥ä¸åŒ
            if 'symbols_count' in small_features and 'symbols_count' in large_features:
                self.assertNotEqual(
                    small_features['symbols_count'],
                    large_features['symbols_count']
                )

            # æ‰¹æ¬¡å¤§å°åº”è¯¥ä¸åŒ
            if 'current_batch_size' in small_features and 'current_batch_size' in large_features:
                self.assertNotEqual(
                    small_features['current_batch_size'],
                    large_features['current_batch_size']
                )

        print("âœ… ç‰¹å¾å·¥ç¨‹è´¨é‡æµ‹è¯•é€šè¿‡")


def run_ai_services_tests():
    """è¿è¡ŒAIæœåŠ¡é›†æˆæµ‹è¯•"""
    print("ğŸ¤– å¼€å§‹è¿è¡ŒAIæœåŠ¡é›†æˆæµ‹è¯•...")
    print("=" * 60)

    # åˆ›å»ºæµ‹è¯•å¥—ä»¶
    suite = unittest.TestSuite()

    # æ·»åŠ AIæœåŠ¡æµ‹è¯•
    suite.addTest(unittest.makeSuite(TestAIPredictionServiceIntegration))
    suite.addTest(unittest.makeSuite(TestAIServiceFeatureExtraction))

    # è¿è¡Œæµ‹è¯•
    runner = unittest.TextTestRunner(verbosity=2)
    result = runner.run(suite)

    # è¾“å‡ºæµ‹è¯•ç»“æœæ‘˜è¦
    print("\n" + "=" * 60)
    print("ğŸ¯ AIæœåŠ¡æµ‹è¯•ç»“æœæ‘˜è¦:")
    print(f"   æ€»æµ‹è¯•æ•°: {result.testsRun}")
    print(f"   æˆåŠŸ: {result.testsRun - len(result.failures) - len(result.errors)}")
    print(f"   å¤±è´¥: {len(result.failures)}")
    print(f"   é”™è¯¯: {len(result.errors)}")

    if result.wasSuccessful():
        print("\nğŸ‰ æ‰€æœ‰AIæœåŠ¡æµ‹è¯•é€šè¿‡ï¼")
        return True
    else:
        print("\nâš ï¸ éƒ¨åˆ†AIæœåŠ¡æµ‹è¯•æœªé€šè¿‡ã€‚")
        return False


if __name__ == "__main__":
    success = run_ai_services_tests()
    sys.exit(0 if success else 1)
