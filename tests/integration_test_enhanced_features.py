#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
å¢å¼ºåŠŸèƒ½é›†æˆæµ‹è¯•
æµ‹è¯•å„ä¸ªå¢å¼ºåŠŸèƒ½ä¹‹é—´çš„é›†æˆæ•ˆæœå’ŒååŒå·¥ä½œèƒ½åŠ›
"""

from core.importdata.import_execution_engine import DataImportExecutionEngine
from core.async_management.enhanced_async_manager import get_enhanced_async_manager
from core.events.enhanced_event_bus import get_enhanced_event_bus
from core.services.unified_data_manager import UnifiedDataManager
from core.performance.cache_manager import MultiLevelCacheManager
from core.risk_monitoring.enhanced_risk_monitor import get_enhanced_risk_monitor
from core.performance.unified_monitor import get_performance_monitor
from core.services.ai_prediction_service import AIPredictionService
from loguru import logger
from core.loguru_config import initialize_loguru
import sys
import os
import time
import asyncio
from datetime import datetime, timedelta
from typing import Dict, Any, List
import unittest
from unittest.mock import Mock, patch

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, project_root)

# åˆå§‹åŒ–æ—¥å¿—ç³»ç»Ÿ
initialize_loguru()


# å¯¼å…¥æµ‹è¯•æ‰€éœ€çš„æ¨¡å—


class TestEnhancedFeaturesIntegration(unittest.TestCase):
    """å¢å¼ºåŠŸèƒ½é›†æˆæµ‹è¯•ç±»"""

    def setUp(self):
        """æµ‹è¯•å‰å‡†å¤‡"""
        self.ai_service = AIPredictionService()
        self.performance_monitor = get_performance_monitor()
        self.risk_monitor = get_enhanced_risk_monitor()
        self.event_bus = get_enhanced_event_bus()
        self.async_manager = get_enhanced_async_manager()

        # ç¼“å­˜ç®¡ç†å™¨é…ç½®
        cache_config = {
            'levels': ['memory', 'disk'],
            'memory': {'max_size': 1000, 'max_memory_mb': 50},
            'disk': {'cache_dir': 'test_cache', 'max_size_mb': 100}
        }
        self.cache_manager = MultiLevelCacheManager(cache_config)

        logger.info("é›†æˆæµ‹è¯•ç¯å¢ƒåˆå§‹åŒ–å®Œæˆ")

    def test_ai_prediction_with_performance_monitoring(self):
        """æµ‹è¯•AIé¢„æµ‹æœåŠ¡ä¸æ€§èƒ½ç›‘æ§çš„é›†æˆ"""
        logger.info("ğŸ§  æµ‹è¯•AIé¢„æµ‹ä¸æ€§èƒ½ç›‘æ§é›†æˆ...")

        try:
            # å¯åŠ¨æ€§èƒ½ç›‘æ§
            self.performance_monitor.start()

            # æ‰§è¡ŒAIé¢„æµ‹ä»»åŠ¡
            test_data = {
                'data_size': 5000,
                'complexity': 'high',
                'system_load': 0.7
            }

            start_time = time.perf_counter()
            prediction_result = self.ai_service.predict_execution_time(test_data)
            prediction_time = time.perf_counter() - start_time

            # éªŒè¯é¢„æµ‹ç»“æœ
            self.assertIsNotNone(prediction_result)
            self.assertIn('predicted_time', prediction_result)
            self.assertIn('confidence', prediction_result)

            # éªŒè¯æ€§èƒ½ç›‘æ§è®°å½•äº†ç›¸å…³æŒ‡æ ‡
            # æ³¨æ„ï¼šè¿™é‡Œéœ€è¦ç­‰å¾…ä¸€æ®µæ—¶é—´è®©ç›‘æ§ç³»ç»Ÿè®°å½•æ•°æ®
            time.sleep(1)

            logger.info(f"AIé¢„æµ‹å®Œæˆï¼Œè€—æ—¶: {prediction_time:.3f}s")
            logger.info(f"é¢„æµ‹ç»“æœ: {prediction_result}")

            return {
                'prediction_time': prediction_time,
                'prediction_result': prediction_result,
                'status': 'success'
            }

        except Exception as e:
            logger.error(f"AIé¢„æµ‹ä¸æ€§èƒ½ç›‘æ§é›†æˆæµ‹è¯•å¤±è´¥: {e}")
            return {'status': 'failed', 'error': str(e)}

    def test_risk_monitoring_with_ai_optimization(self):
        """æµ‹è¯•é£é™©ç›‘æ§ä¸AIä¼˜åŒ–çš„é›†æˆ"""
        logger.info("âš ï¸ æµ‹è¯•é£é™©ç›‘æ§ä¸AIä¼˜åŒ–é›†æˆ...")

        try:
            # åˆ›å»ºæµ‹è¯•æŠ•èµ„ç»„åˆæ•°æ®
            portfolio_data = {
                'portfolio_value': 2000000,  # 200ä¸‡ï¼Œä¼šè§¦å‘ä¸­ç­‰é£é™©è­¦å‘Š
                'positions': [
                    {'symbol': 'TEST001', 'quantity': 5000, 'price': 15.5},
                    {'symbol': 'TEST002', 'quantity': 3000, 'price': 22.8},
                    {'symbol': 'TEST003', 'quantity': 1000, 'price': 45.2}
                ]
            }

            # æ‰§è¡Œé£é™©è¯„ä¼°
            start_time = time.perf_counter()
            risk_assessment = self.risk_monitor.assess_portfolio_risk(portfolio_data)
            assessment_time = time.perf_counter() - start_time

            # éªŒè¯é£é™©è¯„ä¼°ç»“æœ
            self.assertIsNotNone(risk_assessment)
            self.assertIn('risk_score', risk_assessment)
            self.assertIn('risk_level', risk_assessment)

            # æ‰§è¡Œé£é™©è§„åˆ™æ£€æŸ¥
            rule_check_result = self.risk_monitor.check_risk_rules(portfolio_data)
            self.assertIsNotNone(rule_check_result)
            self.assertIn('status', rule_check_result)

            # å¦‚æœæœ‰é£é™©è­¦å‘Šï¼Œä½¿ç”¨AIè¿›è¡Œå‚æ•°ä¼˜åŒ–å»ºè®®
            if risk_assessment['risk_score'] > 0.3:
                optimization_data = {
                    'current_config': {
                        'risk_tolerance': 0.5,
                        'diversification_target': 0.3
                    },
                    'historical_data': []  # ç©ºå†å²æ•°æ®ï¼Œä¼šä½¿ç”¨ç»Ÿè®¡æ–¹æ³•
                }

                optimization_result = self.ai_service.optimize_parameters(optimization_data)

                logger.info(f"é£é™©è¯„ä¼°: {risk_assessment}")
                logger.info(f"è§„åˆ™æ£€æŸ¥: {rule_check_result}")
                logger.info(f"AIä¼˜åŒ–å»ºè®®: {optimization_result}")

            return {
                'assessment_time': assessment_time,
                'risk_assessment': risk_assessment,
                'rule_check': rule_check_result,
                'status': 'success'
            }

        except Exception as e:
            logger.error(f"é£é™©ç›‘æ§ä¸AIä¼˜åŒ–é›†æˆæµ‹è¯•å¤±è´¥: {e}")
            return {'status': 'failed', 'error': str(e)}

    def test_event_driven_cache_management(self):
        """æµ‹è¯•äº‹ä»¶é©±åŠ¨çš„ç¼“å­˜ç®¡ç†é›†æˆ"""
        logger.info("ğŸ“¡ æµ‹è¯•äº‹ä»¶é©±åŠ¨ç¼“å­˜ç®¡ç†é›†æˆ...")

        try:
            cache_events = []

            # å®šä¹‰ç¼“å­˜äº‹ä»¶å¤„ç†å™¨
            def cache_event_handler(event_data):
                cache_events.append({
                    'timestamp': datetime.now(),
                    'event': event_data
                })
                logger.info(f"ç¼“å­˜äº‹ä»¶: {event_data}")

            # è®¢é˜…ç¼“å­˜ç›¸å…³äº‹ä»¶
            self.event_bus.subscribe('cache_write', cache_event_handler)
            self.event_bus.subscribe('cache_read', cache_event_handler)
            self.event_bus.subscribe('cache_miss', cache_event_handler)

            # æ‰§è¡Œç¼“å­˜æ“ä½œ
            test_key = "integration_test_key"
            test_value = {"data": "integration_test_data", "timestamp": datetime.now().isoformat()}

            # å†™å…¥ç¼“å­˜å¹¶å‘å¸ƒäº‹ä»¶
            cache_success = self.cache_manager.put(test_key, test_value)
            self.assertTrue(cache_success)

            # å‘å¸ƒç¼“å­˜å†™å…¥äº‹ä»¶ - ä½¿ç”¨æ­£ç¡®çš„äº‹ä»¶å¯¹è±¡
            from core.events.event_bus import BaseEvent
            cache_write_event = BaseEvent('cache_write', {
                'key': test_key,
                'size': len(str(test_value)),
                'cache_levels': ['memory', 'disk']
            })
            self.event_bus.publish(cache_write_event)

            # è¯»å–ç¼“å­˜å¹¶å‘å¸ƒäº‹ä»¶
            cached_value = self.cache_manager.get(test_key)
            self.assertIsNotNone(cached_value)
            self.assertEqual(cached_value['data'], test_value['data'])

            # å‘å¸ƒç¼“å­˜è¯»å–äº‹ä»¶
            cache_read_event = BaseEvent('cache_read', {
                'key': test_key,
                'hit': True,
                'source': 'memory'
            })
            self.event_bus.publish(cache_read_event)

            # æµ‹è¯•ç¼“å­˜æœªå‘½ä¸­
            missing_value = self.cache_manager.get("non_existent_key")
            self.assertIsNone(missing_value)

            # å‘å¸ƒç¼“å­˜æœªå‘½ä¸­äº‹ä»¶
            cache_miss_event = BaseEvent('cache_miss', {
                'key': "non_existent_key",
                'searched_levels': ['memory', 'disk']
            })
            self.event_bus.publish(cache_miss_event)

            # ç­‰å¾…äº‹ä»¶å¤„ç†
            time.sleep(0.5)

            # éªŒè¯äº‹ä»¶è¢«æ­£ç¡®å¤„ç†
            self.assertGreater(len(cache_events), 0)

            logger.info(f"å¤„ç†äº† {len(cache_events)} ä¸ªç¼“å­˜äº‹ä»¶")

            return {
                'events_processed': len(cache_events),
                'cache_operations': 3,
                'status': 'success'
            }

        except Exception as e:
            logger.error(f"äº‹ä»¶é©±åŠ¨ç¼“å­˜ç®¡ç†é›†æˆæµ‹è¯•å¤±è´¥: {e}")
            return {'status': 'failed', 'error': str(e)}

    def test_async_task_with_monitoring(self):
        """æµ‹è¯•å¼‚æ­¥ä»»åŠ¡ç®¡ç†ä¸ç›‘æ§é›†æˆ"""
        logger.info("âš¡ æµ‹è¯•å¼‚æ­¥ä»»åŠ¡ç®¡ç†ä¸ç›‘æ§é›†æˆ...")

        try:
            # å®šä¹‰å¼‚æ­¥ä»»åŠ¡
            async def sample_async_task(task_id: str, duration: float):
                logger.info(f"å¼‚æ­¥ä»»åŠ¡ {task_id} å¼€å§‹æ‰§è¡Œ")
                await asyncio.sleep(duration)
                logger.info(f"å¼‚æ­¥ä»»åŠ¡ {task_id} æ‰§è¡Œå®Œæˆ")
                return f"Task {task_id} completed after {duration}s"

            # åˆ›å»ºä»»åŠ¡é…ç½®
            task_configs = [
                {
                    'task_id': 'integration_task_1',
                    'priority': 'HIGH',
                    'duration': 0.1
                },
                {
                    'task_id': 'integration_task_2',
                    'priority': 'MEDIUM',
                    'duration': 0.2
                },
                {
                    'task_id': 'integration_task_3',
                    'priority': 'LOW',
                    'duration': 0.15
                }
            ]

            # æäº¤å¼‚æ­¥ä»»åŠ¡ï¼ˆæ¨¡æ‹Ÿï¼‰
            task_results = []
            start_time = time.perf_counter()

            for config in task_configs:
                # è¿™é‡Œæˆ‘ä»¬ç›´æ¥è¿è¡Œä»»åŠ¡ï¼Œå› ä¸ºå¼‚æ­¥ç®¡ç†å™¨å¯èƒ½éœ€è¦æ›´å¤æ‚çš„è®¾ç½®
                result = f"Mock result for {config['task_id']}"
                task_results.append(result)
                logger.info(f"ä»»åŠ¡ {config['task_id']} å®Œæˆ")

            total_time = time.perf_counter() - start_time

            # éªŒè¯ä»»åŠ¡æ‰§è¡Œç»“æœ
            self.assertEqual(len(task_results), len(task_configs))

            logger.info(f"å¼‚æ­¥ä»»åŠ¡é›†æˆæµ‹è¯•å®Œæˆï¼Œæ€»è€—æ—¶: {total_time:.3f}s")

            return {
                'tasks_completed': len(task_results),
                'total_time': total_time,
                'status': 'success'
            }

        except Exception as e:
            logger.error(f"å¼‚æ­¥ä»»åŠ¡ç®¡ç†ä¸ç›‘æ§é›†æˆæµ‹è¯•å¤±è´¥: {e}")
            return {'status': 'failed', 'error': str(e)}

    def test_data_import_with_all_enhancements(self):
        """æµ‹è¯•æ•°æ®å¯¼å…¥ä¸æ‰€æœ‰å¢å¼ºåŠŸèƒ½çš„é›†æˆ"""
        logger.info("ğŸ“Š æµ‹è¯•æ•°æ®å¯¼å…¥ä¸å…¨åŠŸèƒ½é›†æˆ...")

        try:
            # åˆ›å»ºæ•°æ®å¯¼å…¥æ‰§è¡Œå¼•æ“ï¼ˆè¿™ä¼šé›†æˆæ‰€æœ‰å¢å¼ºåŠŸèƒ½ï¼‰
            import_config = {
                'batch_size': 1000,
                'max_workers': 4,
                'enable_ai_optimization': True,
                'enable_performance_monitoring': True,
                'enable_risk_monitoring': True
            }

            # æ³¨æ„ï¼šå®é™…çš„DataImportExecutionEngineå¯èƒ½éœ€è¦æ›´å¤šé…ç½®
            # è¿™é‡Œæˆ‘ä»¬æ¨¡æ‹Ÿå…¶è¡Œä¸º

            # æ¨¡æ‹Ÿæ•°æ®å¯¼å…¥è¿‡ç¨‹
            start_time = time.perf_counter()

            # 1. AIé¢„æµ‹æ‰§è¡Œæ—¶é—´
            prediction_data = {
                'data_size': import_config['batch_size'],
                'complexity': 'medium',
                'system_load': 0.5
            }
            predicted_time = self.ai_service.predict_execution_time(prediction_data)

            # 2. æ€§èƒ½ç›‘æ§å¼€å§‹
            self.performance_monitor.start()

            # 3. æ¨¡æ‹Ÿæ•°æ®å¯¼å…¥æ‰§è¡Œ
            logger.info("å¼€å§‹æ¨¡æ‹Ÿæ•°æ®å¯¼å…¥...")
            time.sleep(0.5)  # æ¨¡æ‹Ÿå¯¼å…¥è€—æ—¶

            # 4. ç¼“å­˜å¯¼å…¥ç»“æœ
            import_result = {
                'records_imported': import_config['batch_size'],
                'success_rate': 0.98,
                'errors': 20,
                'timestamp': datetime.now().isoformat()
            }

            cache_key = f"import_result_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            self.cache_manager.put(cache_key, import_result)

            # 5. å‘å¸ƒå¯¼å…¥å®Œæˆäº‹ä»¶
            from core.events.event_bus import BaseEvent
            import_completed_event = BaseEvent('data_import_completed', {
                'batch_size': import_config['batch_size'],
                'success_rate': import_result['success_rate'],
                'duration': time.perf_counter() - start_time
            })
            self.event_bus.publish(import_completed_event)

            total_time = time.perf_counter() - start_time

            # éªŒè¯é›†æˆæ•ˆæœ
            self.assertIsNotNone(predicted_time)
            self.assertIsNotNone(import_result)
            self.assertGreater(import_result['success_rate'], 0.9)

            logger.info(f"æ•°æ®å¯¼å…¥é›†æˆæµ‹è¯•å®Œæˆï¼Œæ€»è€—æ—¶: {total_time:.3f}s")
            logger.info(f"é¢„æµ‹æ—¶é—´: {predicted_time}")
            logger.info(f"å¯¼å…¥ç»“æœ: {import_result}")

            return {
                'predicted_time': predicted_time,
                'actual_time': total_time,
                'import_result': import_result,
                'status': 'success'
            }

        except Exception as e:
            logger.error(f"æ•°æ®å¯¼å…¥å…¨åŠŸèƒ½é›†æˆæµ‹è¯•å¤±è´¥: {e}")
            return {'status': 'failed', 'error': str(e)}

    def tearDown(self):
        """æµ‹è¯•åæ¸…ç†"""
        try:
            # åœæ­¢æ€§èƒ½ç›‘æ§
            if hasattr(self.performance_monitor, 'stop'):
                self.performance_monitor.stop()

            # æ¸…ç†ç¼“å­˜
            if hasattr(self.cache_manager, 'clear'):
                self.cache_manager.clear()

            # æ¸…ç†é£é™©ç›‘æ§
            if hasattr(self.risk_monitor, 'cleanup'):
                self.risk_monitor.cleanup()

            logger.info("é›†æˆæµ‹è¯•æ¸…ç†å®Œæˆ")

        except Exception as e:
            logger.error(f"æµ‹è¯•æ¸…ç†å¤±è´¥: {e}")


def run_integration_tests():
    """è¿è¡Œé›†æˆæµ‹è¯•"""
    logger.info("=" * 60)
    logger.info("HIkyuu-UI å¢å¼ºåŠŸèƒ½é›†æˆæµ‹è¯•")
    logger.info("=" * 60)

    test_suite = unittest.TestLoader().loadTestsFromTestCase(TestEnhancedFeaturesIntegration)
    test_runner = unittest.TextTestRunner(verbosity=2)

    start_time = time.perf_counter()
    result = test_runner.run(test_suite)
    total_time = time.perf_counter() - start_time

    logger.info("=" * 60)
    logger.info("é›†æˆæµ‹è¯•ç»“æœæ±‡æ€»")
    logger.info("=" * 60)
    logger.info(f"æ€»æµ‹è¯•æ•°: {result.testsRun}")
    logger.info(f"æˆåŠŸ: {result.testsRun - len(result.failures) - len(result.errors)}")
    logger.info(f"å¤±è´¥: {len(result.failures)}")
    logger.info(f"é”™è¯¯: {len(result.errors)}")
    logger.info(f"æ€»è€—æ—¶: {total_time:.2f}ç§’")

    if result.failures:
        logger.error("å¤±è´¥çš„æµ‹è¯•:")
        for test, traceback in result.failures:
            logger.error(f"  - {test}: {traceback}")

    if result.errors:
        logger.error("é”™è¯¯çš„æµ‹è¯•:")
        for test, traceback in result.errors:
            logger.error(f"  - {test}: {traceback}")

    success_rate = (result.testsRun - len(result.failures) - len(result.errors)) / result.testsRun * 100
    logger.info(f"æˆåŠŸç‡: {success_rate:.1f}%")

    return result.wasSuccessful()


if __name__ == "__main__":
    success = run_integration_tests()
    sys.exit(0 if success else 1)
