#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ç›‘æ§å’Œç¼“å­˜ç³»ç»Ÿé›†æˆä¸“é¡¹æµ‹è¯•

ä¸“é—¨æµ‹è¯•ç›‘æ§ã€å¼‚å¸¸æ£€æµ‹å’Œå¤šçº§ç¼“å­˜ç³»ç»Ÿçš„é›†æˆ
"""

import unittest
import sys
import os
import time
import json
from pathlib import Path
from unittest.mock import Mock, patch, MagicMock
from datetime import datetime, timedelta

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

try:
    from core.services.deep_analysis_service import DeepAnalysisService
    from core.services.enhanced_data_manager import (
        MultiLevelCacheManager, CacheLevel,  # MultiLayerCache å·²ç§»é™¤
        FactorWeavePerformanceIntegrator, PerformanceMetric, AnomalyInfo
    )
    MONITORING_CACHE_AVAILABLE = True
except ImportError as e:
    print(f"ç›‘æ§å’Œç¼“å­˜ç»„ä»¶å¯¼å…¥å¤±è´¥: {e}")
    MONITORING_CACHE_AVAILABLE = False


class TestDeepAnalysisServiceIntegration(unittest.TestCase):
    """æ·±åº¦åˆ†ææœåŠ¡é›†æˆæµ‹è¯•"""

    def setUp(self):
        """æµ‹è¯•å‰è®¾ç½®"""
        if not MONITORING_CACHE_AVAILABLE:
            self.skipTest("ç›‘æ§å’Œç¼“å­˜ç»„ä»¶ä¸å¯ç”¨")

        self.deep_analysis = DeepAnalysisService()
        self.test_task_id = "monitoring_test_001"

    def test_01_service_initialization(self):
        """æµ‹è¯•æœåŠ¡åˆå§‹åŒ–"""
        print("\nğŸ“Š æµ‹è¯•æ·±åº¦åˆ†ææœåŠ¡åˆå§‹åŒ–...")

        self.assertIsNotNone(self.deep_analysis)
        self.assertTrue(hasattr(self.deep_analysis, 'start_monitoring'))
        self.assertTrue(hasattr(self.deep_analysis, 'stop_monitoring'))
        self.assertTrue(hasattr(self.deep_analysis, 'detect_anomalies'))
        self.assertTrue(hasattr(self.deep_analysis, 'get_performance_metrics'))

        print("âœ… æ·±åº¦åˆ†ææœåŠ¡åˆå§‹åŒ–æµ‹è¯•é€šè¿‡")

    def test_02_performance_monitoring(self):
        """æµ‹è¯•æ€§èƒ½ç›‘æ§"""
        print("\nâ±ï¸ æµ‹è¯•æ€§èƒ½ç›‘æ§...")

        # å¯åŠ¨ç›‘æ§
        self.deep_analysis.start_monitoring(self.test_task_id)

        # æ¨¡æ‹Ÿä¸€äº›å·¥ä½œè´Ÿè½½
        time.sleep(0.1)

        # åœæ­¢ç›‘æ§
        metrics = self.deep_analysis.stop_monitoring(self.test_task_id)

        if metrics:
            self.assertIsInstance(metrics, dict)
            expected_keys = ['execution_time', 'cpu_usage', 'memory_usage']
            for key in expected_keys:
                if key in metrics:
                    self.assertIsInstance(metrics[key], (int, float))

            print(f"   ç›‘æ§æŒ‡æ ‡: {metrics}")

        print("âœ… æ€§èƒ½ç›‘æ§æµ‹è¯•é€šè¿‡")

    def test_03_anomaly_detection(self):
        """æµ‹è¯•å¼‚å¸¸æ£€æµ‹"""
        print("\nğŸš¨ æµ‹è¯•å¼‚å¸¸æ£€æµ‹...")

        # å¯åŠ¨ç›‘æ§
        self.deep_analysis.start_monitoring(self.test_task_id)

        # æ¨¡æ‹Ÿå¼‚å¸¸æƒ…å†µï¼ˆå¦‚æœæœ‰ç›¸å…³æ–¹æ³•ï¼‰
        time.sleep(0.1)

        # æ£€æµ‹å¼‚å¸¸
        anomalies = self.deep_analysis.detect_anomalies(self.test_task_id)

        self.assertIsInstance(anomalies, list)

        # å¦‚æœæ£€æµ‹åˆ°å¼‚å¸¸ï¼ŒéªŒè¯å¼‚å¸¸ä¿¡æ¯ç»“æ„
        for anomaly in anomalies:
            if hasattr(anomaly, 'type') and hasattr(anomaly, 'severity'):
                self.assertIsInstance(anomaly.type, str)
                self.assertIsInstance(anomaly.severity, str)

        print(f"   æ£€æµ‹åˆ°å¼‚å¸¸æ•°é‡: {len(anomalies)}")
        print("âœ… å¼‚å¸¸æ£€æµ‹æµ‹è¯•é€šè¿‡")

    def test_04_performance_metrics_collection(self):
        """æµ‹è¯•æ€§èƒ½æŒ‡æ ‡æ”¶é›†"""
        print("\nğŸ“ˆ æµ‹è¯•æ€§èƒ½æŒ‡æ ‡æ”¶é›†...")

        # å¯åŠ¨ç›‘æ§
        self.deep_analysis.start_monitoring(self.test_task_id)

        # æ¨¡æ‹Ÿå¤šæ¬¡æ•°æ®æ”¶é›†
        for i in range(5):
            time.sleep(0.05)
            # å¦‚æœæœ‰æ›´æ–°æŒ‡æ ‡çš„æ–¹æ³•ï¼Œå¯ä»¥è°ƒç”¨

        # è·å–æ€§èƒ½æŒ‡æ ‡
        metrics = self.deep_analysis.get_performance_metrics(self.test_task_id)

        if metrics:
            self.assertIsInstance(metrics, (dict, list))
            print(f"   æ”¶é›†åˆ°æŒ‡æ ‡æ•°é‡: {len(metrics) if isinstance(metrics, (list, dict)) else 0}")

        # åœæ­¢ç›‘æ§
        self.deep_analysis.stop_monitoring(self.test_task_id)

        print("âœ… æ€§èƒ½æŒ‡æ ‡æ”¶é›†æµ‹è¯•é€šè¿‡")


class TestFactorWeavePerformanceIntegrator(unittest.TestCase):
    """FactorWeaveæ€§èƒ½é›†æˆå™¨æµ‹è¯•"""

    def setUp(self):
        """æµ‹è¯•å‰è®¾ç½®"""
        if not MONITORING_CACHE_AVAILABLE:
            self.skipTest("ç›‘æ§å’Œç¼“å­˜ç»„ä»¶ä¸å¯ç”¨")

        try:
            self.performance_integrator = FactorWeavePerformanceIntegrator()
            self.test_task_id = "integrator_test_001"
        except Exception as e:
            self.skipTest(f"FactorWeavePerformanceIntegratorä¸å¯ç”¨: {e}")

    def test_01_integrator_initialization(self):
        """æµ‹è¯•é›†æˆå™¨åˆå§‹åŒ–"""
        print("\nğŸ”— æµ‹è¯•æ€§èƒ½é›†æˆå™¨åˆå§‹åŒ–...")

        self.assertIsNotNone(self.performance_integrator)

        # æ£€æŸ¥åŸºæœ¬æ–¹æ³•
        expected_methods = ['start_monitoring', 'stop_monitoring', 'get_metrics']
        for method in expected_methods:
            if hasattr(self.performance_integrator, method):
                self.assertTrue(callable(getattr(self.performance_integrator, method)))

        print("âœ… æ€§èƒ½é›†æˆå™¨åˆå§‹åŒ–æµ‹è¯•é€šè¿‡")

    def test_02_unified_monitoring(self):
        """æµ‹è¯•ç»Ÿä¸€ç›‘æ§"""
        print("\nğŸ“Š æµ‹è¯•ç»Ÿä¸€ç›‘æ§...")

        # å¯åŠ¨ç»Ÿä¸€ç›‘æ§
        if hasattr(self.performance_integrator, 'start_monitoring'):
            self.performance_integrator.start_monitoring(self.test_task_id)

            # æ¨¡æ‹Ÿå·¥ä½œè´Ÿè½½
            time.sleep(0.1)

            # åœæ­¢ç›‘æ§å¹¶è·å–ç»“æœ
            if hasattr(self.performance_integrator, 'stop_monitoring'):
                result = self.performance_integrator.stop_monitoring(self.test_task_id)

                if result:
                    self.assertIsInstance(result, dict)
                    print(f"   ç»Ÿä¸€ç›‘æ§ç»“æœ: {result}")

        print("âœ… ç»Ÿä¸€ç›‘æ§æµ‹è¯•é€šè¿‡")

    def test_03_metrics_aggregation(self):
        """æµ‹è¯•æŒ‡æ ‡èšåˆ"""
        print("\nğŸ“‹ æµ‹è¯•æŒ‡æ ‡èšåˆ...")

        # è·å–èšåˆæŒ‡æ ‡
        if hasattr(self.performance_integrator, 'get_metrics'):
            metrics = self.performance_integrator.get_metrics()

            if metrics:
                self.assertIsInstance(metrics, dict)
                print(f"   èšåˆæŒ‡æ ‡: {metrics}")

        print("âœ… æŒ‡æ ‡èšåˆæµ‹è¯•é€šè¿‡")


class TestMultiLevelCacheManager(unittest.TestCase):
    """å¤šçº§ç¼“å­˜ç®¡ç†å™¨æµ‹è¯•"""

    def setUp(self):
        """æµ‹è¯•å‰è®¾ç½®"""
        if not MONITORING_CACHE_AVAILABLE:
            self.skipTest("ç›‘æ§å’Œç¼“å­˜ç»„ä»¶ä¸å¯ç”¨")

        try:
            self.cache_manager = MultiLevelCacheManager()
        except Exception as e:
            self.skipTest(f"MultiLevelCacheManagerä¸å¯ç”¨: {e}")

    def test_01_cache_manager_initialization(self):
        """æµ‹è¯•ç¼“å­˜ç®¡ç†å™¨åˆå§‹åŒ–"""
        print("\nğŸ’¾ æµ‹è¯•å¤šçº§ç¼“å­˜ç®¡ç†å™¨åˆå§‹åŒ–...")

        self.assertIsNotNone(self.cache_manager)

        # æ£€æŸ¥åŸºæœ¬æ–¹æ³•
        expected_methods = ['get', 'set', 'delete', 'clear', 'get_stats']
        for method in expected_methods:
            if hasattr(self.cache_manager, method):
                self.assertTrue(callable(getattr(self.cache_manager, method)))

        print("âœ… å¤šçº§ç¼“å­˜ç®¡ç†å™¨åˆå§‹åŒ–æµ‹è¯•é€šè¿‡")

    def test_02_cache_operations(self):
        """æµ‹è¯•ç¼“å­˜æ“ä½œ"""
        print("\nğŸ”„ æµ‹è¯•ç¼“å­˜æ“ä½œ...")

        test_key = "test_cache_key"
        test_value = {"data": "test_value", "timestamp": time.time()}

        # æµ‹è¯•è®¾ç½®ç¼“å­˜
        if hasattr(self.cache_manager, 'set'):
            set_result = self.cache_manager.set(test_key, test_value)
            print(f"   ç¼“å­˜è®¾ç½®ç»“æœ: {set_result}")

        # æµ‹è¯•è·å–ç¼“å­˜
        if hasattr(self.cache_manager, 'get'):
            cached_value = self.cache_manager.get(test_key)

            if cached_value is not None:
                self.assertEqual(cached_value, test_value)
                print(f"   ç¼“å­˜è·å–æˆåŠŸ: {cached_value}")
            else:
                print("   ç¼“å­˜è·å–ä¸ºç©ºï¼ˆå¯èƒ½æ˜¯å®ç°å·®å¼‚ï¼‰")

        # æµ‹è¯•åˆ é™¤ç¼“å­˜
        if hasattr(self.cache_manager, 'delete'):
            delete_result = self.cache_manager.delete(test_key)
            print(f"   ç¼“å­˜åˆ é™¤ç»“æœ: {delete_result}")

        print("âœ… ç¼“å­˜æ“ä½œæµ‹è¯•é€šè¿‡")

    def test_03_cache_statistics(self):
        """æµ‹è¯•ç¼“å­˜ç»Ÿè®¡"""
        print("\nğŸ“Š æµ‹è¯•ç¼“å­˜ç»Ÿè®¡...")

        # æ‰§è¡Œä¸€äº›ç¼“å­˜æ“ä½œ
        for i in range(5):
            key = f"stats_test_{i}"
            value = {"index": i, "data": f"test_data_{i}"}

            if hasattr(self.cache_manager, 'set'):
                self.cache_manager.set(key, value)

        # è·å–ç»Ÿè®¡ä¿¡æ¯
        if hasattr(self.cache_manager, 'get_stats'):
            stats = self.cache_manager.get_stats()

            if stats:
                self.assertIsInstance(stats, dict)
                print(f"   ç¼“å­˜ç»Ÿè®¡: {stats}")

        print("âœ… ç¼“å­˜ç»Ÿè®¡æµ‹è¯•é€šè¿‡")

    def test_04_cache_performance(self):
        """æµ‹è¯•ç¼“å­˜æ€§èƒ½"""
        print("\nâš¡ æµ‹è¯•ç¼“å­˜æ€§èƒ½...")

        # æµ‹è¯•æ‰¹é‡å†™å…¥æ€§èƒ½
        start_time = time.time()
        for i in range(100):
            key = f"perf_test_{i}"
            value = {"index": i, "timestamp": time.time()}

            if hasattr(self.cache_manager, 'set'):
                self.cache_manager.set(key, value)

        write_time = time.time() - start_time

        # æµ‹è¯•æ‰¹é‡è¯»å–æ€§èƒ½
        start_time = time.time()
        for i in range(100):
            key = f"perf_test_{i}"

            if hasattr(self.cache_manager, 'get'):
                self.cache_manager.get(key)

        read_time = time.time() - start_time

        print(f"   100æ¬¡å†™å…¥è€—æ—¶: {write_time:.3f}ç§’")
        print(f"   100æ¬¡è¯»å–è€—æ—¶: {read_time:.3f}ç§’")

        # æ€§èƒ½æ–­è¨€
        self.assertLess(write_time, 1.0, "100æ¬¡ç¼“å­˜å†™å…¥åº”åœ¨1ç§’å†…å®Œæˆ")
        self.assertLess(read_time, 0.5, "100æ¬¡ç¼“å­˜è¯»å–åº”åœ¨0.5ç§’å†…å®Œæˆ")

        print("âœ… ç¼“å­˜æ€§èƒ½æµ‹è¯•é€šè¿‡")


# class TestMultiLayerCache(unittest.TestCase):  # å·²ç§»é™¤ - MultiLayerCacheå·²ç»Ÿä¸€ä½¿ç”¨MultiLevelCacheManager
class TestMultiLayerCacheObsolete(unittest.TestCase):
    """å¤šå±‚ç¼“å­˜æµ‹è¯•"""

    def setUp(self):
        """æµ‹è¯•å‰è®¾ç½®"""
        if not MONITORING_CACHE_AVAILABLE:
            self.skipTest("ç›‘æ§å’Œç¼“å­˜ç»„ä»¶ä¸å¯ç”¨")

        try:
            # self.multi_layer_cache = MultiLayerCache()  # å·²ç§»é™¤
            self.skipTest("MultiLayerCacheå·²ç§»é™¤ï¼Œç»Ÿä¸€ä½¿ç”¨MultiLevelCacheManager")
        except Exception as e:
            self.skipTest(f"MultiLayerCacheä¸å¯ç”¨: {e}")

    def test_01_multi_layer_initialization(self):
        """æµ‹è¯•å¤šå±‚ç¼“å­˜åˆå§‹åŒ–"""
        print("\nğŸ—ï¸ æµ‹è¯•å¤šå±‚ç¼“å­˜åˆå§‹åŒ–...")

        self.assertIsNotNone(self.multi_layer_cache)

        # æ£€æŸ¥ç¼“å­˜å±‚çº§
        if hasattr(self.multi_layer_cache, 'cache_levels'):
            cache_levels = self.multi_layer_cache.cache_levels
            print(f"   ç¼“å­˜å±‚çº§: {cache_levels}")

        print("âœ… å¤šå±‚ç¼“å­˜åˆå§‹åŒ–æµ‹è¯•é€šè¿‡")

    def test_02_layer_specific_operations(self):
        """æµ‹è¯•å±‚çº§ç‰¹å®šæ“ä½œ"""
        print("\nğŸ“š æµ‹è¯•å±‚çº§ç‰¹å®šæ“ä½œ...")

        test_data = [
            ("l1_key", {"level": "L1", "data": "fast_access"}),
            ("l2_key", {"level": "L2", "data": "medium_access"}),
            ("disk_key", {"level": "DISK", "data": "slow_access"})
        ]

        # æµ‹è¯•ä¸åŒå±‚çº§çš„ç¼“å­˜æ“ä½œ
        for key, value in test_data:
            # å¦‚æœæ”¯æŒå±‚çº§æŒ‡å®š
            if hasattr(self.multi_layer_cache, 'set_level'):
                try:
                    self.multi_layer_cache.set_level(key, value, CacheLevel.L1)
                except:
                    # å¦‚æœä¸æ”¯æŒå±‚çº§æŒ‡å®šï¼Œä½¿ç”¨æ™®é€šset
                    if hasattr(self.multi_layer_cache, 'set'):
                        self.multi_layer_cache.set(key, value)
            elif hasattr(self.multi_layer_cache, 'set'):
                self.multi_layer_cache.set(key, value)

        # æµ‹è¯•è·å–
        for key, expected_value in test_data:
            if hasattr(self.multi_layer_cache, 'get'):
                cached_value = self.multi_layer_cache.get(key)
                if cached_value:
                    print(f"   ç¼“å­˜å‘½ä¸­: {key} -> {cached_value}")

        print("âœ… å±‚çº§ç‰¹å®šæ“ä½œæµ‹è¯•é€šè¿‡")

    def test_03_cache_hierarchy_performance(self):
        """æµ‹è¯•ç¼“å­˜å±‚çº§æ€§èƒ½"""
        print("\nğŸš€ æµ‹è¯•ç¼“å­˜å±‚çº§æ€§èƒ½...")

        # æµ‹è¯•ä¸åŒå¤§å°æ•°æ®çš„ç¼“å­˜æ€§èƒ½
        test_sizes = [
            ("small", {"size": "small", "data": "x" * 100}),
            ("medium", {"size": "medium", "data": "x" * 1000}),
            ("large", {"size": "large", "data": "x" * 10000})
        ]

        performance_results = {}

        for size_name, data in test_sizes:
            # å†™å…¥æ€§èƒ½æµ‹è¯•
            start_time = time.time()
            key = f"perf_{size_name}"

            if hasattr(self.multi_layer_cache, 'set'):
                self.multi_layer_cache.set(key, data)

            write_time = time.time() - start_time

            # è¯»å–æ€§èƒ½æµ‹è¯•
            start_time = time.time()

            if hasattr(self.multi_layer_cache, 'get'):
                self.multi_layer_cache.get(key)

            read_time = time.time() - start_time

            performance_results[size_name] = {
                'write_time': write_time,
                'read_time': read_time
            }

        # è¾“å‡ºæ€§èƒ½ç»“æœ
        for size_name, perf in performance_results.items():
            print(f"   {size_name}æ•°æ® - å†™å…¥: {perf['write_time']:.4f}ç§’, è¯»å–: {perf['read_time']:.4f}ç§’")

        print("âœ… ç¼“å­˜å±‚çº§æ€§èƒ½æµ‹è¯•é€šè¿‡")


class TestIntegratedMonitoringAndCaching(unittest.TestCase):
    """ç›‘æ§å’Œç¼“å­˜é›†æˆæµ‹è¯•"""

    def setUp(self):
        """æµ‹è¯•å‰è®¾ç½®"""
        if not MONITORING_CACHE_AVAILABLE:
            self.skipTest("ç›‘æ§å’Œç¼“å­˜ç»„ä»¶ä¸å¯ç”¨")

        try:
            self.deep_analysis = DeepAnalysisService()
            self.cache_manager = MultiLevelCacheManager()
            self.test_task_id = "integrated_test_001"
        except Exception as e:
            self.skipTest(f"é›†æˆç»„ä»¶ä¸å¯ç”¨: {e}")

    def test_01_monitoring_with_caching(self):
        """æµ‹è¯•ç›‘æ§ä¸ç¼“å­˜çš„ååŒå·¥ä½œ"""
        print("\nğŸ”„ æµ‹è¯•ç›‘æ§ä¸ç¼“å­˜çš„ååŒå·¥ä½œ...")

        # å¯åŠ¨ç›‘æ§
        self.deep_analysis.start_monitoring(self.test_task_id)

        # æ‰§è¡Œä¸€äº›ç¼“å­˜æ“ä½œï¼ŒåŒæ—¶ç›‘æ§æ€§èƒ½
        for i in range(10):
            key = f"integrated_test_{i}"
            value = {
                "index": i,
                "timestamp": time.time(),
                "task_id": self.test_task_id
            }

            # ç¼“å­˜æ“ä½œ
            if hasattr(self.cache_manager, 'set'):
                self.cache_manager.set(key, value)

            # çŸ­æš‚å»¶è¿Ÿ
            time.sleep(0.01)

        # åœæ­¢ç›‘æ§å¹¶è·å–ç»“æœ
        monitoring_result = self.deep_analysis.stop_monitoring(self.test_task_id)

        # è·å–ç¼“å­˜ç»Ÿè®¡
        cache_stats = None
        if hasattr(self.cache_manager, 'get_stats'):
            cache_stats = self.cache_manager.get_stats()

        # éªŒè¯ç»“æœ
        if monitoring_result:
            self.assertIsInstance(monitoring_result, dict)
            print(f"   ç›‘æ§ç»“æœ: {monitoring_result}")

        if cache_stats:
            self.assertIsInstance(cache_stats, dict)
            print(f"   ç¼“å­˜ç»Ÿè®¡: {cache_stats}")

        print("âœ… ç›‘æ§ä¸ç¼“å­˜ååŒå·¥ä½œæµ‹è¯•é€šè¿‡")

    def test_02_performance_impact_analysis(self):
        """æµ‹è¯•æ€§èƒ½å½±å“åˆ†æ"""
        print("\nğŸ“ˆ æµ‹è¯•æ€§èƒ½å½±å“åˆ†æ...")

        # æµ‹è¯•æ— ç¼“å­˜æƒ…å†µä¸‹çš„æ€§èƒ½
        self.deep_analysis.start_monitoring(f"{self.test_task_id}_no_cache")

        # æ¨¡æ‹Ÿæ— ç¼“å­˜çš„æ•°æ®å¤„ç†
        for i in range(50):
            # æ¨¡æ‹Ÿæ•°æ®å¤„ç†å»¶è¿Ÿ
            time.sleep(0.002)

        no_cache_result = self.deep_analysis.stop_monitoring(f"{self.test_task_id}_no_cache")

        # æµ‹è¯•æœ‰ç¼“å­˜æƒ…å†µä¸‹çš„æ€§èƒ½
        self.deep_analysis.start_monitoring(f"{self.test_task_id}_with_cache")

        # é¢„å…ˆç¼“å­˜ä¸€äº›æ•°æ®
        for i in range(50):
            key = f"cached_data_{i}"
            value = {"processed": True, "result": i * 2}

            if hasattr(self.cache_manager, 'set'):
                self.cache_manager.set(key, value)

        # æ¨¡æ‹Ÿä»ç¼“å­˜è¯»å–æ•°æ®
        for i in range(50):
            key = f"cached_data_{i}"

            if hasattr(self.cache_manager, 'get'):
                self.cache_manager.get(key)

        with_cache_result = self.deep_analysis.stop_monitoring(f"{self.test_task_id}_with_cache")

        # æ¯”è¾ƒæ€§èƒ½å·®å¼‚
        if no_cache_result and with_cache_result:
            print(f"   æ— ç¼“å­˜æ€§èƒ½: {no_cache_result}")
            print(f"   æœ‰ç¼“å­˜æ€§èƒ½: {with_cache_result}")

            # å¦‚æœæœ‰æ‰§è¡Œæ—¶é—´å­—æ®µï¼Œæ¯”è¾ƒå·®å¼‚
            if 'execution_time' in no_cache_result and 'execution_time' in with_cache_result:
                no_cache_time = no_cache_result['execution_time']
                with_cache_time = with_cache_result['execution_time']

                if no_cache_time > 0 and with_cache_time > 0:
                    improvement = (no_cache_time - with_cache_time) / no_cache_time * 100
                    print(f"   æ€§èƒ½æå‡: {improvement:.2f}%")

        print("âœ… æ€§èƒ½å½±å“åˆ†ææµ‹è¯•é€šè¿‡")


def run_monitoring_cache_tests():
    """è¿è¡Œç›‘æ§å’Œç¼“å­˜é›†æˆæµ‹è¯•"""
    print("ğŸ“Š å¼€å§‹è¿è¡Œç›‘æ§å’Œç¼“å­˜é›†æˆæµ‹è¯•...")
    print("=" * 60)

    # åˆ›å»ºæµ‹è¯•å¥—ä»¶
    suite = unittest.TestSuite()

    # æ·»åŠ ç›‘æ§å’Œç¼“å­˜æµ‹è¯•
    suite.addTest(unittest.makeSuite(TestDeepAnalysisServiceIntegration))
    suite.addTest(unittest.makeSuite(TestFactorWeavePerformanceIntegrator))
    suite.addTest(unittest.makeSuite(TestMultiLevelCacheManager))
    # suite.addTest(unittest.makeSuite(TestMultiLayerCache))  # å·²ç§»é™¤
    suite.addTest(unittest.makeSuite(TestMultiLayerCacheObsolete))  # å ä½æµ‹è¯•ï¼Œä¼šè¢«è·³è¿‡
    suite.addTest(unittest.makeSuite(TestIntegratedMonitoringAndCaching))

    # è¿è¡Œæµ‹è¯•
    runner = unittest.TextTestRunner(verbosity=2)
    result = runner.run(suite)

    # è¾“å‡ºæµ‹è¯•ç»“æœæ‘˜è¦
    print("\n" + "=" * 60)
    print("ğŸ¯ ç›‘æ§å’Œç¼“å­˜æµ‹è¯•ç»“æœæ‘˜è¦:")
    print(f"   æ€»æµ‹è¯•æ•°: {result.testsRun}")
    print(f"   æˆåŠŸ: {result.testsRun - len(result.failures) - len(result.errors)}")
    print(f"   å¤±è´¥: {len(result.failures)}")
    print(f"   é”™è¯¯: {len(result.errors)}")

    if result.wasSuccessful():
        print("\nğŸ‰ æ‰€æœ‰ç›‘æ§å’Œç¼“å­˜æµ‹è¯•é€šè¿‡ï¼")
        return True
    else:
        print("\nâš ï¸ éƒ¨åˆ†ç›‘æ§å’Œç¼“å­˜æµ‹è¯•æœªé€šè¿‡ã€‚")
        return False


if __name__ == "__main__":
    success = run_monitoring_cache_tests()
    sys.exit(0 if success else 1)
