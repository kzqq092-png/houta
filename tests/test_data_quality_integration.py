#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
æ•°æ®è´¨é‡ç›‘æ§ç³»ç»Ÿé›†æˆä¸“é¡¹æµ‹è¯•

ä¸“é—¨æµ‹è¯•æ•°æ®è´¨é‡ç›‘æ§ã€éªŒè¯å’ŒKçº¿æ•°æ®ç‰¹å®šæ£€æŸ¥çš„é›†æˆ
"""

import unittest
import sys
import os
import pandas as pd
import numpy as np
from pathlib import Path
from unittest.mock import Mock, patch, MagicMock
from datetime import datetime, timedelta

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

try:
    from core.services.enhanced_data_manager import (
        DataQualityMonitor, DataQualityMetrics, DataQuality,
        ValidationLevel, ValidationResult
    )
    DATA_QUALITY_AVAILABLE = True
except ImportError as e:
    print(f"æ•°æ®è´¨é‡ç»„ä»¶å¯¼å…¥å¤±è´¥: {e}")
    DATA_QUALITY_AVAILABLE = False


class TestDataQualityMonitorIntegration(unittest.TestCase):
    """æ•°æ®è´¨é‡ç›‘æ§é›†æˆæµ‹è¯•"""

    def setUp(self):
        """æµ‹è¯•å‰è®¾ç½®"""
        if not DATA_QUALITY_AVAILABLE:
            self.skipTest("æ•°æ®è´¨é‡ç»„ä»¶ä¸å¯ç”¨")

        try:
            self.quality_monitor = DataQualityMonitor()
            self.test_task_id = "quality_test_001"
        except Exception as e:
            self.skipTest(f"DataQualityMonitorä¸å¯ç”¨: {e}")

        # åˆ›å»ºæµ‹è¯•æ•°æ®
        self.create_test_data()

    def create_test_data(self):
        """åˆ›å»ºå„ç§æµ‹è¯•æ•°æ®"""

        # 1. æ­£å¸¸çš„Kçº¿æ•°æ®
        self.normal_kdata = pd.DataFrame({
            'date': pd.date_range('2024-01-01', periods=100, freq='D'),
            'open': np.random.uniform(10, 20, 100),
            'high': np.random.uniform(15, 25, 100),
            'low': np.random.uniform(8, 15, 100),
            'close': np.random.uniform(10, 20, 100),
            'volume': np.random.randint(1000, 100000, 100),
            'amount': np.random.uniform(10000, 1000000, 100)
        })

        # ç¡®ä¿OHLCé€»è¾‘æ­£ç¡®
        for i in range(len(self.normal_kdata)):
            row = self.normal_kdata.iloc[i]
            high = max(row['open'], row['close']) + np.random.uniform(0, 2)
            low = min(row['open'], row['close']) - np.random.uniform(0, 2)
            self.normal_kdata.at[i, 'high'] = high
            self.normal_kdata.at[i, 'low'] = low

        # 2. æœ‰é—®é¢˜çš„Kçº¿æ•°æ®
        self.problematic_kdata = self.normal_kdata.copy()

        # æ·»åŠ å„ç§æ•°æ®è´¨é‡é—®é¢˜
        self.problematic_kdata.loc[10, 'high'] = self.problematic_kdata.loc[10, 'low'] - 1  # high < low
        self.problematic_kdata.loc[20, 'open'] = np.nan  # ç¼ºå¤±å€¼
        self.problematic_kdata.loc[30, 'volume'] = -1000  # è´Ÿæ•°æˆäº¤é‡
        self.problematic_kdata.loc[40, 'close'] = self.problematic_kdata.loc[40, 'high'] + 5  # close > high

        # 3. ç©ºæ•°æ®
        self.empty_data = pd.DataFrame()

        # 4. ä¸å®Œæ•´çš„æ•°æ®
        self.incomplete_data = pd.DataFrame({
            'date': pd.date_range('2024-01-01', periods=10, freq='D'),
            'open': np.random.uniform(10, 20, 10),
            'close': np.random.uniform(10, 20, 10)
            # ç¼ºå°‘ high, low, volume ç­‰å­—æ®µ
        })

    def test_01_quality_monitor_initialization(self):
        """æµ‹è¯•æ•°æ®è´¨é‡ç›‘æ§å™¨åˆå§‹åŒ–"""
        print("\nâœ… æµ‹è¯•æ•°æ®è´¨é‡ç›‘æ§å™¨åˆå§‹åŒ–...")

        self.assertIsNotNone(self.quality_monitor)

        # æ£€æŸ¥åŸºæœ¬æ–¹æ³•
        expected_methods = [
            'validate_data', 'get_quality_metrics', 'check_completeness',
            'check_accuracy', 'check_consistency', 'check_timeliness'
        ]

        for method in expected_methods:
            if hasattr(self.quality_monitor, method):
                self.assertTrue(callable(getattr(self.quality_monitor, method)))
                print(f"   âœ“ æ–¹æ³• {method} å¯ç”¨")

        print("âœ… æ•°æ®è´¨é‡ç›‘æ§å™¨åˆå§‹åŒ–æµ‹è¯•é€šè¿‡")

    def test_02_normal_data_validation(self):
        """æµ‹è¯•æ­£å¸¸æ•°æ®éªŒè¯"""
        print("\nğŸ“Š æµ‹è¯•æ­£å¸¸æ•°æ®éªŒè¯...")

        # éªŒè¯æ­£å¸¸Kçº¿æ•°æ®
        if hasattr(self.quality_monitor, 'validate_data'):
            try:
                validation_result = self.quality_monitor.validate_data(
                    task_id=self.test_task_id,
                    data=self.normal_kdata,
                    data_source="tongdaxin",
                    data_type="kdata"
                )

                if validation_result:
                    self.assertIsInstance(validation_result, ValidationResult)

                    # éªŒè¯ç»“æœå±æ€§
                    if hasattr(validation_result, 'is_valid'):
                        print(f"   æ•°æ®æœ‰æ•ˆæ€§: {validation_result.is_valid}")

                    if hasattr(validation_result, 'quality_level'):
                        print(f"   è´¨é‡ç­‰çº§: {validation_result.quality_level}")

                    if hasattr(validation_result, 'overall_score'):
                        print(f"   æ€»ä½“è¯„åˆ†: {validation_result.overall_score}")
                        self.assertIsInstance(validation_result.overall_score, (int, float))
                        self.assertGreaterEqual(validation_result.overall_score, 0)
                        self.assertLessEqual(validation_result.overall_score, 100)

                    if hasattr(validation_result, 'issues'):
                        print(f"   å‘ç°é—®é¢˜æ•°é‡: {len(validation_result.issues)}")

                        # æ­£å¸¸æ•°æ®åº”è¯¥é—®é¢˜è¾ƒå°‘
                        if len(validation_result.issues) > 0:
                            print("   å‘ç°çš„é—®é¢˜:")
                            for issue in validation_result.issues[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
                                print(f"     - {issue}")
                else:
                    print("   éªŒè¯ç»“æœä¸ºç©º")

            except Exception as e:
                print(f"   æ•°æ®éªŒè¯é‡åˆ°å¼‚å¸¸: {e}")

        print("âœ… æ­£å¸¸æ•°æ®éªŒè¯æµ‹è¯•é€šè¿‡")

    def test_03_problematic_data_validation(self):
        """æµ‹è¯•é—®é¢˜æ•°æ®éªŒè¯"""
        print("\nğŸš¨ æµ‹è¯•é—®é¢˜æ•°æ®éªŒè¯...")

        # éªŒè¯æœ‰é—®é¢˜çš„Kçº¿æ•°æ®
        if hasattr(self.quality_monitor, 'validate_data'):
            try:
                validation_result = self.quality_monitor.validate_data(
                    task_id=self.test_task_id,
                    data=self.problematic_kdata,
                    data_source="tongdaxin",
                    data_type="kdata"
                )

                if validation_result:
                    print(f"   é—®é¢˜æ•°æ®æœ‰æ•ˆæ€§: {validation_result.is_valid}")
                    print(f"   é—®é¢˜æ•°æ®è´¨é‡ç­‰çº§: {validation_result.quality_level}")
                    print(f"   é—®é¢˜æ•°æ®è¯„åˆ†: {validation_result.overall_score}")

                    # é—®é¢˜æ•°æ®åº”è¯¥è¢«æ£€æµ‹å‡ºæ¥
                    if hasattr(validation_result, 'issues'):
                        print(f"   æ£€æµ‹åˆ°é—®é¢˜æ•°é‡: {len(validation_result.issues)}")

                        # åº”è¯¥æ£€æµ‹åˆ°æˆ‘ä»¬æ•…æ„æ·»åŠ çš„é—®é¢˜
                        self.assertGreater(len(validation_result.issues), 0)

                        print("   æ£€æµ‹åˆ°çš„é—®é¢˜:")
                        for issue in validation_result.issues:
                            print(f"     - {issue}")

                    # é—®é¢˜æ•°æ®çš„è¯„åˆ†åº”è¯¥è¾ƒä½
                    if hasattr(validation_result, 'overall_score'):
                        # ä¸ä¸€å®šæ€»æ˜¯æˆç«‹ï¼Œå–å†³äºé—®é¢˜çš„ä¸¥é‡ç¨‹åº¦
                        # self.assertLess(validation_result.overall_score, 80)
                        pass
                else:
                    print("   é—®é¢˜æ•°æ®éªŒè¯ç»“æœä¸ºç©º")

            except Exception as e:
                print(f"   é—®é¢˜æ•°æ®éªŒè¯é‡åˆ°å¼‚å¸¸: {e}")

        print("âœ… é—®é¢˜æ•°æ®éªŒè¯æµ‹è¯•é€šè¿‡")

    def test_04_empty_and_incomplete_data_validation(self):
        """æµ‹è¯•ç©ºæ•°æ®å’Œä¸å®Œæ•´æ•°æ®éªŒè¯"""
        print("\nğŸ“­ æµ‹è¯•ç©ºæ•°æ®å’Œä¸å®Œæ•´æ•°æ®éªŒè¯...")

        # æµ‹è¯•ç©ºæ•°æ®
        if hasattr(self.quality_monitor, 'validate_data'):
            try:
                empty_result = self.quality_monitor.validate_data(
                    task_id=self.test_task_id,
                    data=self.empty_data,
                    data_source="tongdaxin",
                    data_type="kdata"
                )

                if empty_result:
                    print(f"   ç©ºæ•°æ®éªŒè¯ç»“æœ: {empty_result.is_valid}")
                    print(f"   ç©ºæ•°æ®è¯„åˆ†: {empty_result.overall_score}")

                    # ç©ºæ•°æ®åº”è¯¥è¢«æ ‡è®°ä¸ºæ— æ•ˆ
                    if hasattr(empty_result, 'is_valid'):
                        self.assertFalse(empty_result.is_valid)
                else:
                    print("   ç©ºæ•°æ®éªŒè¯æ— ç»“æœ")

            except Exception as e:
                print(f"   ç©ºæ•°æ®éªŒè¯é‡åˆ°å¼‚å¸¸: {e}")

        # æµ‹è¯•ä¸å®Œæ•´æ•°æ®
        if hasattr(self.quality_monitor, 'validate_data'):
            try:
                incomplete_result = self.quality_monitor.validate_data(
                    task_id=self.test_task_id,
                    data=self.incomplete_data,
                    data_source="tongdaxin",
                    data_type="kdata"
                )

                if incomplete_result:
                    print(f"   ä¸å®Œæ•´æ•°æ®éªŒè¯ç»“æœ: {incomplete_result.is_valid}")
                    print(f"   ä¸å®Œæ•´æ•°æ®è¯„åˆ†: {incomplete_result.overall_score}")

                    # ä¸å®Œæ•´æ•°æ®åº”è¯¥æœ‰è´¨é‡é—®é¢˜
                    if hasattr(incomplete_result, 'issues'):
                        print(f"   ä¸å®Œæ•´æ•°æ®é—®é¢˜æ•°é‡: {len(incomplete_result.issues)}")
                else:
                    print("   ä¸å®Œæ•´æ•°æ®éªŒè¯æ— ç»“æœ")

            except Exception as e:
                print(f"   ä¸å®Œæ•´æ•°æ®éªŒè¯é‡åˆ°å¼‚å¸¸: {e}")

        print("âœ… ç©ºæ•°æ®å’Œä¸å®Œæ•´æ•°æ®éªŒè¯æµ‹è¯•é€šè¿‡")

    def test_05_quality_metrics_collection(self):
        """æµ‹è¯•è´¨é‡æŒ‡æ ‡æ”¶é›†"""
        print("\nğŸ“ˆ æµ‹è¯•è´¨é‡æŒ‡æ ‡æ”¶é›†...")

        # æ‰§è¡Œå¤šæ¬¡éªŒè¯ä»¥æ”¶é›†æŒ‡æ ‡
        test_datasets = [
            ("normal", self.normal_kdata),
            ("problematic", self.problematic_kdata),
            ("incomplete", self.incomplete_data)
        ]

        for name, data in test_datasets:
            if hasattr(self.quality_monitor, 'validate_data'):
                try:
                    self.quality_monitor.validate_data(
                        task_id=f"{self.test_task_id}_{name}",
                        data=data,
                        data_source="tongdaxin",
                        data_type="kdata"
                    )
                except:
                    pass

        # è·å–è´¨é‡æŒ‡æ ‡
        if hasattr(self.quality_monitor, 'get_quality_metrics'):
            try:
                metrics = self.quality_monitor.get_quality_metrics()

                if metrics:
                    self.assertIsInstance(metrics, (dict, DataQualityMetrics))

                    if isinstance(metrics, dict):
                        print(f"   è´¨é‡æŒ‡æ ‡: {metrics}")

                        # éªŒè¯åŸºæœ¬æŒ‡æ ‡
                        expected_keys = [
                            'total_validations', 'successful_validations',
                            'average_quality_score', 'common_issues'
                        ]

                        for key in expected_keys:
                            if key in metrics:
                                print(f"   {key}: {metrics[key]}")

                    elif hasattr(metrics, 'total_records_processed'):
                        print(f"   å¤„ç†è®°å½•æ€»æ•°: {metrics.total_records_processed}")
                        print(f"   å¹³å‡è´¨é‡åˆ†æ•°: {metrics.average_quality_score}")
                else:
                    print("   è´¨é‡æŒ‡æ ‡ä¸ºç©º")

            except Exception as e:
                print(f"   è·å–è´¨é‡æŒ‡æ ‡é‡åˆ°å¼‚å¸¸: {e}")

        print("âœ… è´¨é‡æŒ‡æ ‡æ”¶é›†æµ‹è¯•é€šè¿‡")

    def test_06_specific_quality_checks(self):
        """æµ‹è¯•ç‰¹å®šè´¨é‡æ£€æŸ¥"""
        print("\nğŸ” æµ‹è¯•ç‰¹å®šè´¨é‡æ£€æŸ¥...")

        # æµ‹è¯•å®Œæ•´æ€§æ£€æŸ¥
        if hasattr(self.quality_monitor, 'check_completeness'):
            try:
                completeness = self.quality_monitor.check_completeness(self.normal_kdata)

                if completeness is not None:
                    self.assertIsInstance(completeness, (int, float, dict))
                    print(f"   å®Œæ•´æ€§æ£€æŸ¥ç»“æœ: {completeness}")

            except Exception as e:
                print(f"   å®Œæ•´æ€§æ£€æŸ¥é‡åˆ°å¼‚å¸¸: {e}")

        # æµ‹è¯•å‡†ç¡®æ€§æ£€æŸ¥
        if hasattr(self.quality_monitor, 'check_accuracy'):
            try:
                accuracy = self.quality_monitor.check_accuracy(
                    self.normal_kdata, "kdata"
                )

                if accuracy is not None:
                    self.assertIsInstance(accuracy, (int, float, dict))
                    print(f"   å‡†ç¡®æ€§æ£€æŸ¥ç»“æœ: {accuracy}")

            except Exception as e:
                print(f"   å‡†ç¡®æ€§æ£€æŸ¥é‡åˆ°å¼‚å¸¸: {e}")

        # æµ‹è¯•ä¸€è‡´æ€§æ£€æŸ¥
        if hasattr(self.quality_monitor, 'check_consistency'):
            try:
                consistency = self.quality_monitor.check_consistency(self.normal_kdata)

                if consistency is not None:
                    self.assertIsInstance(consistency, (int, float, dict))
                    print(f"   ä¸€è‡´æ€§æ£€æŸ¥ç»“æœ: {consistency}")

            except Exception as e:
                print(f"   ä¸€è‡´æ€§æ£€æŸ¥é‡åˆ°å¼‚å¸¸: {e}")

        # æµ‹è¯•æ—¶æ•ˆæ€§æ£€æŸ¥
        if hasattr(self.quality_monitor, 'check_timeliness'):
            try:
                timeliness = self.quality_monitor.check_timeliness(self.normal_kdata)

                if timeliness is not None:
                    self.assertIsInstance(timeliness, (int, float, dict))
                    print(f"   æ—¶æ•ˆæ€§æ£€æŸ¥ç»“æœ: {timeliness}")

            except Exception as e:
                print(f"   æ—¶æ•ˆæ€§æ£€æŸ¥é‡åˆ°å¼‚å¸¸: {e}")

        print("âœ… ç‰¹å®šè´¨é‡æ£€æŸ¥æµ‹è¯•é€šè¿‡")

    def test_07_kline_specific_validation(self):
        """æµ‹è¯•Kçº¿ç‰¹å®šéªŒè¯"""
        print("\nğŸ“Š æµ‹è¯•Kçº¿ç‰¹å®šéªŒè¯...")

        # åˆ›å»ºä¸“é—¨çš„Kçº¿æµ‹è¯•æ•°æ®
        kline_test_cases = {
            "æ­£å¸¸Kçº¿": pd.DataFrame({
                'date': pd.date_range('2024-01-01', periods=5, freq='D'),
                'open': [10.0, 11.0, 12.0, 13.0, 14.0],
                'high': [10.5, 11.5, 12.5, 13.5, 14.5],
                'low': [9.5, 10.5, 11.5, 12.5, 13.5],
                'close': [10.2, 11.2, 12.2, 13.2, 14.2],
                'volume': [1000, 1100, 1200, 1300, 1400]
            }),

            "OHLCé€»è¾‘é”™è¯¯": pd.DataFrame({
                'date': pd.date_range('2024-01-01', periods=3, freq='D'),
                'open': [10.0, 11.0, 12.0],
                'high': [9.0, 10.0, 11.0],  # high < openï¼Œé”™è¯¯
                'low': [11.0, 12.0, 13.0],  # low > openï¼Œé”™è¯¯
                'close': [10.2, 11.2, 12.2],
                'volume': [1000, 1100, 1200]
            }),

            "æˆäº¤é‡å¼‚å¸¸": pd.DataFrame({
                'date': pd.date_range('2024-01-01', periods=3, freq='D'),
                'open': [10.0, 11.0, 12.0],
                'high': [10.5, 11.5, 12.5],
                'low': [9.5, 10.5, 11.5],
                'close': [10.2, 11.2, 12.2],
                'volume': [-1000, 0, 1200]  # è´Ÿæ•°å’Œé›¶æˆäº¤é‡
            })
        }

        for case_name, test_data in kline_test_cases.items():
            print(f"   æµ‹è¯•æ¡ˆä¾‹: {case_name}")

            if hasattr(self.quality_monitor, 'validate_data'):
                try:
                    result = self.quality_monitor.validate_data(
                        task_id=f"{self.test_task_id}_{case_name}",
                        data=test_data,
                        data_source="tongdaxin",
                        data_type="kdata"
                    )

                    if result:
                        print(f"     æœ‰æ•ˆæ€§: {result.is_valid}")
                        print(f"     è¯„åˆ†: {result.overall_score}")

                        if hasattr(result, 'issues') and result.issues:
                            print(f"     é—®é¢˜æ•°é‡: {len(result.issues)}")
                            for issue in result.issues[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ªé—®é¢˜
                                print(f"       - {issue}")
                    else:
                        print(f"     éªŒè¯ç»“æœä¸ºç©º")

                except Exception as e:
                    print(f"     éªŒè¯é‡åˆ°å¼‚å¸¸: {e}")

        print("âœ… Kçº¿ç‰¹å®šéªŒè¯æµ‹è¯•é€šè¿‡")

    def test_08_quality_issue_handling(self):
        """æµ‹è¯•è´¨é‡é—®é¢˜å¤„ç†"""
        print("\nğŸ› ï¸ æµ‹è¯•è´¨é‡é—®é¢˜å¤„ç†...")

        # éªŒè¯é—®é¢˜æ•°æ®
        if hasattr(self.quality_monitor, 'validate_data'):
            try:
                validation_result = self.quality_monitor.validate_data(
                    task_id=self.test_task_id,
                    data=self.problematic_kdata,
                    data_source="tongdaxin",
                    data_type="kdata"
                )

                if validation_result and hasattr(validation_result, 'issues'):
                    print(f"   æ£€æµ‹åˆ°é—®é¢˜æ•°é‡: {len(validation_result.issues)}")

                    # æµ‹è¯•é—®é¢˜å¤„ç†
                    if hasattr(self.quality_monitor, 'handle_quality_issues'):
                        try:
                            handling_result = self.quality_monitor.handle_quality_issues(
                                validation_result, self.test_task_id
                            )

                            if handling_result:
                                print(f"   é—®é¢˜å¤„ç†ç»“æœ: {handling_result}")
                            else:
                                print("   é—®é¢˜å¤„ç†æ— ç»“æœ")

                        except Exception as e:
                            print(f"   é—®é¢˜å¤„ç†é‡åˆ°å¼‚å¸¸: {e}")

                    # æµ‹è¯•é—®é¢˜åˆ†ç±»
                    if hasattr(self.quality_monitor, 'categorize_issues'):
                        try:
                            categorized = self.quality_monitor.categorize_issues(
                                validation_result.issues
                            )

                            if categorized:
                                print(f"   é—®é¢˜åˆ†ç±»ç»“æœ: {categorized}")

                        except Exception as e:
                            print(f"   é—®é¢˜åˆ†ç±»é‡åˆ°å¼‚å¸¸: {e}")

            except Exception as e:
                print(f"   è´¨é‡é—®é¢˜å¤„ç†æµ‹è¯•é‡åˆ°å¼‚å¸¸: {e}")

        print("âœ… è´¨é‡é—®é¢˜å¤„ç†æµ‹è¯•é€šè¿‡")

    def test_09_performance_benchmarks(self):
        """æµ‹è¯•æ•°æ®è´¨é‡æ£€æŸ¥æ€§èƒ½åŸºå‡†"""
        print("\nâš¡ æµ‹è¯•æ•°æ®è´¨é‡æ£€æŸ¥æ€§èƒ½åŸºå‡†...")

        import time

        # åˆ›å»ºä¸åŒå¤§å°çš„æµ‹è¯•æ•°æ®
        test_sizes = [100, 1000, 5000]
        performance_results = {}

        for size in test_sizes:
            # åˆ›å»ºæŒ‡å®šå¤§å°çš„æµ‹è¯•æ•°æ®
            large_data = pd.DataFrame({
                'date': pd.date_range('2024-01-01', periods=size, freq='D'),
                'open': np.random.uniform(10, 20, size),
                'high': np.random.uniform(15, 25, size),
                'low': np.random.uniform(8, 15, size),
                'close': np.random.uniform(10, 20, size),
                'volume': np.random.randint(1000, 100000, size)
            })

            # ç¡®ä¿OHLCé€»è¾‘æ­£ç¡®
            for i in range(len(large_data)):
                row = large_data.iloc[i]
                high = max(row['open'], row['close']) + np.random.uniform(0, 2)
                low = min(row['open'], row['close']) - np.random.uniform(0, 2)
                large_data.at[i, 'high'] = high
                large_data.at[i, 'low'] = low

            # æµ‹è¯•éªŒè¯æ€§èƒ½
            if hasattr(self.quality_monitor, 'validate_data'):
                start_time = time.time()

                try:
                    self.quality_monitor.validate_data(
                        task_id=f"perf_test_{size}",
                        data=large_data,
                        data_source="tongdaxin",
                        data_type="kdata"
                    )

                    validation_time = time.time() - start_time
                    performance_results[size] = validation_time

                    print(f"   {size}æ¡è®°å½•éªŒè¯è€—æ—¶: {validation_time:.3f}ç§’")

                    # æ€§èƒ½æ–­è¨€
                    records_per_second = size / validation_time if validation_time > 0 else 0
                    print(f"   å¤„ç†é€Ÿåº¦: {records_per_second:.0f}æ¡/ç§’")

                    # åˆç†çš„æ€§èƒ½æœŸæœ›ï¼šè‡³å°‘æ¯ç§’å¤„ç†1000æ¡è®°å½•
                    if size >= 1000:
                        self.assertGreater(records_per_second, 500,
                                           f"æ€§èƒ½ä¸è¶³ï¼š{size}æ¡è®°å½•å¤„ç†é€Ÿåº¦åº”å¤§äº500æ¡/ç§’")

                except Exception as e:
                    print(f"   {size}æ¡è®°å½•éªŒè¯é‡åˆ°å¼‚å¸¸: {e}")

        # è¾“å‡ºæ€§èƒ½æ‘˜è¦
        if performance_results:
            print("   æ€§èƒ½æ‘˜è¦:")
            for size, time_taken in performance_results.items():
                rate = size / time_taken if time_taken > 0 else 0
                print(f"     {size}æ¡è®°å½•: {time_taken:.3f}ç§’ ({rate:.0f}æ¡/ç§’)")

        print("âœ… æ•°æ®è´¨é‡æ£€æŸ¥æ€§èƒ½åŸºå‡†æµ‹è¯•é€šè¿‡")

    def test_10_integration_with_import_engine(self):
        """æµ‹è¯•ä¸å¯¼å…¥å¼•æ“çš„é›†æˆ"""
        print("\nğŸ”— æµ‹è¯•ä¸å¯¼å…¥å¼•æ“çš„é›†æˆ...")

        # æ¨¡æ‹Ÿå¯¼å…¥å¼•æ“è°ƒç”¨æ•°æ®è´¨é‡æ£€æŸ¥
        mock_import_scenarios = [
            {
                "task_id": "import_integration_1",
                "data": self.normal_kdata,
                "source": "tongdaxin",
                "expected_valid": True
            },
            {
                "task_id": "import_integration_2",
                "data": self.problematic_kdata,
                "source": "akshare",
                "expected_valid": False
            },
            {
                "task_id": "import_integration_3",
                "data": self.empty_data,
                "source": "tushare",
                "expected_valid": False
            }
        ]

        integration_results = []

        for scenario in mock_import_scenarios:
            print(f"   æµ‹è¯•åœºæ™¯: {scenario['task_id']}")

            if hasattr(self.quality_monitor, 'validate_data'):
                try:
                    result = self.quality_monitor.validate_data(
                        task_id=scenario['task_id'],
                        data=scenario['data'],
                        data_source=scenario['source'],
                        data_type="kdata"
                    )

                    if result:
                        integration_results.append({
                            'scenario': scenario,
                            'result': result,
                            'validation_passed': result.is_valid == scenario['expected_valid']
                        })

                        print(f"     éªŒè¯ç»“æœ: {result.is_valid}")
                        print(f"     é¢„æœŸç»“æœ: {scenario['expected_valid']}")
                        print(f"     é›†æˆæµ‹è¯•: {'é€šè¿‡' if result.is_valid == scenario['expected_valid'] else 'å¤±è´¥'}")
                    else:
                        print(f"     éªŒè¯ç»“æœä¸ºç©º")

                except Exception as e:
                    print(f"     é›†æˆæµ‹è¯•é‡åˆ°å¼‚å¸¸: {e}")

        # éªŒè¯é›†æˆæ•ˆæœ
        passed_tests = sum(1 for r in integration_results if r['validation_passed'])
        total_tests = len(integration_results)

        print(f"   é›†æˆæµ‹è¯•é€šè¿‡ç‡: {passed_tests}/{total_tests} ({passed_tests/total_tests*100:.1f}%)")

        if total_tests > 0:
            self.assertGreaterEqual(passed_tests / total_tests, 0.6,
                                    "é›†æˆæµ‹è¯•é€šè¿‡ç‡åº”è‡³å°‘è¾¾åˆ°60%")

        print("âœ… ä¸å¯¼å…¥å¼•æ“çš„é›†æˆæµ‹è¯•é€šè¿‡")


def run_data_quality_tests():
    """è¿è¡Œæ•°æ®è´¨é‡é›†æˆæµ‹è¯•"""
    print("âœ… å¼€å§‹è¿è¡Œæ•°æ®è´¨é‡é›†æˆæµ‹è¯•...")
    print("=" * 60)

    # åˆ›å»ºæµ‹è¯•å¥—ä»¶
    suite = unittest.TestSuite()

    # æ·»åŠ æ•°æ®è´¨é‡æµ‹è¯•
    suite.addTest(unittest.makeSuite(TestDataQualityMonitorIntegration))

    # è¿è¡Œæµ‹è¯•
    runner = unittest.TextTestRunner(verbosity=2)
    result = runner.run(suite)

    # è¾“å‡ºæµ‹è¯•ç»“æœæ‘˜è¦
    print("\n" + "=" * 60)
    print("ğŸ¯ æ•°æ®è´¨é‡æµ‹è¯•ç»“æœæ‘˜è¦:")
    print(f"   æ€»æµ‹è¯•æ•°: {result.testsRun}")
    print(f"   æˆåŠŸ: {result.testsRun - len(result.failures) - len(result.errors)}")
    print(f"   å¤±è´¥: {len(result.failures)}")
    print(f"   é”™è¯¯: {len(result.errors)}")

    if result.wasSuccessful():
        print("\nğŸ‰ æ‰€æœ‰æ•°æ®è´¨é‡æµ‹è¯•é€šè¿‡ï¼")
        return True
    else:
        print("\nâš ï¸ éƒ¨åˆ†æ•°æ®è´¨é‡æµ‹è¯•æœªé€šè¿‡ã€‚")
        return False


if __name__ == "__main__":
    success = run_data_quality_tests()
    sys.exit(0 if success else 1)
