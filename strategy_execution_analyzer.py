#!/usr/bin/env python3
"""
ç­–ç•¥æ‰§è¡Œå’Œé£é™©æ§åˆ¶é€»è¾‘åˆ†æå™¨
==========================

æ·±å…¥åˆ†æå›æµ‹ç³»ç»Ÿä¸­çš„ç­–ç•¥æ‰§è¡Œé€»è¾‘ã€é£é™©æ§åˆ¶æœºåˆ¶å’Œäº¤æ˜“æ‰§è¡Œæµç¨‹
"""

import sys
import ast
import inspect
import logging
from typing import Dict, List, Any, Optional, Tuple, Set
from dataclasses import dataclass, field
from pathlib import Path
import json
import re

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


@dataclass
class StrategyExecutionIssue:
    """ç­–ç•¥æ‰§è¡Œé—®é¢˜"""
    severity: str  # CRITICAL, HIGH, MEDIUM, LOW
    category: str
    method_name: str
    file_path: str
    line_number: int
    issue_type: str
    description: str
    code_snippet: str
    risk_level: str
    recommendation: str


@dataclass
class RiskControlAnalysis:
    """é£é™©æ§åˆ¶åˆ†æ"""
    method_name: str
    risk_checks: List[str] = field(default_factory=list)
    missing_checks: List[str] = field(default_factory=list)
    potential_issues: List[str] = field(default_factory=list)
    safety_score: int = 0  # 0-100


class StrategyExecutionAnalyzer:
    """ç­–ç•¥æ‰§è¡Œåˆ†æå™¨"""

    def __init__(self):
        self.execution_issues = []
        self.risk_analyses = {}
        self.trading_flow_issues = []

    def analyze_strategy_execution(self) -> Dict[str, Any]:
        """åˆ†æç­–ç•¥æ‰§è¡Œé€»è¾‘"""
        logger.info("ğŸ¯ å¼€å§‹åˆ†æç­–ç•¥æ‰§è¡Œå’Œé£é™©æ§åˆ¶é€»è¾‘...")

        results = {
            'execution_flow_analysis': {},
            'risk_control_analysis': {},
            'trading_logic_issues': [],
            'data_integrity_issues': [],
            'performance_issues': [],
            'safety_recommendations': [],
            'critical_fixes_needed': []
        }

        try:
            # 1. åˆ†ææ‰§è¡Œæµç¨‹
            logger.info("ğŸ“Š åˆ†ææ‰§è¡Œæµç¨‹...")
            results['execution_flow_analysis'] = self._analyze_execution_flow()

            # 2. åˆ†æé£é™©æ§åˆ¶
            logger.info("ğŸ›¡ï¸ åˆ†æé£é™©æ§åˆ¶æœºåˆ¶...")
            results['risk_control_analysis'] = self._analyze_risk_control()

            # 3. åˆ†æäº¤æ˜“é€»è¾‘
            logger.info("ğŸ’° åˆ†æäº¤æ˜“é€»è¾‘...")
            results['trading_logic_issues'] = self._analyze_trading_logic()

            # 4. åˆ†ææ•°æ®å®Œæ•´æ€§
            logger.info("ğŸ“‹ åˆ†ææ•°æ®å®Œæ•´æ€§...")
            results['data_integrity_issues'] = self._analyze_data_integrity()

            # 5. åˆ†ææ€§èƒ½é—®é¢˜
            logger.info("âš¡ åˆ†ææ€§èƒ½é—®é¢˜...")
            results['performance_issues'] = self._analyze_performance_issues()

            # 6. ç”Ÿæˆå®‰å…¨å»ºè®®
            logger.info("ğŸ”’ ç”Ÿæˆå®‰å…¨å»ºè®®...")
            results['safety_recommendations'] = self._generate_safety_recommendations()

            # 7. è¯†åˆ«å…³é”®ä¿®å¤é¡¹
            results['critical_fixes_needed'] = self._identify_critical_fixes(results)

            logger.info("âœ… ç­–ç•¥æ‰§è¡Œåˆ†æå®Œæˆ")
            return results

        except Exception as e:
            logger.error(f"ç­–ç•¥æ‰§è¡Œåˆ†æå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return results

    def _analyze_execution_flow(self) -> Dict[str, Any]:
        """åˆ†ææ‰§è¡Œæµç¨‹"""
        flow_analysis = {
            'main_execution_methods': [],
            'execution_order': [],
            'bottleneck_points': [],
            'error_handling_gaps': [],
            'flow_complexity': {}
        }

        # åˆ†æä¸»è¦æ‰§è¡Œæ–‡ä»¶
        main_files = [
            'backtest/unified_backtest_engine.py',
            'plugins/strategies/hikyuu_strategy_plugin.py',
            'plugins/strategies/backtrader_strategy_plugin.py'
        ]

        for file_path in main_files:
            full_path = project_root / file_path
            if full_path.exists():
                file_analysis = self._analyze_execution_file(full_path)
                flow_analysis['main_execution_methods'].extend(file_analysis['execution_methods'])
                flow_analysis['bottleneck_points'].extend(file_analysis['bottlenecks'])
                flow_analysis['error_handling_gaps'].extend(file_analysis['error_gaps'])

        return flow_analysis

    def _analyze_execution_file(self, file_path: Path) -> Dict[str, Any]:
        """åˆ†ææ‰§è¡Œæ–‡ä»¶"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()

            tree = ast.parse(content)

            analysis = {
                'execution_methods': [],
                'bottlenecks': [],
                'error_gaps': []
            }

            # æŸ¥æ‰¾å…³é”®æ‰§è¡Œæ–¹æ³•
            execution_method_patterns = [
                'run_backtest', 'execute', 'process', 'calculate',
                '_run_core_backtest', '_process_trading_signals',
                '_execute_open_position', '_check_exit_conditions'
            ]

            for node in ast.walk(tree):
                if isinstance(node, ast.FunctionDef):
                    method_name = node.name

                    # æ£€æŸ¥æ˜¯å¦æ˜¯æ‰§è¡Œæ–¹æ³•
                    if any(pattern in method_name.lower() for pattern in execution_method_patterns):
                        method_info = self._analyze_execution_method(node, file_path)
                        analysis['execution_methods'].append(method_info)

                        # æ£€æŸ¥ç“¶é¢ˆ
                        if method_info['complexity'] > 15 or method_info['loop_count'] > 3:
                            analysis['bottlenecks'].append({
                                'method': method_name,
                                'file': str(file_path),
                                'reason': f"å¤æ‚åº¦ {method_info['complexity']}, å¾ªç¯ {method_info['loop_count']}"
                            })

                        # æ£€æŸ¥é”™è¯¯å¤„ç†ç¼ºé™·
                        if method_info['bare_except_count'] > 0:
                            analysis['error_gaps'].append({
                                'method': method_name,
                                'file': str(file_path),
                                'issue': f"è£¸éœ²å¼‚å¸¸å¤„ç† {method_info['bare_except_count']} ä¸ª"
                            })

            return analysis

        except Exception as e:
            logger.error(f"åˆ†ææ‰§è¡Œæ–‡ä»¶ {file_path} å¤±è´¥: {e}")
            return {'execution_methods': [], 'bottlenecks': [], 'error_gaps': []}

    def _analyze_execution_method(self, node: ast.FunctionDef, file_path: Path) -> Dict[str, Any]:
        """åˆ†ææ‰§è¡Œæ–¹æ³•"""
        method_info = {
            'name': node.name,
            'file': str(file_path),
            'line': node.lineno,
            'complexity': 1,
            'loop_count': 0,
            'condition_count': 0,
            'bare_except_count': 0,
            'database_calls': 0,
            'calculation_calls': 0,
            'potential_issues': []
        }

        # åˆ†ææ–¹æ³•ä½“
        for child in ast.walk(node):
            if isinstance(child, (ast.If, ast.While, ast.For)):
                method_info['complexity'] += 1
                if isinstance(child, (ast.While, ast.For)):
                    method_info['loop_count'] += 1
                else:
                    method_info['condition_count'] += 1

            elif isinstance(child, ast.ExceptHandler):
                if child.type is None:
                    method_info['bare_except_count'] += 1

            elif isinstance(child, ast.Call):
                if hasattr(child.func, 'attr'):
                    func_name = child.func.attr.lower()
                    if any(db_word in func_name for db_word in ['query', 'execute', 'fetch', 'commit']):
                        method_info['database_calls'] += 1
                    elif any(calc_word in func_name for calc_word in ['calculate', 'compute', 'sum', 'mean']):
                        method_info['calculation_calls'] += 1

        # è¯†åˆ«æ½œåœ¨é—®é¢˜
        if method_info['bare_except_count'] > 0:
            method_info['potential_issues'].append("è£¸éœ²å¼‚å¸¸å¤„ç†å¯èƒ½éšè—å…³é”®é”™è¯¯")

        if method_info['loop_count'] > 2 and method_info['database_calls'] > 0:
            method_info['potential_issues'].append("å¾ªç¯ä¸­åŒ…å«æ•°æ®åº“è°ƒç”¨ï¼Œå¯èƒ½å½±å“æ€§èƒ½")

        if method_info['complexity'] > 20:
            method_info['potential_issues'].append("æ–¹æ³•å¤æ‚åº¦è¿‡é«˜ï¼Œéš¾ä»¥ç»´æŠ¤å’Œæµ‹è¯•")

        return method_info

    def _analyze_risk_control(self) -> Dict[str, Any]:
        """åˆ†æé£é™©æ§åˆ¶æœºåˆ¶"""
        risk_analysis = {
            'position_management': {},
            'stop_loss_logic': {},
            'take_profit_logic': {},
            'risk_metrics_calculation': {},
            'portfolio_constraints': {},
            'missing_controls': []
        }

        # åˆ†æUnifiedBacktestEngineä¸­çš„é£é™©æ§åˆ¶
        engine_file = project_root / 'backtest/unified_backtest_engine.py'
        if engine_file.exists():
            risk_analysis.update(self._analyze_risk_control_in_file(engine_file))

        return risk_analysis

    def _analyze_risk_control_in_file(self, file_path: Path) -> Dict[str, Any]:
        """åˆ†ææ–‡ä»¶ä¸­çš„é£é™©æ§åˆ¶"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()

            tree = ast.parse(content)

            risk_methods = {
                'position_management': [],
                'stop_loss_logic': [],
                'take_profit_logic': [],
                'risk_metrics_calculation': [],
                'portfolio_constraints': [],
                'missing_controls': []
            }

            # æŸ¥æ‰¾é£é™©æ§åˆ¶ç›¸å…³æ–¹æ³•
            risk_patterns = {
                'position_management': ['position', 'size', 'allocation'],
                'stop_loss_logic': ['stop_loss', 'sl', 'exit', 'loss'],
                'take_profit_logic': ['take_profit', 'tp', 'profit', 'target'],
                'risk_metrics_calculation': ['risk', 'drawdown', 'var', 'volatility'],
                'portfolio_constraints': ['constraint', 'limit', 'max', 'min']
            }

            for node in ast.walk(tree):
                if isinstance(node, ast.FunctionDef):
                    method_name = node.name.lower()

                    for category, patterns in risk_patterns.items():
                        if any(pattern in method_name for pattern in patterns):
                            method_analysis = self._analyze_risk_method(node, file_path)
                            risk_methods[category].append(method_analysis)

            # æ£€æŸ¥ç¼ºå¤±çš„é£é™©æ§åˆ¶
            essential_controls = [
                'position_size_validation',
                'stop_loss_enforcement',
                'portfolio_risk_check',
                'drawdown_protection'
            ]

            found_controls = set()
            for category, methods in risk_methods.items():
                for method in methods:
                    method_name = method['name'].lower()
                    if 'position' in method_name and 'size' in method_name:
                        found_controls.add('position_size_validation')
                    elif 'stop' in method_name and 'loss' in method_name:
                        found_controls.add('stop_loss_enforcement')
                    elif 'portfolio' in method_name and 'risk' in method_name:
                        found_controls.add('portfolio_risk_check')
                    elif 'drawdown' in method_name:
                        found_controls.add('drawdown_protection')

            missing_controls = [control for control in essential_controls if control not in found_controls]
            risk_methods['missing_controls'] = missing_controls

            return risk_methods

        except Exception as e:
            logger.error(f"åˆ†æé£é™©æ§åˆ¶æ–‡ä»¶ {file_path} å¤±è´¥: {e}")
            return {}

    def _analyze_risk_method(self, node: ast.FunctionDef, file_path: Path) -> Dict[str, Any]:
        """åˆ†æé£é™©æ§åˆ¶æ–¹æ³•"""
        method_analysis = {
            'name': node.name,
            'file': str(file_path),
            'line': node.lineno,
            'risk_checks': [],
            'validation_logic': [],
            'error_handling': [],
            'potential_issues': []
        }

        # åˆ†ææ–¹æ³•å†…å®¹
        method_source = ast.get_source_segment(open(file_path, 'r', encoding='utf-8').read(), node)
        if method_source:
            # æ£€æŸ¥é£é™©éªŒè¯é€»è¾‘
            if re.search(r'if.*[<>]=?.*:', method_source):
                method_analysis['risk_checks'].append('æ•°å€¼èŒƒå›´æ£€æŸ¥')

            if re.search(r'assert\s+', method_source):
                method_analysis['validation_logic'].append('æ–­è¨€éªŒè¯')

            if re.search(r'raise\s+', method_source):
                method_analysis['validation_logic'].append('å¼‚å¸¸æŠ›å‡º')

            if re.search(r'try:', method_source):
                method_analysis['error_handling'].append('å¼‚å¸¸å¤„ç†')

            # æ£€æŸ¥æ½œåœ¨é—®é¢˜
            if 'except:' in method_source:
                method_analysis['potential_issues'].append('è£¸éœ²å¼‚å¸¸å¤„ç†')

            if not method_analysis['risk_checks'] and 'risk' in node.name.lower():
                method_analysis['potential_issues'].append('é£é™©æ–¹æ³•ç¼ºå°‘éªŒè¯é€»è¾‘')

        return method_analysis

    def _analyze_trading_logic(self) -> List[Dict[str, Any]]:
        """åˆ†æäº¤æ˜“é€»è¾‘"""
        trading_issues = []

        # åˆ†æäº¤æ˜“æ‰§è¡Œç›¸å…³æ–‡ä»¶
        trading_files = [
            'backtest/unified_backtest_engine.py',
            'plugins/strategies/hikyuu_strategy_plugin.py'
        ]

        for file_path in trading_files:
            full_path = project_root / file_path
            if full_path.exists():
                file_issues = self._analyze_trading_file(full_path)
                trading_issues.extend(file_issues)

        return trading_issues

    def _analyze_trading_file(self, file_path: Path) -> List[Dict[str, Any]]:
        """åˆ†æäº¤æ˜“æ–‡ä»¶"""
        issues = []

        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()

            # æŸ¥æ‰¾äº¤æ˜“æ‰§è¡Œæ–¹æ³•
            trading_method_patterns = [
                '_execute_open_position',
                '_execute_close_position',
                '_process_trading_signals',
                'buy', 'sell', 'trade'
            ]

            lines = content.splitlines()

            for i, line in enumerate(lines, 1):
                line_lower = line.lower().strip()

                # æ£€æŸ¥äº¤æ˜“é€»è¾‘é—®é¢˜
                if any(pattern in line_lower for pattern in trading_method_patterns):
                    # æ£€æŸ¥æ˜¯å¦æœ‰é€‚å½“çš„é”™è¯¯å¤„ç†
                    if 'try:' not in content[max(0, content.find(line)-500):content.find(line)+500]:
                        issues.append({
                            'type': 'missing_error_handling',
                            'file': str(file_path),
                            'line': i,
                            'description': 'äº¤æ˜“æ‰§è¡Œç¼ºå°‘é”™è¯¯å¤„ç†',
                            'severity': 'HIGH',
                            'code': line.strip()
                        })

                # æ£€æŸ¥ä»·æ ¼è®¡ç®—é—®é¢˜
                if 'price' in line_lower and ('*' in line or '/' in line):
                    if 'round' not in line_lower and 'decimal' not in line_lower:
                        issues.append({
                            'type': 'price_precision',
                            'file': str(file_path),
                            'line': i,
                            'description': 'ä»·æ ¼è®¡ç®—å¯èƒ½å­˜åœ¨ç²¾åº¦é—®é¢˜',
                            'severity': 'MEDIUM',
                            'code': line.strip()
                        })

                # æ£€æŸ¥æ•°é‡è®¡ç®—é—®é¢˜
                if 'quantity' in line_lower or 'shares' in line_lower:
                    if 'int(' not in line_lower and 'floor(' not in line_lower:
                        issues.append({
                            'type': 'quantity_precision',
                            'file': str(file_path),
                            'line': i,
                            'description': 'è‚¡ç¥¨æ•°é‡è®¡ç®—å¯èƒ½äº§ç”Ÿå°æ•°',
                            'severity': 'MEDIUM',
                            'code': line.strip()
                        })

        except Exception as e:
            logger.error(f"åˆ†æäº¤æ˜“æ–‡ä»¶ {file_path} å¤±è´¥: {e}")

        return issues

    def _analyze_data_integrity(self) -> List[Dict[str, Any]]:
        """åˆ†ææ•°æ®å®Œæ•´æ€§"""
        integrity_issues = []

        # æ£€æŸ¥æ•°æ®éªŒè¯é€»è¾‘
        data_files = [
            'backtest/unified_backtest_engine.py',
            'core/metrics/repository.py'
        ]

        for file_path in data_files:
            full_path = project_root / file_path
            if full_path.exists():
                file_issues = self._analyze_data_integrity_in_file(full_path)
                integrity_issues.extend(file_issues)

        return integrity_issues

    def _analyze_data_integrity_in_file(self, file_path: Path) -> List[Dict[str, Any]]:
        """åˆ†ææ–‡ä»¶ä¸­çš„æ•°æ®å®Œæ•´æ€§"""
        issues = []

        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()

            lines = content.splitlines()

            for i, line in enumerate(lines, 1):
                line_lower = line.lower().strip()

                # æ£€æŸ¥æ•°æ®è®¿é—®æ˜¯å¦æœ‰è¾¹ç•Œæ£€æŸ¥
                if '[' in line and ']' in line:
                    # æ•°ç»„/åˆ—è¡¨è®¿é—®
                    if 'len(' not in content[max(0, content.find(line)-200):content.find(line)]:
                        issues.append({
                            'type': 'missing_bounds_check',
                            'file': str(file_path),
                            'line': i,
                            'description': 'æ•°ç»„è®¿é—®ç¼ºå°‘è¾¹ç•Œæ£€æŸ¥',
                            'severity': 'MEDIUM',
                            'code': line.strip()
                        })

                # æ£€æŸ¥é™¤æ³•è¿ç®—æ˜¯å¦æœ‰é›¶æ£€æŸ¥
                if '/' in line and 'if' not in line_lower:
                    if '!= 0' not in content[max(0, content.find(line)-100):content.find(line)+100]:
                        issues.append({
                            'type': 'division_by_zero_risk',
                            'file': str(file_path),
                            'line': i,
                            'description': 'é™¤æ³•è¿ç®—å¯èƒ½å­˜åœ¨é™¤é›¶é£é™©',
                            'severity': 'HIGH',
                            'code': line.strip()
                        })

                # æ£€æŸ¥æ•°æ®åº“æŸ¥è¯¢ç»“æœæ˜¯å¦éªŒè¯
                if 'query' in line_lower or 'fetch' in line_lower:
                    if 'if' not in content[content.find(line):content.find(line)+200]:
                        issues.append({
                            'type': 'unchecked_query_result',
                            'file': str(file_path),
                            'line': i,
                            'description': 'æ•°æ®åº“æŸ¥è¯¢ç»“æœæœªéªŒè¯',
                            'severity': 'MEDIUM',
                            'code': line.strip()
                        })

        except Exception as e:
            logger.error(f"åˆ†ææ•°æ®å®Œæ•´æ€§æ–‡ä»¶ {file_path} å¤±è´¥: {e}")

        return issues

    def _analyze_performance_issues(self) -> List[Dict[str, Any]]:
        """åˆ†ææ€§èƒ½é—®é¢˜"""
        performance_issues = []

        # åŸºäºä¹‹å‰çš„åˆ†æç»“æœ
        known_issues = [
            {
                'method': '_run_core_backtest',
                'issue': 'æ ¸å¿ƒå›æµ‹å¾ªç¯å¯èƒ½å­˜åœ¨æ€§èƒ½ç“¶é¢ˆ',
                'recommendation': 'è€ƒè™‘å‘é‡åŒ–æ“ä½œå’Œå¹¶è¡Œå¤„ç†'
            },
            {
                'method': '_process_trading_signals',
                'issue': 'ä¿¡å·å¤„ç†é€»è¾‘å¯èƒ½é‡å¤è®¡ç®—',
                'recommendation': 'å®ç°ä¿¡å·ç¼“å­˜æœºåˆ¶'
            },
            {
                'method': 'query_historical_data',
                'issue': 'å†å²æ•°æ®æŸ¥è¯¢å¯èƒ½é¢‘ç¹è®¿é—®æ•°æ®åº“',
                'recommendation': 'å®ç°æ•°æ®é¢„åŠ è½½å’Œç¼“å­˜'
            }
        ]

        for issue in known_issues:
            performance_issues.append({
                'type': 'performance_bottleneck',
                'method': issue['method'],
                'description': issue['issue'],
                'recommendation': issue['recommendation'],
                'severity': 'HIGH'
            })

        return performance_issues

    def _generate_safety_recommendations(self) -> List[Dict[str, Any]]:
        """ç”Ÿæˆå®‰å…¨å»ºè®®"""
        recommendations = [
            {
                'category': 'å¼‚å¸¸å¤„ç†',
                'priority': 'CRITICAL',
                'title': 'ä¿®å¤è£¸éœ²å¼‚å¸¸å¤„ç†',
                'description': 'å°†æ‰€æœ‰ except: æ”¹ä¸ºå…·ä½“å¼‚å¸¸ç±»å‹',
                'implementation': [
                    'è¯†åˆ«æ‰€æœ‰è£¸éœ²çš„ except: è¯­å¥',
                    'æ ¹æ®ä¸Šä¸‹æ–‡ç¡®å®šå…·ä½“å¼‚å¸¸ç±»å‹',
                    'æ·»åŠ é€‚å½“çš„é”™è¯¯æ—¥å¿—è®°å½•',
                    'å®ç°ä¼˜é›…çš„é”™è¯¯æ¢å¤æœºåˆ¶'
                ]
            },
            {
                'category': 'æ•°æ®éªŒè¯',
                'priority': 'HIGH',
                'title': 'åŠ å¼ºæ•°æ®å®Œæ•´æ€§æ£€æŸ¥',
                'description': 'åœ¨å…³é”®æ•°æ®æ“ä½œå‰æ·»åŠ éªŒè¯é€»è¾‘',
                'implementation': [
                    'æ·»åŠ æ•°ç»„è¾¹ç•Œæ£€æŸ¥',
                    'å®ç°é™¤é›¶ä¿æŠ¤',
                    'éªŒè¯æ•°æ®åº“æŸ¥è¯¢ç»“æœ',
                    'æ·»åŠ æ•°æ®ç±»å‹æ£€æŸ¥'
                ]
            },
            {
                'category': 'é£é™©æ§åˆ¶',
                'priority': 'HIGH',
                'title': 'å®Œå–„é£é™©ç®¡ç†æœºåˆ¶',
                'description': 'å®ç°å…¨é¢çš„é£é™©æ§åˆ¶ä½“ç³»',
                'implementation': [
                    'æ·»åŠ ä»“ä½å¤§å°éªŒè¯',
                    'å®ç°æ­¢æŸæ­¢ç›ˆå¼ºåˆ¶æ‰§è¡Œ',
                    'æ·»åŠ ç»„åˆé£é™©ç›‘æ§',
                    'å®ç°æœ€å¤§å›æ’¤ä¿æŠ¤'
                ]
            },
            {
                'category': 'æ€§èƒ½ä¼˜åŒ–',
                'priority': 'MEDIUM',
                'title': 'ä¼˜åŒ–å…³é”®æ€§èƒ½ç“¶é¢ˆ',
                'description': 'é’ˆå¯¹è¯†åˆ«çš„ç“¶é¢ˆè¿›è¡Œä¸“é¡¹ä¼˜åŒ–',
                'implementation': [
                    'å®ç°æ•°æ®ç¼“å­˜æœºåˆ¶',
                    'ä½¿ç”¨å‘é‡åŒ–æ“ä½œ',
                    'è€ƒè™‘å¹¶è¡Œå¤„ç†',
                    'ä¼˜åŒ–æ•°æ®åº“æŸ¥è¯¢'
                ]
            }
        ]

        return recommendations

    def _identify_critical_fixes(self, results: Dict[str, Any]) -> List[Dict[str, Any]]:
        """è¯†åˆ«å…³é”®ä¿®å¤é¡¹"""
        critical_fixes = []

        # åŸºäºåˆ†æç»“æœè¯†åˆ«æœ€å…³é”®çš„é—®é¢˜
        execution_flow = results.get('execution_flow_analysis', {})
        risk_control = results.get('risk_control_analysis', {})
        trading_issues = results.get('trading_logic_issues', [])
        data_issues = results.get('data_integrity_issues', [])

        # å…³é”®ä¿®å¤é¡¹1ï¼šå¼‚å¸¸å¤„ç†
        error_gaps = execution_flow.get('error_handling_gaps', [])
        if error_gaps:
            critical_fixes.append({
                'priority': 1,
                'category': 'å¼‚å¸¸å¤„ç†',
                'title': 'ä¿®å¤å¼‚å¸¸å¤„ç†ç¼ºé™·',
                'affected_methods': [gap['method'] for gap in error_gaps],
                'risk_level': 'CRITICAL',
                'description': 'å¤šä¸ªå…³é”®æ–¹æ³•å­˜åœ¨è£¸éœ²å¼‚å¸¸å¤„ç†ï¼Œå¯èƒ½éšè—ä¸¥é‡é”™è¯¯'
            })

        # å…³é”®ä¿®å¤é¡¹2ï¼šæ•°æ®å®Œæ•´æ€§
        high_severity_data_issues = [issue for issue in data_issues if issue.get('severity') == 'HIGH']
        if high_severity_data_issues:
            critical_fixes.append({
                'priority': 2,
                'category': 'æ•°æ®å®Œæ•´æ€§',
                'title': 'ä¿®å¤æ•°æ®å®Œæ•´æ€§é—®é¢˜',
                'affected_methods': list(set(issue['file'] for issue in high_severity_data_issues)),
                'risk_level': 'HIGH',
                'description': 'å­˜åœ¨é™¤é›¶é£é™©å’Œæ•°æ®è®¿é—®å®‰å…¨é—®é¢˜'
            })

        # å…³é”®ä¿®å¤é¡¹3ï¼šé£é™©æ§åˆ¶ç¼ºå¤±
        missing_controls = risk_control.get('missing_controls', [])
        if missing_controls:
            critical_fixes.append({
                'priority': 3,
                'category': 'é£é™©æ§åˆ¶',
                'title': 'å®ç°ç¼ºå¤±çš„é£é™©æ§åˆ¶',
                'missing_controls': missing_controls,
                'risk_level': 'HIGH',
                'description': 'ç¼ºå°‘å…³é”®çš„é£é™©æ§åˆ¶æœºåˆ¶'
            })

        return critical_fixes

    def generate_strategy_analysis_report(self, results: Dict[str, Any]) -> str:
        """ç”Ÿæˆç­–ç•¥æ‰§è¡Œåˆ†ææŠ¥å‘Š"""
        report = []
        report.append("# ç­–ç•¥æ‰§è¡Œå’Œé£é™©æ§åˆ¶æ·±åº¦åˆ†ææŠ¥å‘Š")
        report.append("=" * 80)

        # æ‰§è¡Œæ‘˜è¦
        report.append(f"\n## ğŸ“Š æ‰§è¡Œæ‘˜è¦")

        execution_flow = results.get('execution_flow_analysis', {})
        risk_control = results.get('risk_control_analysis', {})
        trading_issues = results.get('trading_logic_issues', [])
        data_issues = results.get('data_integrity_issues', [])
        performance_issues = results.get('performance_issues', [])

        report.append(f"- æ‰§è¡Œæ–¹æ³•åˆ†æ: {len(execution_flow.get('main_execution_methods', []))} ä¸ª")
        report.append(f"- å‘ç°ç“¶é¢ˆç‚¹: {len(execution_flow.get('bottleneck_points', []))} ä¸ª")
        report.append(f"- äº¤æ˜“é€»è¾‘é—®é¢˜: {len(trading_issues)} ä¸ª")
        report.append(f"- æ•°æ®å®Œæ•´æ€§é—®é¢˜: {len(data_issues)} ä¸ª")
        report.append(f"- æ€§èƒ½é—®é¢˜: {len(performance_issues)} ä¸ª")

        # å…³é”®ä¿®å¤é¡¹
        critical_fixes = results.get('critical_fixes_needed', [])
        if critical_fixes:
            report.append(f"\n## ğŸš¨ å…³é”®ä¿®å¤é¡¹")
            for fix in critical_fixes:
                report.append(f"\n### {fix['priority']}. {fix['title']} ({fix['risk_level']})")
                report.append(f"**ç±»åˆ«**: {fix['category']}")
                report.append(f"**æè¿°**: {fix['description']}")

                if 'affected_methods' in fix:
                    methods_str = ", ".join(fix['affected_methods'][:5])
                    if len(fix['affected_methods']) > 5:
                        methods_str += f" ç­‰ {len(fix['affected_methods'])} ä¸ª"
                    report.append(f"**å½±å“æ–¹æ³•**: {methods_str}")

                if 'missing_controls' in fix:
                    report.append(f"**ç¼ºå¤±æ§åˆ¶**: {', '.join(fix['missing_controls'])}")

        # æ‰§è¡Œæµç¨‹åˆ†æ
        if execution_flow:
            report.append(f"\n## ğŸ”„ æ‰§è¡Œæµç¨‹åˆ†æ")

            bottlenecks = execution_flow.get('bottleneck_points', [])
            if bottlenecks:
                report.append(f"\n### æ€§èƒ½ç“¶é¢ˆç‚¹")
                for i, bottleneck in enumerate(bottlenecks[:10], 1):
                    report.append(f"{i}. **{bottleneck['method']}** ({Path(bottleneck['file']).name})")
                    report.append(f"   - åŸå› : {bottleneck['reason']}")

            error_gaps = execution_flow.get('error_handling_gaps', [])
            if error_gaps:
                report.append(f"\n### é”™è¯¯å¤„ç†ç¼ºé™·")
                for i, gap in enumerate(error_gaps[:10], 1):
                    report.append(f"{i}. **{gap['method']}** ({Path(gap['file']).name})")
                    report.append(f"   - é—®é¢˜: {gap['issue']}")

        # é£é™©æ§åˆ¶åˆ†æ
        if risk_control:
            report.append(f"\n## ğŸ›¡ï¸ é£é™©æ§åˆ¶åˆ†æ")

            missing_controls = risk_control.get('missing_controls', [])
            if missing_controls:
                report.append(f"\n### ç¼ºå¤±çš„é£é™©æ§åˆ¶")
                for control in missing_controls:
                    report.append(f"- {control}")

            # åˆ†æå„ç±»é£é™©æ§åˆ¶
            risk_categories = ['position_management', 'stop_loss_logic', 'take_profit_logic', 'risk_metrics_calculation']
            for category in risk_categories:
                methods = risk_control.get(category, [])
                if methods:
                    category_name = category.replace('_', ' ').title()
                    report.append(f"\n### {category_name}")
                    for method in methods[:5]:
                        report.append(f"- **{method['name']}** ({Path(method['file']).name}:{method['line']})")
                        if method.get('potential_issues'):
                            for issue in method['potential_issues']:
                                report.append(f"  âš ï¸ {issue}")

        # äº¤æ˜“é€»è¾‘é—®é¢˜
        if trading_issues:
            report.append(f"\n## ğŸ’° äº¤æ˜“é€»è¾‘é—®é¢˜")

            # æŒ‰ä¸¥é‡ç¨‹åº¦åˆ†ç»„
            high_issues = [issue for issue in trading_issues if issue.get('severity') == 'HIGH']
            medium_issues = [issue for issue in trading_issues if issue.get('severity') == 'MEDIUM']

            if high_issues:
                report.append(f"\n### ğŸ”´ é«˜ä¸¥é‡æ€§é—®é¢˜")
                for i, issue in enumerate(high_issues, 1):
                    report.append(f"{i}. **{issue['type']}** ({Path(issue['file']).name}:{issue['line']})")
                    report.append(f"   - æè¿°: {issue['description']}")
                    report.append(f"   - ä»£ç : `{issue['code']}`")

            if medium_issues:
                report.append(f"\n### ğŸŸ¡ ä¸­ä¸¥é‡æ€§é—®é¢˜")
                for i, issue in enumerate(medium_issues[:5], 1):
                    report.append(f"{i}. **{issue['type']}** ({Path(issue['file']).name}:{issue['line']})")
                    report.append(f"   - æè¿°: {issue['description']}")

        # æ•°æ®å®Œæ•´æ€§é—®é¢˜
        if data_issues:
            report.append(f"\n## ğŸ“‹ æ•°æ®å®Œæ•´æ€§é—®é¢˜")

            high_data_issues = [issue for issue in data_issues if issue.get('severity') == 'HIGH']
            if high_data_issues:
                report.append(f"\n### ğŸ”´ é«˜é£é™©æ•°æ®é—®é¢˜")
                for i, issue in enumerate(high_data_issues, 1):
                    report.append(f"{i}. **{issue['type']}** ({Path(issue['file']).name}:{issue['line']})")
                    report.append(f"   - æè¿°: {issue['description']}")
                    report.append(f"   - ä»£ç : `{issue['code']}`")

        # å®‰å…¨å»ºè®®
        safety_recommendations = results.get('safety_recommendations', [])
        if safety_recommendations:
            report.append(f"\n## ğŸ”’ å®‰å…¨å»ºè®®")

            for rec in safety_recommendations:
                report.append(f"\n### {rec['priority']} - {rec['title']}")
                report.append(f"**ç±»åˆ«**: {rec['category']}")
                report.append(f"**æè¿°**: {rec['description']}")

                if rec.get('implementation'):
                    report.append("**å®æ–½æ­¥éª¤**:")
                    for step in rec['implementation']:
                        report.append(f"- {step}")

        return "\n".join(report)

    def run_analysis_and_save_report(self):
        """è¿è¡Œåˆ†æå¹¶ä¿å­˜æŠ¥å‘Š"""
        try:
            # è¿è¡Œç­–ç•¥æ‰§è¡Œåˆ†æ
            results = self.analyze_strategy_execution()

            # ç”ŸæˆæŠ¥å‘Š
            report = self.generate_strategy_analysis_report(results)

            # ä¿å­˜æŠ¥å‘Š
            with open('strategy_execution_analysis.md', 'w', encoding='utf-8') as f:
                f.write(report)

            # ä¿å­˜åŸå§‹æ•°æ®
            with open('strategy_execution_data.json', 'w', encoding='utf-8') as f:
                json.dump(results, f, indent=2, ensure_ascii=False, default=str)

            # æ˜¾ç¤ºæ‘˜è¦
            print("\n" + "="*80)
            print("ğŸ¯ ç­–ç•¥æ‰§è¡Œå’Œé£é™©æ§åˆ¶åˆ†æç»“æœ")
            print("="*80)

            execution_flow = results.get('execution_flow_analysis', {})
            trading_issues = results.get('trading_logic_issues', [])
            data_issues = results.get('data_integrity_issues', [])
            critical_fixes = results.get('critical_fixes_needed', [])

            print(f"ğŸ“Š åˆ†æç»“æœ:")
            print(f"   æ‰§è¡Œæ–¹æ³•: {len(execution_flow.get('main_execution_methods', []))} ä¸ª")
            print(f"   ç“¶é¢ˆç‚¹: {len(execution_flow.get('bottleneck_points', []))} ä¸ª")
            print(f"   äº¤æ˜“é—®é¢˜: {len(trading_issues)} ä¸ª")
            print(f"   æ•°æ®é—®é¢˜: {len(data_issues)} ä¸ª")

            if critical_fixes:
                print(f"\nğŸš¨ å…³é”®ä¿®å¤é¡¹:")
                for fix in critical_fixes[:3]:
                    print(f"   - {fix['title']} ({fix['risk_level']})")

            logger.info("ğŸ“„ ç­–ç•¥æ‰§è¡Œåˆ†ææŠ¥å‘Šå·²ä¿å­˜åˆ° strategy_execution_analysis.md")
            logger.info("ğŸ“„ åŸå§‹åˆ†ææ•°æ®å·²ä¿å­˜åˆ° strategy_execution_data.json")

            return results

        except Exception as e:
            logger.error(f"ç­–ç•¥æ‰§è¡Œåˆ†æå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return None


def main():
    """ä¸»å‡½æ•°"""
    analyzer = StrategyExecutionAnalyzer()
    return analyzer.run_analysis_and_save_report()


if __name__ == "__main__":
    main()
