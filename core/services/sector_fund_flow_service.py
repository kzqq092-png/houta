"""
æ¿å—èµ„é‡‘æµæ•°æ®æœåŠ¡

æ­¤æ¨¡å—æä¾›ç»Ÿä¸€çš„æ¿å—èµ„é‡‘æµæ•°æ®è®¿é—®æ¥å£ï¼Œæ”¯æŒå¤šæ•°æ®æºåˆ‡æ¢ã€
æ•°æ®ç¼“å­˜ã€å¼‚æ­¥åŠ è½½ç­‰åŠŸèƒ½ã€‚

ä¸»è¦åŠŸèƒ½ï¼š
- æ”¯æŒå¤šæ•°æ®æºï¼ˆAkShareã€ä¸œæ–¹è´¢å¯Œç­‰ï¼‰
- ç»Ÿä¸€çš„æ•°æ®æ ¼å¼å’Œæ¥å£
- æ•°æ®ç¼“å­˜å’Œæ€§èƒ½ä¼˜åŒ–
- å¼‚æ­¥æ•°æ®åŠ è½½
- é”™è¯¯å¤„ç†å’Œé™çº§ç­–ç•¥
"""

import asyncio
import logging
import threading
from typing import Dict, List, Optional, Any, Callable
from datetime import datetime, timedelta
from concurrent.futures import ThreadPoolExecutor
from dataclasses import dataclass

import pandas as pd
from PyQt5.QtCore import QObject, pyqtSignal, QTimer

from ..logger import LogManager
from .unified_data_manager import UnifiedDataManager


@dataclass
class SectorFlowConfig:
    """æ¿å—èµ„é‡‘æµæœåŠ¡é…ç½®"""
    cache_duration_minutes: int = 5  # ç¼“å­˜æŒç»­æ—¶é—´ï¼ˆåˆ†é’Ÿï¼‰
    auto_refresh_interval_minutes: int = 10  # è‡ªåŠ¨åˆ·æ–°é—´éš”ï¼ˆåˆ†é’Ÿï¼‰
    max_concurrent_requests: int = 3  # æœ€å¤§å¹¶å‘è¯·æ±‚æ•°
    request_timeout_seconds: int = 30  # è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
    enable_cache: bool = True  # å¯ç”¨ç¼“å­˜
    enable_auto_refresh: bool = True  # å¯ç”¨è‡ªåŠ¨åˆ·æ–°
    fallback_data_source: str = "akshare"  # é™çº§æ•°æ®æº


class SectorFundFlowService(QObject):
    """æ¿å—èµ„é‡‘æµæ•°æ®æœåŠ¡"""

    # ä¿¡å·å®šä¹‰
    data_updated = pyqtSignal(object)  # æ•°æ®æ›´æ–°ä¿¡å·
    error_occurred = pyqtSignal(str)  # é”™è¯¯ä¿¡å·
    source_changed = pyqtSignal(str)  # æ•°æ®æºå˜æ›´ä¿¡å·

    def __init__(self, data_manager: Optional[UnifiedDataManager] = None,
                 config: Optional[SectorFlowConfig] = None,
                 log_manager: Optional[LogManager] = None):
        """
        åˆå§‹åŒ–æ¿å—èµ„é‡‘æµæœåŠ¡

        Args:
            data_manager: æ•°æ®ç®¡ç†å™¨å®ä¾‹
            config: æœåŠ¡é…ç½®
            log_manager: æ—¥å¿—ç®¡ç†å™¨
        """
        super().__init__()

        # ä½¿ç”¨æ•°æ®ç®¡ç†å™¨å·¥å‚è·å–æ­£ç¡®çš„DataManagerå®ä¾‹
        if data_manager is None:
            try:
                from utils.manager_factory import get_manager_factory, get_data_manager
                factory = get_manager_factory()
                self.data_manager = get_data_manager()
            except ImportError:
                # é™çº§åˆ°ç›´æ¥å¯¼å…¥
                from .unified_data_manager import get_unified_data_manager
                self.data_manager = get_unified_data_manager()
        else:
            self.data_manager = data_manager
        self.config = config or SectorFlowConfig()
        self.log_manager = log_manager or logging.getLogger(__name__)

        # ç¼“å­˜ç®¡ç†
        self._cache: Dict[str, Any] = {}
        self._cache_timestamps: Dict[str, datetime] = {}
        self._cache_lock = threading.RLock()

        # å¼‚æ­¥æ‰§è¡Œå™¨
        self._executor = ThreadPoolExecutor(max_workers=self.config.max_concurrent_requests)

        # è‡ªåŠ¨åˆ·æ–°å®šæ—¶å™¨
        self._refresh_timer = QTimer()
        self._refresh_timer.timeout.connect(self._auto_refresh)

        self._is_initialized = False
        self._current_source = None

    def initialize(self) -> bool:
        """åˆå§‹åŒ–æœåŠ¡"""
        try:
            self.log_manager.info("ğŸš€ åˆå§‹åŒ–æ¿å—èµ„é‡‘æµæœåŠ¡...")
            import time
            start_time = time.time()

            # æ£€æŸ¥æ•°æ®ç®¡ç†å™¨
            self.log_manager.info("ğŸ” æ£€æŸ¥æ•°æ®ç®¡ç†å™¨çŠ¶æ€...")
            if self.data_manager:
                self.log_manager.info("âœ… æ•°æ®ç®¡ç†å™¨å¯ç”¨")
            else:
                self.log_manager.warning("âš ï¸ æ•°æ®ç®¡ç†å™¨ä¸å¯ç”¨")

            # å¯åŠ¨è‡ªåŠ¨åˆ·æ–°
            self.log_manager.info("âš™ï¸ é…ç½®è‡ªåŠ¨åˆ·æ–°è®¾ç½®...")
            if self.config.enable_auto_refresh:
                refresh_start = time.time()
                self._start_auto_refresh()
                refresh_time = time.time()
                self.log_manager.info(f"âœ… è‡ªåŠ¨åˆ·æ–°å¯åŠ¨å®Œæˆï¼Œè€—æ—¶: {(refresh_time - refresh_start):.2f}ç§’")
            else:
                self.log_manager.info("â„¹ï¸ è‡ªåŠ¨åˆ·æ–°å·²ç¦ç”¨")

            # è·å–å½“å‰æ•°æ®æº
            self._current_source = self.data_manager.get_current_source()

            self._is_initialized = True
            self.log_manager.info(f"âœ… æ¿å—èµ„é‡‘æµæœåŠ¡åˆå§‹åŒ–å®Œæˆï¼Œå½“å‰æ•°æ®æº: {self._current_source}")

            return True

        except Exception as e:
            self.log_manager.error(f"âŒ æ¿å—èµ„é‡‘æµæœåŠ¡åˆå§‹åŒ–å¤±è´¥: {e}")
            return False

    def cleanup(self) -> None:
        """æ¸…ç†æœåŠ¡èµ„æº"""
        try:
            self.log_manager.info("ğŸ§¹ æ¸…ç†æ¿å—èµ„é‡‘æµæœåŠ¡...")

            # åœæ­¢è‡ªåŠ¨åˆ·æ–°
            self._refresh_timer.stop()

            # å…³é—­æ‰§è¡Œå™¨
            self._executor.shutdown(wait=True)

            # æ¸…ç†ç¼“å­˜
            with self._cache_lock:
                self._cache.clear()
                self._cache_timestamps.clear()

            self.log_manager.info("âœ… æ¿å—èµ„é‡‘æµæœåŠ¡æ¸…ç†å®Œæˆ")

        except Exception as e:
            self.log_manager.error(f"âŒ æ¸…ç†æ¿å—èµ„é‡‘æµæœåŠ¡å¤±è´¥: {e}")

    def get_sector_flow_rank(self, indicator: str = "ä»Šæ—¥", force_refresh: bool = False) -> pd.DataFrame:
        """è·å–æ¿å—èµ„é‡‘æµæ’è¡Œ

        Args:
            indicator: æ—¶é—´å‘¨æœŸï¼ˆä»Šæ—¥ã€3æ—¥ã€5æ—¥ã€10æ—¥ã€20æ—¥ï¼‰
            force_refresh: æ˜¯å¦å¼ºåˆ¶åˆ·æ–°ç¼“å­˜

        Returns:
            pd.DataFrame: æ¿å—èµ„é‡‘æµæ’è¡Œæ•°æ®
        """
        cache_key = f"sector_flow_rank_{indicator}"

        try:
            # æ£€æŸ¥ç¼“å­˜
            if not force_refresh and self._is_cache_valid(cache_key):
                self.log_manager.info(f"ğŸ“‹ ä½¿ç”¨ç¼“å­˜çš„æ¿å—èµ„é‡‘æµæ’è¡Œæ•°æ®: {indicator}")
                return self._get_from_cache(cache_key)

            self.log_manager.info(f"ğŸ”„ è·å–æ¿å—èµ„é‡‘æµæ’è¡Œæ•°æ®: {indicator}")

            # ä»æ•°æ®ç®¡ç†å™¨è·å–æ•°æ®
            fund_flow_data = self.data_manager.get_fund_flow()

            if fund_flow_data and 'sector_flow_rank' in fund_flow_data:
                df = fund_flow_data['sector_flow_rank']

                # æ•°æ®æ ‡å‡†åŒ–å¤„ç†
                df = self._standardize_sector_flow_data(df)

                # æ›´æ–°ç¼“å­˜
                self._update_cache(cache_key, df)

                self.log_manager.info(f"âœ… æ¿å—èµ„é‡‘æµæ’è¡Œæ•°æ®è·å–æˆåŠŸ: {len(df)} æ¡è®°å½•")
                self.data_updated.emit({'type': 'sector_flow_rank', 'data': df})

                return df
            else:
                self.log_manager.warning("âš ï¸ æœªè·å–åˆ°æ¿å—èµ„é‡‘æµæ’è¡Œæ•°æ®")
                return pd.DataFrame()

        except Exception as e:
            self.log_manager.error(f"âŒ è·å–æ¿å—èµ„é‡‘æµæ’è¡Œå¤±è´¥: {e}")
            self.error_occurred.emit(f"è·å–æ¿å—èµ„é‡‘æµæ’è¡Œå¤±è´¥: {str(e)}")
            return pd.DataFrame()

    def get_sector_flow_summary(self, symbol: str, indicator: str = "ä»Šæ—¥") -> pd.DataFrame:
        """è·å–æ¿å—èµ„é‡‘æµæ±‡æ€»

        Args:
            symbol: æ¿å—åç§°
            indicator: æ—¶é—´å‘¨æœŸ

        Returns:
            pd.DataFrame: æ¿å—èµ„é‡‘æµæ±‡æ€»æ•°æ®
        """
        try:
            df = self.data_manager.get_sector_fund_flow_summary(symbol, indicator)
            self.log_manager.info(f"âœ… æ¿å—èµ„é‡‘æµæ±‡æ€»è·å–æˆåŠŸ: {symbol}, {len(df)} æ¡è®°å½•")
            return df

        except Exception as e:
            self.log_manager.error(f"âŒ è·å–æ¿å—èµ„é‡‘æµæ±‡æ€»å¤±è´¥: {e}")
            return pd.DataFrame()

    def get_sector_flow_history(self, symbol: str, period: str = "è¿‘6æœˆ") -> pd.DataFrame:
        """è·å–æ¿å—å†å²èµ„é‡‘æµ

        Args:
            symbol: æ¿å—åç§°
            period: æ—¶é—´å‘¨æœŸ

        Returns:
            pd.DataFrame: æ¿å—å†å²èµ„é‡‘æµæ•°æ®
        """
        try:
            df = self.data_manager.get_sector_fund_flow_hist(symbol, period)
            self.log_manager.info(f"âœ… æ¿å—å†å²èµ„é‡‘æµè·å–æˆåŠŸ: {symbol}, {len(df)} æ¡è®°å½•")
            return df

        except Exception as e:
            self.log_manager.error(f"âŒ è·å–æ¿å—å†å²èµ„é‡‘æµå¤±è´¥: {e}")
            return pd.DataFrame()

    def get_concept_flow_history(self, symbol: str, period: str = "è¿‘6æœˆ") -> pd.DataFrame:
        """è·å–æ¦‚å¿µå†å²èµ„é‡‘æµ

        Args:
            symbol: æ¦‚å¿µåç§°
            period: æ—¶é—´å‘¨æœŸ

        Returns:
            pd.DataFrame: æ¦‚å¿µå†å²èµ„é‡‘æµæ•°æ®
        """
        try:
            df = self.data_manager.get_concept_fund_flow_hist(symbol, period)
            self.log_manager.info(f"âœ… æ¦‚å¿µå†å²èµ„é‡‘æµè·å–æˆåŠŸ: {symbol}, {len(df)} æ¡è®°å½•")
            return df

        except Exception as e:
            self.log_manager.error(f"âŒ è·å–æ¦‚å¿µå†å²èµ„é‡‘æµå¤±è´¥: {e}")
            return pd.DataFrame()

    def switch_data_source(self, source: str) -> bool:
        """åˆ‡æ¢æ•°æ®æº

        Args:
            source: æ•°æ®æºåç§°

        Returns:
            bool: æ˜¯å¦åˆ‡æ¢æˆåŠŸ
        """
        try:
            self.log_manager.info(f"ğŸ”„ åˆ‡æ¢æ•°æ®æºåˆ°: {source}")

            # åˆ‡æ¢æ•°æ®ç®¡ç†å™¨çš„æ•°æ®æº
            self.data_manager.set_data_source(source)
            self._current_source = source

            # æ¸…ç†ç¼“å­˜
            self._clear_cache()

            self.log_manager.info(f"âœ… æ•°æ®æºåˆ‡æ¢æˆåŠŸ: {source}")
            self.source_changed.emit(source)

            return True

        except Exception as e:
            self.log_manager.error(f"âŒ æ•°æ®æºåˆ‡æ¢å¤±è´¥: {e}")
            self.error_occurred.emit(f"æ•°æ®æºåˆ‡æ¢å¤±è´¥: {str(e)}")
            return False

    def _standardize_sector_flow_data(self, df: pd.DataFrame) -> pd.DataFrame:
        """æ ‡å‡†åŒ–æ¿å—èµ„é‡‘æµæ•°æ®æ ¼å¼"""
        try:
            # æ ‡å‡†åŒ–åˆ—å
            column_mapping = {
                'æ¿å—': 'sector_name',
                'ä»Šæ—¥ä¸»åŠ›å‡€æµå…¥-å‡€é¢': 'main_net_inflow',
                'ä»Šæ—¥ä¸»åŠ›å‡€æµå…¥-å‡€å æ¯”': 'main_net_inflow_ratio',
                'ä»Šæ—¥æ•£æˆ·å‡€æµå…¥-å‡€é¢': 'retail_net_inflow',
                'ä»Šæ—¥æ•£æˆ·å‡€æµå…¥-å‡€å æ¯”': 'retail_net_inflow_ratio',
                'ä»Šæ—¥æ¶¨è·Œå¹…': 'change_pct'
            }

            # é‡å‘½ååˆ—
            for old_col, new_col in column_mapping.items():
                if old_col in df.columns:
                    df = df.rename(columns={old_col: new_col})

            # æ•°æ®ç±»å‹è½¬æ¢
            numeric_columns = ['main_net_inflow', 'main_net_inflow_ratio',
                               'retail_net_inflow', 'retail_net_inflow_ratio', 'change_pct']

            for col in numeric_columns:
                if col in df.columns:
                    df[col] = pd.to_numeric(df[col], errors='coerce')

            return df

        except Exception as e:
            self.log_manager.warning(f"âš ï¸ æ•°æ®æ ‡å‡†åŒ–å¤±è´¥: {e}")
            return df

    def _is_cache_valid(self, cache_key: str) -> bool:
        """æ£€æŸ¥ç¼“å­˜æ˜¯å¦æœ‰æ•ˆ"""
        if not self.config.enable_cache:
            return False

        with self._cache_lock:
            if cache_key not in self._cache_timestamps:
                return False

            cache_time = self._cache_timestamps[cache_key]
            cache_duration = timedelta(minutes=self.config.cache_duration_minutes)

            return datetime.now() - cache_time < cache_duration

    def _get_from_cache(self, cache_key: str) -> Any:
        """ä»ç¼“å­˜è·å–æ•°æ®"""
        with self._cache_lock:
            return self._cache.get(cache_key)

    def _update_cache(self, cache_key: str, data: Any) -> None:
        """æ›´æ–°ç¼“å­˜"""
        if self.config.enable_cache:
            with self._cache_lock:
                self._cache[cache_key] = data
                self._cache_timestamps[cache_key] = datetime.now()

    def _clear_cache(self) -> None:
        """æ¸…ç†ç¼“å­˜"""
        with self._cache_lock:
            self._cache.clear()
            self._cache_timestamps.clear()
        self.log_manager.info("ğŸ—‘ï¸ ç¼“å­˜å·²æ¸…ç†")

    def _start_auto_refresh(self) -> None:
        """å¯åŠ¨è‡ªåŠ¨åˆ·æ–°"""
        if self.config.auto_refresh_interval_minutes > 0:
            interval_ms = self.config.auto_refresh_interval_minutes * 60 * 1000
            self._refresh_timer.start(interval_ms)
            self.log_manager.info(f"ğŸ”„ å¯åŠ¨è‡ªåŠ¨åˆ·æ–°ï¼Œé—´éš” {self.config.auto_refresh_interval_minutes} åˆ†é’Ÿ")

    def _auto_refresh(self) -> None:
        """è‡ªåŠ¨åˆ·æ–°æ•°æ®ï¼ˆåå°çº¿ç¨‹æ‰§è¡Œï¼Œé¿å…é˜»å¡UIçº¿ç¨‹ï¼‰"""
        try:
            self.log_manager.info("â° è°ƒåº¦è‡ªåŠ¨åˆ·æ–°ä»»åŠ¡...")
            # å°†å®é™…åˆ·æ–°ä»»åŠ¡æ”¾å…¥çº¿ç¨‹æ± ï¼Œé¿å…åœ¨Qtå®šæ—¶å™¨å›è°ƒï¼ˆä¸»çº¿ç¨‹ï¼‰ä¸­æ‰§è¡Œé‡IO/CPUå·¥ä½œ
            self._executor.submit(self._run_auto_refresh_task)
        except Exception as e:
            self.log_manager.error(f"âŒ è‡ªåŠ¨åˆ·æ–°è°ƒåº¦å¤±è´¥: {e}")

    def _run_auto_refresh_task(self) -> None:
        """å®é™…çš„è‡ªåŠ¨åˆ·æ–°ä»»åŠ¡ï¼Œåœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡Œ"""
        try:
            # è¿™é‡Œç›´æ¥è°ƒç”¨ç°æœ‰æ–¹æ³•å³å¯ï¼›è¯¥æ–¹æ³•å†…éƒ¨ä¼šé€šè¿‡Qtä¿¡å·é€šçŸ¥æ•°æ®æ›´æ–°
            self.get_sector_flow_rank(force_refresh=True)
        except Exception as e:
            self.log_manager.error(f"âŒ è‡ªåŠ¨åˆ·æ–°ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {e}")

    def get_service_status(self) -> Dict[str, Any]:
        """è·å–æœåŠ¡çŠ¶æ€"""
        return {
            'is_initialized': self._is_initialized,
            'current_source': self._current_source,
            'cache_enabled': self.config.enable_cache,
            'auto_refresh_enabled': self.config.enable_auto_refresh,
            'cache_size': len(self._cache) if self.config.enable_cache else 0
        }
