"""
ç»Ÿä¸€æ•°æ®ç®¡ç†å™¨

è´Ÿè´£åè°ƒå„æœåŠ¡çš„æ•°æ®åŠ è½½è¯·æ±‚ï¼Œé¿å…é‡å¤æ•°æ®åŠ è½½ï¼Œæä¾›ç»Ÿä¸€çš„æ•°æ®è®¿é—®æ¥å£ã€‚
"""

import logging
import threading
import time
from typing import Dict, Any, Optional, List, Callable, Set
from datetime import datetime, timedelta
from concurrent.futures import ThreadPoolExecutor, Future
from dataclasses import dataclass
from enum import Enum
import pandas as pd
import asyncio
from asyncio import Future as AsyncioFuture

from ..events import EventBus, DataUpdateEvent
from ..containers import ServiceContainer, get_service_container
from ..plugin_types import AssetType, DataType
from ..tet_data_pipeline import TETDataPipeline, StandardQuery, StandardData, create_tet_pipeline

logger = logging.getLogger(__name__)


def get_unified_data_manager() -> Optional['UnifiedDataManager']:
    """
    è·å–ç»Ÿä¸€æ•°æ®ç®¡ç†å™¨çš„å®ä¾‹

    Returns:
        ç»Ÿä¸€æ•°æ®ç®¡ç†å™¨å®ä¾‹ï¼Œå¦‚æœæœªæ³¨å†Œåˆ™è¿”å›None
    """
    try:
        container = get_service_container()
        if container:
            return container.resolve(UnifiedDataManager)
        return None
    except Exception as e:
        logger.error(f"è·å–ç»Ÿä¸€æ•°æ®ç®¡ç†å™¨å¤±è´¥: {e}")
        return None


class DataRequestStatus(Enum):
    """æ•°æ®è¯·æ±‚çŠ¶æ€"""
    PENDING = "pending"
    LOADING = "loading"
    COMPLETED = "completed"
    FAILED = "failed"
    CANCELLED = "cancelled"


@dataclass
class DataRequest:
    """æ•°æ®è¯·æ±‚"""
    request_id: str
    symbol: str  # ç»Ÿä¸€ä½¿ç”¨symbolæ›¿ä»£stock_code
    asset_type: AssetType = AssetType.STOCK  # æ–°å¢èµ„äº§ç±»å‹æ”¯æŒ
    data_type: str = 'kdata'  # 'kdata', 'indicators', 'analysis'
    period: str = 'D'
    time_range: int = 365
    parameters: Dict[str, Any] = None
    priority: int = 0  # 0=é«˜ä¼˜å…ˆçº§, 1=ä¸­ä¼˜å…ˆçº§, 2=ä½ä¼˜å…ˆçº§
    future: Optional[AsyncioFuture] = None  # ç”¨äºasync/await
    timestamp: float = 0
    status: DataRequestStatus = DataRequestStatus.PENDING

    # å‘åå…¼å®¹å±æ€§
    @property
    def stock_code(self) -> str:
        """å‘åå…¼å®¹ï¼šè‚¡ç¥¨ä»£ç """
        return self.symbol

    @stock_code.setter
    def stock_code(self, value: str):
        """å‘åå…¼å®¹ï¼šè®¾ç½®è‚¡ç¥¨ä»£ç """
        self.symbol = value

    def __post_init__(self):
        if self.timestamp == 0:
            self.timestamp = time.time()
        if self.parameters is None:
            self.parameters = {}

    def __eq__(self, other):
        if not isinstance(other, DataRequest):
            return NotImplemented
        return (self.symbol == other.symbol and
                self.asset_type == other.asset_type and
                self.data_type == other.data_type and
                self.period == other.period and
                self.time_range == other.time_range and
                self.parameters == other.parameters)

    def __hash__(self):
        # The hash should be based on the immutable fields that define the request's identity
        # Note: self.parameters is mutable, so we convert it to a string representation of its items
        param_tuple = tuple(sorted((self.parameters or {}).items()))
        return hash((self.symbol,
                     self.asset_type,
                     self.data_type,
                     self.period,
                     self.time_range,
                     param_tuple))


class UnifiedDataManager:
    """
    ç»Ÿä¸€æ•°æ®ç®¡ç†å™¨

    åŠŸèƒ½ï¼š
    1. åè°ƒæ•°æ®åŠ è½½è¯·æ±‚
    2. é¿å…é‡å¤æ•°æ®åŠ è½½  
    3. æä¾›ç»Ÿä¸€çš„æ•°æ®è®¿é—®æ¥å£
    4. ç®¡ç†æ•°æ®ç¼“å­˜
    5. ä¼˜åŒ–æ•°æ®åŠ è½½æ€§èƒ½
    6. æ”¯æŒTETæ•°æ®ç®¡é“ï¼ˆTransform-Extract-Transformï¼‰
    7. å¤šèµ„äº§ç±»å‹æ•°æ®å¤„ç†
    """

    def __init__(self, service_container: ServiceContainer, event_bus: EventBus, max_workers: int = 3):
        """
        åˆå§‹åŒ–ç»Ÿä¸€æ•°æ®ç®¡ç†å™¨

        Args:
            service_container: æœåŠ¡å®¹å™¨
            event_bus: äº‹ä»¶æ€»çº¿
            max_workers: æœ€å¤§å·¥ä½œçº¿ç¨‹æ•°
        """
        self.service_container = service_container
        self.event_bus = event_bus
        self.loop = None  # å»¶è¿Ÿåˆå§‹åŒ–ï¼Œåœ¨å¼‚æ­¥æ–¹æ³•ä¸­è·å–

        # çº¿ç¨‹æ± 
        self._executor = ThreadPoolExecutor(
            max_workers=max_workers, thread_name_prefix="DataManager")

        # è¯·æ±‚ç®¡ç†
        self._pending_requests: Dict[str, DataRequest] = {}
        self._active_requests: Dict[str, DataRequest] = {}
        self._completed_requests: Dict[str, DataRequest] = {}
        self._request_lock = threading.Lock()

        # æ•°æ®ç¼“å­˜
        self._data_cache: Dict[str, Any] = {}
        self._cache_timestamps: Dict[str, float] = {}
        self._cache_lock = threading.Lock()
        self._cache_ttl = 300  # 5åˆ†é’Ÿç¼“å­˜TTL

        # å»é‡æœºåˆ¶
        self._request_dedup: Dict[str, Set[DataRequest]] = {}  # è¯·æ±‚é”® -> è¯·æ±‚IDé›†åˆ
        self._dedup_lock = threading.Lock()

        # è¯·æ±‚è·Ÿè¸ªå™¨ - ç”¨äºå–æ¶ˆè¯·æ±‚
        self.request_tracker: Dict[str, Dict[str, Any]] = {}
        self.request_tracker_lock = threading.Lock()

        # æ•°æ®ç­–ç•¥
        self.history_data_strategy = HistoryDataStrategy()
        self.realtime_data_strategy = RealtimeDataStrategy()

        # ç»Ÿè®¡ä¿¡æ¯
        self._stats = {
            'requests_total': 0,
            'requests_deduplicated': 0,
            'requests_completed': 0,
            'requests_failed': 0,
            'requests_cancelled': 0,
            'cache_hits': 0,
            'cache_misses': 0
        }

        # æ•°æ®æºè·¯ç”±å™¨
        self.data_source_router = None
        self._initialize_data_source_router()

        # TETæ•°æ®ç®¡é“æ”¯æŒ
        self.tet_pipeline: Optional[TETDataPipeline] = None
        self.tet_enabled = False
        self._initialize_tet_pipeline()

        logger.info("Unified data manager initialized")

    def _initialize_data_source_router(self):
        """åˆå§‹åŒ–æ•°æ®æºè·¯ç”±å™¨"""
        try:
            from ..data_source_router import DataSourceRouter
            self.data_source_router = DataSourceRouter()
            logger.info("âœ… æ•°æ®æºè·¯ç”±å™¨å·²åˆå§‹åŒ–")
        except Exception as e:
            logger.warning(f"âš ï¸ æ•°æ®æºè·¯ç”±å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            self.data_source_router = None

    def _initialize_tet_pipeline(self):
        """åˆå§‹åŒ–TETæ•°æ®ç®¡é“"""
        try:
            logger.info("ğŸ”§ æ­£åœ¨åˆå§‹åŒ–TETæ•°æ®ç®¡é“...")

            # å°è¯•è·å–æ•°æ®æºè·¯ç”±å™¨
            if hasattr(self, 'data_source_router') and self.data_source_router:
                router = self.data_source_router
                logger.info("âœ… ä½¿ç”¨æœ¬åœ°æ•°æ®æºè·¯ç”±å™¨")
            else:
                # ä»æœåŠ¡å®¹å™¨è·å–
                logger.info("ğŸ” å°è¯•ä»æœåŠ¡å®¹å™¨è·å–æ•°æ®æºè·¯ç”±å™¨...")
                from ..data_source_router import DataSourceRouter
                try:
                    router = self.service_container.resolve(DataSourceRouter)
                    logger.info("âœ… ä»æœåŠ¡å®¹å™¨è·å–æ•°æ®æºè·¯ç”±å™¨æˆåŠŸ")
                except Exception as resolve_error:
                    logger.warning(f"âš ï¸ ä»æœåŠ¡å®¹å™¨è·å–æ•°æ®æºè·¯ç”±å™¨å¤±è´¥: {resolve_error}")
                    router = None

            if router:
                # æ£€æŸ¥è·¯ç”±å™¨ä¸­çš„æ•°æ®æºæ•°é‡
                source_count = len(router.data_sources) if hasattr(router, 'data_sources') else 0
                logger.info(f"ğŸ“Š æ•°æ®æºè·¯ç”±å™¨çŠ¶æ€: {source_count} ä¸ªæ•°æ®æºå·²æ³¨å†Œ")

                from ..tet_data_pipeline import create_tet_pipeline
                self.tet_pipeline = create_tet_pipeline(router)
                self.tet_enabled = True
                logger.info("ğŸ‰ TETæ•°æ®ç®¡é“å·²æˆåŠŸå¯ç”¨ï¼")
                logger.info(f"ğŸš€ TETæ¨¡å¼å·²æ¿€æ´»ï¼Œæ”¯æŒå¤šèµ„äº§ç±»å‹æ•°æ®å¤„ç†")
            else:
                logger.warning("âŒ æ•°æ®æºè·¯ç”±å™¨ä¸å¯ç”¨ï¼ŒTETç®¡é“æœªå¯ç”¨")
                logger.warning("ğŸ’¡ å»ºè®®æ£€æŸ¥æ’ä»¶ç®¡ç†å™¨å’Œæ•°æ®æºæ³¨å†Œ")
                self.tet_enabled = False

        except Exception as e:
            logger.error(f"âŒ TETæ•°æ®ç®¡é“åˆå§‹åŒ–å¤±è´¥: {e}")
            logger.error("ğŸ”„ å°†ä½¿ç”¨ä¼ ç»Ÿæ•°æ®è·å–æ¨¡å¼")
            import traceback
            logger.debug(traceback.format_exc())
            self.tet_enabled = False

    def get_asset_list(self, asset_type: AssetType, market: str = None) -> List[Dict[str, Any]]:
        """
        è·å–èµ„äº§åˆ—è¡¨ï¼ˆTETæ¨¡å¼ï¼‰

        Args:
            asset_type: èµ„äº§ç±»å‹
            market: å¸‚åœºè¿‡æ»¤

        Returns:
            List[Dict]: æ ‡å‡†åŒ–çš„èµ„äº§åˆ—è¡¨
        """
        if self.tet_enabled and self.tet_pipeline:
            try:
                query = StandardQuery(
                    symbol="",  # èµ„äº§åˆ—è¡¨æŸ¥è¯¢ä¸éœ€è¦å…·ä½“symbol
                    asset_type=asset_type,
                    data_type=DataType.ASSET_LIST,
                    market=market
                )

                result = self.tet_pipeline.process(query)
                return self._format_asset_list(result.data)

            except Exception as e:
                logger.warning(f"TETæ¨¡å¼è·å–èµ„äº§åˆ—è¡¨å¤±è´¥: {e}")

        # é™çº§åˆ°ä¼ ç»Ÿæ–¹å¼
        return self._legacy_get_asset_list(asset_type, market)

    def get_asset_data(self, symbol: str, asset_type: AssetType = AssetType.STOCK,
                       data_type: DataType = DataType.HISTORICAL_KLINE,
                       period: str = "D", **kwargs) -> Optional[pd.DataFrame]:
        """
        è·å–èµ„äº§æ•°æ®ï¼ˆTETæ¨¡å¼ï¼‰

        Args:
            symbol: äº¤æ˜“ä»£ç 
            asset_type: èµ„äº§ç±»å‹
            data_type: æ•°æ®ç±»å‹
            period: å‘¨æœŸ
            **kwargs: å…¶ä»–å‚æ•°

        Returns:
            Optional[pd.DataFrame]: æ ‡å‡†åŒ–æ•°æ®
        """
        if self.tet_enabled and self.tet_pipeline:
            try:
                logger.info(f"ğŸš€ ä½¿ç”¨TETæ¨¡å¼è·å–æ•°æ®: {symbol} ({asset_type.value})")

                query = StandardQuery(
                    symbol=symbol,
                    asset_type=asset_type,
                    data_type=data_type,
                    period=period,
                    **kwargs
                )

                result = self.tet_pipeline.process(query)

                # è®°å½•ä½¿ç”¨çš„æ•°æ®æº
                if result and hasattr(result, 'source_info') and result.source_info:
                    data_source = result.source_info.get('provider', 'Unknown')
                    logger.info(f"âœ… TETæ•°æ®è·å–æˆåŠŸ: {symbol} | æ•°æ®æº: {data_source} | è®°å½•æ•°: {len(result.data) if result.data is not None else 0}")
                else:
                    logger.info(f"âœ… TETæ•°æ®è·å–æˆåŠŸ: {symbol} | è®°å½•æ•°: {len(result.data) if result.data is not None else 0}")

                return result.data

            except Exception as e:
                logger.warning(f"âŒ TETæ¨¡å¼è·å–æ•°æ®å¤±è´¥: {symbol} - {e}")
                logger.info("ğŸ”„ é™çº§åˆ°ä¼ ç»Ÿæ•°æ®è·å–æ¨¡å¼")

        # é™çº§åˆ°ä¼ ç»Ÿæ–¹å¼
        if asset_type == AssetType.STOCK:
            logger.info(f"ğŸ“Š ä½¿ç”¨ä¼ ç»Ÿæ¨¡å¼è·å–è‚¡ç¥¨æ•°æ®: {symbol}")
            data = self._legacy_get_stock_data(symbol, period, **kwargs)
            if data is not None:
                logger.info(f"âœ… ä¼ ç»Ÿæ¨¡å¼æ•°æ®è·å–æˆåŠŸ: {symbol} | æ•°æ®æº: HIkyuu/DataAccess | è®°å½•æ•°: {len(data)}")
            else:
                logger.warning(f"âŒ ä¼ ç»Ÿæ¨¡å¼æ•°æ®è·å–å¤±è´¥: {symbol}")
            return data
        else:
            logger.warning(f"âŒ ä¼ ç»Ÿæ¨¡å¼ä¸æ”¯æŒèµ„äº§ç±»å‹: {asset_type.value} | å»ºè®®å¯ç”¨TETæ¨¡å¼")
            return None

    def _format_asset_list(self, asset_data: pd.DataFrame) -> List[Dict[str, Any]]:
        """æ ¼å¼åŒ–èµ„äº§åˆ—è¡¨ä¸ºæ ‡å‡†æ ¼å¼"""
        if asset_data.empty:
            return []

        result = []
        for _, row in asset_data.iterrows():
            result.append({
                'symbol': row.get('symbol', ''),
                'name': row.get('name', ''),
                'asset_type': row.get('asset_type', ''),
                'market': row.get('market', ''),
                'status': row.get('status', 'active')
            })

        return result

    def _legacy_get_asset_list(self, asset_type: AssetType, market: str = None) -> List[Dict[str, Any]]:
        """ä¼ ç»Ÿæ–¹å¼è·å–èµ„äº§åˆ—è¡¨"""
        try:
            if asset_type == AssetType.STOCK:
                # ä½¿ç”¨ä¼ ç»Ÿçš„è‚¡ç¥¨æ•°æ®è·å–æ–¹å¼
                from ..data.data_access import DataAccess
                data_access = DataAccess()
                stock_list = data_access.get_stock_list()

                result = []
                for stock in stock_list:
                    result.append({
                        'symbol': stock.get('code', ''),
                        'name': stock.get('name', ''),
                        'asset_type': 'STOCK',
                        'market': stock.get('market', market or ''),
                        'status': 'active'
                    })
                return result
            else:
                logger.warning(f"ä¼ ç»Ÿæ¨¡å¼ä¸æ”¯æŒèµ„äº§ç±»å‹: {asset_type.value}")
                return []

        except Exception as e:
            logger.error(f"ä¼ ç»Ÿæ–¹å¼è·å–èµ„äº§åˆ—è¡¨å¤±è´¥: {e}")
            return []

    def _legacy_get_stock_data(self, symbol: str, period: str = "D", **kwargs) -> Optional[pd.DataFrame]:
        """ä¼ ç»Ÿæ–¹å¼è·å–è‚¡ç¥¨æ•°æ®"""
        try:
            # ä½¿ç”¨ç°æœ‰çš„è‚¡ç¥¨æ•°æ®è·å–é€»è¾‘
            from ..data.data_access import DataAccess
            data_access = DataAccess()
            return data_access.get_kdata(symbol, period)
        except Exception as e:
            logger.error(f"ä¼ ç»Ÿæ–¹å¼è·å–è‚¡ç¥¨æ•°æ®å¤±è´¥: {e}")
            return None

    async def get_stock_data(self, code: str, freq: str, start_date=None, end_date=None, request_id=None):
        """ç»Ÿä¸€çš„æ•°æ®è¯·æ±‚æ–¹æ³•ï¼ŒåŒºåˆ†å†å²å’Œå®æ—¶æ•°æ®"""
        if request_id:
            self._register_request(request_id)

        try:
            # æ£€æŸ¥æ˜¯å¦éœ€è¦å®æ—¶æ•°æ®
            if self._needs_realtime_data(end_date):
                return await self.realtime_data_strategy.get_data(code, freq, start_date, end_date)
            else:
                return await self.history_data_strategy.get_data(code, freq, start_date, end_date)
        except Exception as e:
            logger.error(f"Error fetching data for {code}: {e}")
            return None
        finally:
            if request_id:
                self._unregister_request(request_id)

    def _needs_realtime_data(self, end_date=None):
        """åˆ¤æ–­æ˜¯å¦éœ€è¦å®æ—¶æ•°æ®"""
        if end_date is None:
            # æ²¡æœ‰æŒ‡å®šç»“æŸæ—¥æœŸï¼Œéœ€è¦å®æ—¶æ•°æ®
            return True

        # å¦‚æœç»“æŸæ—¥æœŸæ˜¯ä»Šå¤©æˆ–æœªæ¥ï¼Œéœ€è¦å®æ—¶æ•°æ®
        today = datetime.now().date()
        if isinstance(end_date, str):
            try:
                end_date = datetime.strptime(end_date, "%Y-%m-%d").date()
            except:
                return True

        if isinstance(end_date, datetime):
            end_date = end_date.date()

        return end_date >= today

    async def request_data(self, stock_code: str, data_type: str = 'kdata',
                           period: str = 'D', time_range: str = "æœ€è¿‘1å¹´", **kwargs) -> Any:
        """è¯·æ±‚æ•°æ®

        Args:
            stock_code: è‚¡ç¥¨ä»£ç 
            data_type: æ•°æ®ç±»å‹ï¼Œå¦‚'kdata', 'financial', 'news'ç­‰
            period: å‘¨æœŸï¼Œå¦‚'D'(æ—¥çº¿)ã€'W'(å‘¨çº¿)ã€'M'(æœˆçº¿)ã€'60'(60åˆ†é’Ÿ)ç­‰
            time_range: æ—¶é—´èŒƒå›´ï¼Œå¦‚"æœ€è¿‘7å¤©"ã€"æœ€è¿‘30å¤©"ã€"æœ€è¿‘1å¹´"ç­‰
            **kwargs: å…¶ä»–å‚æ•°

        Returns:
            è¯·æ±‚çš„æ•°æ®
        """
        try:
            # å¤„ç†å‘¨æœŸæ˜ å°„
            period_map = {
                'åˆ†æ—¶': 'min',
                'æ—¥çº¿': 'D',
                'å‘¨çº¿': 'W',
                'æœˆçº¿': 'M',
                '5åˆ†é’Ÿ': '5',
                '15åˆ†é’Ÿ': '15',
                '30åˆ†é’Ÿ': '30',
                '60åˆ†é’Ÿ': '60'
            }

            # å¦‚æœperiodæ˜¯ä¸­æ–‡æè¿°ï¼Œè½¬æ¢ä¸ºå¯¹åº”ä»£ç 
            actual_period = period_map.get(period, period)

            # å¤„ç†æ—¶é—´èŒƒå›´æ˜ å°„ï¼ˆè½¬æ¢ä¸ºå¤©æ•°ï¼‰
            time_range_map = {
                "æœ€è¿‘7å¤©": 7,
                "æœ€è¿‘30å¤©": 30,
                "æœ€è¿‘90å¤©": 90,
                "æœ€è¿‘180å¤©": 180,
                "æœ€è¿‘1å¹´": 365,
                "æœ€è¿‘2å¹´": 365 * 2,
                "æœ€è¿‘3å¹´": 365 * 3,
                "æœ€è¿‘5å¹´": 365 * 5,
                "å…¨éƒ¨": -1  # è¡¨ç¤ºæ‰€æœ‰å¯ç”¨æ•°æ®
            }

            # è·å–å¤©æ•°ï¼Œé»˜è®¤ä¸º365å¤©ï¼ˆçº¦1å¹´ï¼‰
            count = time_range_map.get(time_range, 365)

            logger.info(f"è¯·æ±‚æ•°æ®ï¼šè‚¡ç¥¨={stock_code}, ç±»å‹={data_type}, å‘¨æœŸ={actual_period}, æ—¶é—´èŒƒå›´={count}å¤©")

            if data_type == 'kdata':
                # è·å–Kçº¿æ•°æ®
                return await self._get_kdata(stock_code, period=actual_period, count=count)
            elif data_type == 'financial':
                # è·å–è´¢åŠ¡æ•°æ®
                return await self._get_financial_data(stock_code)
            elif data_type == 'news':
                # è·å–æ–°é—»æ•°æ®
                return await self._get_news(stock_code)
            elif data_type == 'all':
                # è·å–æ‰€æœ‰æ•°æ®
                kdata = await self._get_kdata(stock_code, period=actual_period, count=count)
                financial = await self._get_financial_data(stock_code)
                news = await self._get_news(stock_code)
                return {
                    'kdata': kdata,
                    'financial': financial,
                    'news': news
                }
            else:
                logger.error(f"æœªçŸ¥çš„æ•°æ®ç±»å‹: {data_type}")
                return None
        except Exception as e:
            logger.error(f"è¯·æ±‚æ•°æ®å¤±è´¥: {e}", exc_info=True)
            return None

    async def _get_kdata(self, stock_code: str, period: str = 'D', count: int = 365) -> pd.DataFrame:
        """è·å–Kçº¿æ•°æ®

        Args:
            stock_code: è‚¡ç¥¨ä»£ç 
            period: å‘¨æœŸï¼Œå¦‚'D'ã€'W'ã€'M'
            count: è·å–çš„å¤©æ•°

        Returns:
            Kçº¿DataFrame
        """
        try:
            logger.info(f"è·å–Kçº¿æ•°æ®: {stock_code}, å‘¨æœŸ={period}, æ•°é‡={count}")

            # å°è¯•ä»æœåŠ¡å®¹å™¨è§£æChartService
            from core.services.chart_service import ChartService
            chart_service = self.service_container.resolve(ChartService)

            if chart_service:
                return chart_service.get_kdata(stock_code, period, count)

            # å¦‚æœæ²¡æœ‰ChartServiceï¼Œå°è¯•ä½¿ç”¨æ•°æ®æºç›´æ¥è·å–
            from core.data_manager import get_data_manager
            data_manager = get_data_manager()

            if data_manager:
                return data_manager.get_kdata(stock_code, period, count)

            logger.error("æ— æ³•è·å–Kçº¿æ•°æ®ï¼šæœªæ‰¾åˆ°æ•°æ®æœåŠ¡")
            return pd.DataFrame()

        except Exception as e:
            logger.error(f"è·å–Kçº¿æ•°æ®å¤±è´¥: {e}", exc_info=True)
            return pd.DataFrame()

    async def _get_financial_data(self, stock_code: str) -> Dict[str, Any]:
        """è·å–è´¢åŠ¡æ•°æ®

        Args:
            stock_code: è‚¡ç¥¨ä»£ç 

        Returns:
            è´¢åŠ¡æ•°æ®å­—å…¸
        """
        try:
            logger.info(f"è·å–è´¢åŠ¡æ•°æ®: {stock_code}")

            # è·å–è´¢åŠ¡æ•°æ®å¯èƒ½éœ€è¦ç‰¹å®šçš„æœåŠ¡
            # è¿™é‡Œä»…ä½œä¸ºç¤ºä¾‹å®ç°ï¼Œè¿”å›ç©ºå­—å…¸
            return {}

        except Exception as e:
            logger.error(f"è·å–è´¢åŠ¡æ•°æ®å¤±è´¥: {e}", exc_info=True)
            return {}

    async def _get_news(self, stock_code: str) -> Dict[str, Any]:
        """è·å–æ–°é—»æ•°æ®

        Args:
            stock_code: è‚¡ç¥¨ä»£ç 

        Returns:
            æ–°é—»æ•°æ®å­—å…¸
        """
        try:
            logger.info(f"è·å–æ–°é—»æ•°æ®: {stock_code}")

            # è·å–æ–°é—»æ•°æ®å¯èƒ½éœ€è¦ç‰¹å®šçš„æœåŠ¡
            # è¿™é‡Œä»…ä½œä¸ºç¤ºä¾‹å®ç°ï¼Œè¿”å›ç©ºå­—å…¸
            return {}

        except Exception as e:
            logger.error(f"è·å–æ–°é—»æ•°æ®å¤±è´¥: {e}", exc_info=True)
            return {}

    def cancel_request(self, request_id: str) -> bool:
        """
        å–æ¶ˆè¯·æ±‚

        Args:
            request_id: è¯·æ±‚ID

        Returns:
            æ˜¯å¦æˆåŠŸå–æ¶ˆ
        """
        with self.request_tracker_lock:
            if request_id in self.request_tracker:
                task = self.request_tracker[request_id].get('task')
                if task and not task.done():
                    task.cancel()
                    logger.info(f"Request {request_id} cancelled")

                # æ¸…ç†èµ„æº
                self._cleanup_resources(request_id)

                # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
                self._stats['requests_cancelled'] += 1

                return True

        with self._request_lock:
            # æ£€æŸ¥å¾…å¤„ç†è¯·æ±‚
            if request_id in self._pending_requests:
                request = self._pending_requests[request_id]
                request.status = DataRequestStatus.CANCELLED
                del self._pending_requests[request_id]
                logger.debug(f"Cancelled pending request {request_id}")
                return True

            # æ£€æŸ¥æ´»åŠ¨è¯·æ±‚
            if request_id in self._active_requests:
                request = self._active_requests[request_id]
                if request.future and not request.future.done():
                    request.future.cancel()
                request.status = DataRequestStatus.CANCELLED
                del self._active_requests[request_id]
                logger.debug(f"Cancelled active request {request_id}")
                return True

        return False

    def _register_request(self, request_id: str):
        """æ³¨å†Œè¯·æ±‚åˆ°è·Ÿè¸ªå™¨"""
        with self.request_tracker_lock:
            try:
                task = asyncio.current_task() if asyncio.iscoroutinefunction(
                    self.get_stock_data) else None
            except RuntimeError:
                # æ²¡æœ‰è¿è¡Œçš„äº‹ä»¶å¾ªç¯
                task = None
            self.request_tracker[request_id] = {
                'timestamp': time.time(),
                'task': task
            }

    def _unregister_request(self, request_id: str):
        """ä»è·Ÿè¸ªå™¨ä¸­æ³¨é”€è¯·æ±‚"""
        with self.request_tracker_lock:
            if request_id in self.request_tracker:
                del self.request_tracker[request_id]

    def _cleanup_resources(self, request_id: str):
        """æ¸…ç†è¯·æ±‚ç›¸å…³èµ„æº"""
        # ä»å„ç§é›†åˆä¸­ç§»é™¤è¯·æ±‚
        with self._request_lock:
            if request_id in self._pending_requests:
                del self._pending_requests[request_id]

            if request_id in self._active_requests:
                del self._active_requests[request_id]

            if request_id in self._completed_requests:
                del self._completed_requests[request_id]

        # ä»å»é‡æœºåˆ¶ä¸­ç§»é™¤
        with self._dedup_lock:
            for key, requests in list(self._request_dedup.items()):
                if request_id in requests:
                    requests.remove(request_id)
                    if not requests:
                        del self._request_dedup[key]
                    break

        # ä»è·Ÿè¸ªå™¨ä¸­ç§»é™¤
        self._unregister_request(request_id)

        logger.debug(f"Resources cleaned up for request {request_id}")

    def preload_data(self, code: str, freq: str = 'D', priority: str = 'low'):
        """é¢„åŠ è½½æ•°æ®"""
        # è½¬æ¢ä¼˜å…ˆçº§å­—ç¬¦ä¸²åˆ°æ•°å€¼
        priority_map = {'high': 0, 'normal': 1, 'low': 2}
        priority_value = priority_map.get(priority.lower(), 2)

        # ä½¿ç”¨ä½ä¼˜å…ˆçº§è¯·æ±‚é¢„åŠ è½½æ•°æ®
        self.request_data(
            stock_code=code,
            data_type='kdata',
            period=freq,
            priority=priority_value,
            callback=None  # æ— éœ€å›è°ƒ
        )

        logger.debug(f"Preloading data for {code} with priority {priority}")

        return True

    def get_request_status(self, request_id: str) -> Optional[DataRequestStatus]:
        """
        è·å–è¯·æ±‚çŠ¶æ€

        Args:
            request_id: è¯·æ±‚ID

        Returns:
            è¯·æ±‚çŠ¶æ€
        """
        with self._request_lock:
            if request_id in self._pending_requests:
                return self._pending_requests[request_id].status
            elif request_id in self._active_requests:
                return self._active_requests[request_id].status
            elif request_id in self._completed_requests:
                return self._completed_requests[request_id].status

        return None

    def get_stats(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        with self._request_lock:
            return {
                **self._stats,
                'pending_requests': len(self._pending_requests),
                'active_requests': len(self._active_requests),
                'completed_requests': len(self._completed_requests),
                'cache_size': len(self._data_cache)
            }

    def clear_cache(self, stock_code: str = None, data_type: str = None) -> None:
        """
        æ¸…ç†ç¼“å­˜

        Args:
            stock_code: è‚¡ç¥¨ä»£ç ï¼ˆå¯é€‰ï¼Œæ¸…ç†ç‰¹å®šè‚¡ç¥¨çš„ç¼“å­˜ï¼‰
            data_type: æ•°æ®ç±»å‹ï¼ˆå¯é€‰ï¼Œæ¸…ç†ç‰¹å®šç±»å‹çš„ç¼“å­˜ï¼‰
        """
        with self._cache_lock:
            if stock_code is None and data_type is None:
                # æ¸…ç†æ‰€æœ‰ç¼“å­˜
                self._data_cache.clear()
                self._cache_timestamps.clear()
                logger.info("All cache cleared")
            else:
                # æ¸…ç†ç‰¹å®šç¼“å­˜
                keys_to_remove = []
                for key in self._data_cache.keys():
                    if stock_code and stock_code not in key:
                        continue
                    if data_type and data_type not in key:
                        continue
                    keys_to_remove.append(key)

                for key in keys_to_remove:
                    del self._data_cache[key]
                    if key in self._cache_timestamps:
                        del self._cache_timestamps[key]

                logger.info(f"Cleared {len(keys_to_remove)} cache entries")

    def _submit_request(self, request: DataRequest) -> None:
        """æäº¤è¯·æ±‚åˆ°çº¿ç¨‹æ± """
        with self._request_lock:
            self._pending_requests[request.request_id] = request

        # æäº¤åˆ°çº¿ç¨‹æ± 
        future = self._executor.submit(self._process_request, request)
        request.future = future

        logger.debug(
            f"Submitted request {request.request_id} for {request.stock_code}")

    def _process_request(self, request: DataRequest) -> None:
        """
        å¤„ç†æ•°æ®è¯·æ±‚
        """
        try:
            data = None
            if request.data_type == 'kdata':
                kline_data = self._load_kdata(request)
                # ä¿®æ”¹ï¼šå°†Kçº¿æ•°æ®åŒ…è£…åœ¨å­—å…¸ä¸­ï¼Œä¿æŒæ•°æ®ç»“æ„ä¸€è‡´æ€§
                data = {
                    'kline_data': kline_data,
                    'stock_code': request.stock_code,
                    'period': request.period
                }
            elif request.data_type == 'indicators':
                data = self._load_indicators(request)
            elif request.data_type == 'analysis':
                data = self._load_analysis(request)
            elif request.data_type == 'chart':
                kline_data = self._load_kdata(request)
                indicators_data = self._load_indicators(request)
                data = {
                    'kline_data': kline_data,
                    'indicators_data': indicators_data
                }
            else:
                raise ValueError(f"Unsupported data type: {request.data_type}")

            self._complete_request(request, data)

        except Exception as e:
            logger.error(
                f"Failed to process request {request.request_id}: {e}")
            self._complete_request(request, None, str(e))

    def _complete_request(self, request: DataRequest, data: Any, error: str = None) -> None:
        """
        å®Œæˆè¯·æ±‚å¹¶é€šè¿‡Futureè¿”å›ç»“æœ
        """
        request_key = self._get_request_key(
            request.stock_code, request.data_type, request.period, request.time_range, request.parameters)

        with self._dedup_lock:
            request_group = self._request_dedup.pop(request_key, set())

        for req in request_group:
            if req.future and not req.future.done():
                if error:
                    exception = Exception(error)
                    self.loop.call_soon_threadsafe(
                        req.future.set_exception, exception)
                else:
                    self.loop.call_soon_threadsafe(req.future.set_result, data)

            with self._request_lock:
                self._completed_requests[req.request_id] = req
                req.status = DataRequestStatus.COMPLETED if not error else DataRequestStatus.FAILED

        if not error:
            self._stats['requests_completed'] += len(request_group)
        else:
            self._stats['requests_failed'] += len(request_group)

    def _load_kdata(self, request: DataRequest) -> pd.DataFrame:
        """åŠ è½½Kçº¿æ•°æ®"""
        try:
            from .stock_service import StockService
            stock_service = self.service_container.resolve(StockService)
            return stock_service.get_stock_data(
                request.stock_code, request.period, request.time_range
            )
        except Exception as e:
            logger.error(f"Failed to load kdata: {e}")
            raise

    def _load_indicators(self, request: DataRequest) -> Dict[str, Any]:
        """åŠ è½½æŠ€æœ¯æŒ‡æ ‡æ•°æ®"""
        try:
            from .analysis_service import AnalysisService
            analysis_service = self.service_container.resolve(AnalysisService)

            indicators = request.parameters.get('indicators', ['MA', 'MACD'])
            return analysis_service.calculate_technical_indicators(
                request.stock_code, indicators, request.period, request.time_range
            )
        except Exception as e:
            logger.error(f"Failed to load indicators: {e}")
            raise

    def _load_analysis(self, request: DataRequest) -> Dict[str, Any]:
        """åŠ è½½åˆ†ææ•°æ®"""
        try:
            from .analysis_service import AnalysisService
            analysis_service = self.service_container.resolve(AnalysisService)

            analysis_type = request.parameters.get(
                'analysis_type', 'comprehensive')
            return analysis_service.analyze_stock(request.stock_code, analysis_type)
        except Exception as e:
            logger.error(f"Failed to load analysis: {e}")
            raise

    def _get_cache_key(self, stock_code: str, data_type: str, period: str,
                       time_range: int, parameters: Dict[str, Any]) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        param_hash = hash(str(sorted(parameters.items()))
                          if parameters else "")
        return f"{data_type}_{stock_code}_{period}_{time_range}_{param_hash}"

    def _get_request_key(self, stock_code: str, data_type: str, period: str,
                         time_range: int, parameters: Dict[str, Any]) -> str:
        """ç”Ÿæˆè¯·æ±‚é”®"""
        return self._get_cache_key(stock_code, data_type, period, time_range, parameters)

    def _get_from_cache(self, cache_key: str) -> Optional[Any]:
        """ä»ç¼“å­˜è·å–æ•°æ®"""
        with self._cache_lock:
            if cache_key in self._data_cache:
                timestamp = self._cache_timestamps.get(cache_key, 0)
                if time.time() - timestamp < self._cache_ttl:
                    return self._data_cache[cache_key]
                else:
                    # ç¼“å­˜è¿‡æœŸï¼Œæ¸…ç†
                    del self._data_cache[cache_key]
                    if cache_key in self._cache_timestamps:
                        del self._cache_timestamps[cache_key]

        return None

    def _put_to_cache(self, cache_key: str, data: Any) -> None:
        """å°†æ•°æ®æ”¾å…¥ç¼“å­˜"""
        with self._cache_lock:
            self._data_cache[cache_key] = data
            self._cache_timestamps[cache_key] = time.time()

    def dispose(self) -> None:
        """æ¸…ç†èµ„æº"""
        logger.info("Disposing unified data manager")

        # å–æ¶ˆæ‰€æœ‰å¾…å¤„ç†è¯·æ±‚
        with self._request_lock:
            for request in list(self._pending_requests.values()):
                self.cancel_request(request.request_id)

            for request in list(self._active_requests.values()):
                self.cancel_request(request.request_id)

        # å…³é—­çº¿ç¨‹æ± 
        self._executor.shutdown(wait=True)

        # æ¸…ç†ç¼“å­˜
        self.clear_cache()

        logger.info("Unified data manager disposed")

# æ•°æ®ç­–ç•¥ç±»


class HistoryDataStrategy:
    """å†å²æ•°æ®åŠ è½½ç­–ç•¥"""

    async def get_data(self, code: str, freq: str, start_date=None, end_date=None):
        """è·å–å†å²æ•°æ®"""
        logger.debug(
            f"Loading historical data for {code} from {start_date} to {end_date}")
        # å®é™…å®ç°åº”è¯¥è°ƒç”¨ç›¸åº”çš„å†å²æ•°æ®æœåŠ¡
        # è¿™é‡Œä¸ºç¤ºä¾‹å®ç°
        try:
            # æ¨¡æ‹Ÿå¼‚æ­¥åŠ è½½
            await asyncio.sleep(0.1)
            return {'type': 'historical', 'code': code, 'freq': freq, 'data': []}
        except Exception as e:
            logger.error(f"Error loading historical data: {e}")
            return None


class RealtimeDataStrategy:
    """å®æ—¶æ•°æ®åŠ è½½ç­–ç•¥"""

    async def get_data(self, code: str, freq: str, start_date=None, end_date=None):
        """è·å–å®æ—¶æ•°æ®"""
        logger.debug(f"Loading realtime data for {code}")
        # å®é™…å®ç°åº”è¯¥è°ƒç”¨å®æ—¶è¡Œæƒ…æœåŠ¡
        # è¿™é‡Œä¸ºç¤ºä¾‹å®ç°
        try:
            # æ¨¡æ‹Ÿå¼‚æ­¥åŠ è½½
            await asyncio.sleep(0.2)
            return {'type': 'realtime', 'code': code, 'freq': freq, 'data': []}
        except Exception as e:
            logger.error(f"Error loading realtime data: {e}")
            return None
