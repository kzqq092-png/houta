"""
统一缓存服务

整合所有缓存管理器为单一服务，提供：
- 多级缓存策略（内存、磁盘、分布式）
- 智能缓存失效和预热
- 性能监控和优化
- 统一缓存接口
- 自适应缓存策略
"""

import asyncio
import threading
import time
import hashlib
from contextlib import contextmanager
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from enum import Enum
from pathlib import Path
from typing import Any, Dict, List, Optional, Union, Callable, Set, Tuple
from collections import defaultdict, deque
import json
import pickle
from loguru import logger

from ..performance.cache_manager import (
    MultiLevelCacheManager, LRUCache, DiskCache, CacheLevel,
    CacheEntry, CacheStats
)
from ..performance.intelligent_cache_coordinator import (
    IntelligentCacheCoordinator, CacheStrategy, CacheConfiguration,
    CacheAccessPattern, CacheRecommendation
)
from ..performance.adaptive_cache_strategy import AdaptiveCacheStrategy
from ..performance.enhanced_cache_system import EnhancedCacheSystem
from ..services.base_service import BaseService
from ..events import EventBus, get_event_bus
from ..containers import ServiceContainer, get_service_container


class CacheServiceLevel(Enum):
    """缓存服务级别"""
    L1_MEMORY = "l1_memory"      # L1内存缓存（最快）
    L2_DISK = "l2_disk"          # L2磁盘缓存
    L3_DISTRIBUTED = "l3_distributed"  # L3分布式缓存
    L4_PERSISTENT = "l4_persistent"    # L4持久化缓存


class CacheOperation(Enum):
    """缓存操作类型"""
    GET = "get"
    SET = "set"
    DELETE = "delete"
    INVALIDATE = "invalidate"
    PRELOAD = "preload"
    EVICT = "evict"


@dataclass
class CacheConfiguration:
    """缓存配置"""
    # 内存缓存配置
    memory_cache_size: int = 1024 * 1024 * 256  # 256MB
    memory_cache_ttl: int = 3600  # 1小时
    memory_cache_max_entries: int = 10000

    # 磁盘缓存配置
    disk_cache_size: int = 1024 * 1024 * 1024 * 2  # 2GB
    disk_cache_ttl: int = 86400  # 24小时
    disk_cache_path: str = "cache/disk"

    # 分布式缓存配置
    distributed_enabled: bool = False
    distributed_servers: List[str] = field(default_factory=list)
    distributed_ttl: int = 7200  # 2小时

    # 性能配置
    auto_eviction_enabled: bool = True
    preloading_enabled: bool = True
    compression_enabled: bool = True
    encryption_enabled: bool = False

    # 监控配置
    metrics_collection_enabled: bool = True
    performance_monitoring_enabled: bool = True


@dataclass
class CacheMetrics:
    """缓存指标"""
    level: CacheServiceLevel
    hits: int = 0
    misses: int = 0
    sets: int = 0
    deletes: int = 0
    evictions: int = 0
    hit_ratio: float = 0.0
    avg_access_time_ms: float = 0.0
    total_size_bytes: int = 0
    entry_count: int = 0
    last_updated: datetime = field(default_factory=datetime.now)


@dataclass
class CacheOperationContext:
    """缓存操作上下文"""
    operation: CacheOperation
    key: str
    level: CacheServiceLevel
    timestamp: datetime
    execution_time_ms: Optional[float] = None
    success: bool = True
    error: Optional[str] = None
    metadata: Dict[str, Any] = field(default_factory=dict)


class UnifiedCacheService(BaseService):
    """
    统一缓存服务

    整合所有缓存管理器，提供统一的多级缓存系统：
    - L1内存缓存（最快访问）
    - L2磁盘缓存（大容量）
    - L3分布式缓存（横向扩展）
    - L4持久化缓存（长期存储）
    """

    def __init__(self,
                 config: Optional[CacheConfiguration] = None,
                 service_container: Optional[ServiceContainer] = None,
                 event_bus: Optional[EventBus] = None):
        """
        初始化统一缓存服务

        Args:
            config: 缓存配置
            service_container: 服务容器
            event_bus: 事件总线
        """
        super().__init__(event_bus)

        self._service_container = service_container or get_service_container()
        self._config = config or CacheConfiguration()

        # 核心缓存管理器
        self._multi_level_manager: Optional[MultiLevelCacheManager] = None
        self._intelligent_coordinator: Optional[IntelligentCacheCoordinator] = None
        self._adaptive_strategy: Optional[AdaptiveCacheStrategy] = None
        self._enhanced_system: Optional[EnhancedCacheSystem] = None

        # 多级缓存实例
        self._l1_cache: Optional[LRUCache] = None  # 内存缓存
        self._l2_cache: Optional[DiskCache] = None  # 磁盘缓存
        self._l3_cache: Optional[Any] = None  # 分布式缓存
        self._l4_cache: Optional[Any] = None  # 持久化缓存

        # 缓存指标
        self._metrics: Dict[CacheServiceLevel, CacheMetrics] = {}
        self._operation_history: deque = deque(maxlen=10000)

        # 性能监控
        self._access_patterns: Dict[str, CacheAccessPattern] = {}
        self._hot_keys: Set[str] = set()
        self._cold_keys: Set[str] = set()

        # 线程和锁
        self._cache_lock = threading.RLock()
        self._metrics_lock = threading.RLock()
        self._pattern_lock = threading.RLock()

        # 后台任务
        self._monitoring_task: Optional[asyncio.Task] = None
        self._optimization_task: Optional[asyncio.Task] = None
        self._cleanup_task: Optional[asyncio.Task] = None

        logger.info("Unified cache service initialized")

    async def initialize(self) -> None:
        """初始化统一缓存服务"""
        try:
            logger.info("Initializing unified cache service...")

            # 初始化核心缓存管理器
            await self._initialize_cache_managers()

            # 设置多级缓存
            await self._setup_multi_level_cache()

            # 初始化智能协调器
            await self._setup_intelligent_coordination()

            # 启动后台任务
            await self._start_background_tasks()

            # 初始化指标
            self._initialize_metrics()

            self._initialized = True
            logger.info("✅ Unified cache service initialized successfully")

        except Exception as e:
            logger.error(f"Failed to initialize unified cache service: {e}")
            raise

    async def _initialize_cache_managers(self) -> None:
        """初始化核心缓存管理器"""
        try:
            # 多级缓存管理器
            self._multi_level_manager = MultiLevelCacheManager(
                memory_limit_mb=self._config.memory_cache_size // (1024 * 1024),
                disk_cache_dir=self._config.disk_cache_path,
                disk_limit_mb=self._config.disk_cache_size // (1024 * 1024)
            )

            # 智能缓存协调器
            self._intelligent_coordinator = IntelligentCacheCoordinator()

            # 自适应缓存策略
            self._adaptive_strategy = AdaptiveCacheStrategy()

            # 增强缓存系统
            try:
                self._enhanced_system = EnhancedCacheSystem()
            except Exception as e:
                logger.warning(f"Enhanced cache system initialization failed: {e}")
                self._enhanced_system = None

            logger.info("Core cache managers initialized")

        except Exception as e:
            logger.error(f"Failed to initialize cache managers: {e}")
            raise

    async def _setup_multi_level_cache(self) -> None:
        """设置多级缓存"""
        try:
            # L1 内存缓存
            self._l1_cache = LRUCache(
                capacity=self._config.memory_cache_max_entries,
                ttl=timedelta(seconds=self._config.memory_cache_ttl)
            )

            # L2 磁盘缓存
            disk_path = Path(self._config.disk_cache_path)
            disk_path.mkdir(parents=True, exist_ok=True)

            self._l2_cache = DiskCache(
                cache_dir=str(disk_path),
                max_size_mb=self._config.disk_cache_size // (1024 * 1024),
                ttl=timedelta(seconds=self._config.disk_cache_ttl)
            )

            # L3 分布式缓存（如果启用）
            if self._config.distributed_enabled and self._config.distributed_servers:
                await self._setup_distributed_cache()

            # L4 持久化缓存
            await self._setup_persistent_cache()

            logger.info("Multi-level cache setup complete")

        except Exception as e:
            logger.error(f"Failed to setup multi-level cache: {e}")
            raise

    async def _setup_distributed_cache(self) -> None:
        """设置分布式缓存"""
        try:
            # 这里可以集成Redis、Memcached等分布式缓存
            # 目前使用简单的占位符实现
            self._l3_cache = {}
            logger.info("Distributed cache setup (placeholder)")

        except Exception as e:
            logger.error(f"Failed to setup distributed cache: {e}")
            self._l3_cache = None

    async def _setup_persistent_cache(self) -> None:
        """设置持久化缓存"""
        try:
            # 使用SQLite作为持久化缓存
            persistent_path = Path(self._config.disk_cache_path) / "persistent.db"
            self._l4_cache = {'db_path': str(persistent_path)}
            logger.info("Persistent cache setup complete")

        except Exception as e:
            logger.error(f"Failed to setup persistent cache: {e}")
            self._l4_cache = None

    async def _setup_intelligent_coordination(self) -> None:
        """设置智能协调"""
        try:
            if self._intelligent_coordinator:
                # 注册缓存实例到协调器
                if self._multi_level_manager:
                    await asyncio.to_thread(
                        self._intelligent_coordinator.register_cache_manager,
                        'multi_level', self._multi_level_manager
                    )

                # 启动智能协调
                await asyncio.to_thread(self._intelligent_coordinator.start_coordination)

                logger.info("Intelligent coordination setup complete")

        except Exception as e:
            logger.error(f"Failed to setup intelligent coordination: {e}")

    async def _start_background_tasks(self) -> None:
        """启动后台任务"""
        try:
            # 性能监控任务
            self._monitoring_task = asyncio.create_task(self._monitor_performance())

            # 缓存优化任务
            self._optimization_task = asyncio.create_task(self._optimize_cache())

            # 清理任务
            self._cleanup_task = asyncio.create_task(self._cleanup_expired())

            logger.info("Background tasks started")

        except Exception as e:
            logger.error(f"Failed to start background tasks: {e}")

    def _initialize_metrics(self) -> None:
        """初始化指标"""
        for level in CacheServiceLevel:
            self._metrics[level] = CacheMetrics(level=level)

    async def get(self,
                  key: str,
                  default: Any = None,
                  preferred_level: Optional[CacheServiceLevel] = None) -> Any:
        """
        获取缓存值

        Args:
            key: 缓存键
            default: 默认值
            preferred_level: 首选缓存级别

        Returns:
            缓存值或默认值
        """
        start_time = time.time()

        try:
            # 记录访问模式
            await self._record_access_pattern(key, CacheOperation.GET)

            # 按级别顺序查找
            levels_to_check = self._get_search_levels(preferred_level)

            for level in levels_to_check:
                try:
                    value = await self._get_from_level(key, level)
                    if value is not None:
                        # 记录命中
                        execution_time = (time.time() - start_time) * 1000
                        await self._record_hit(level, execution_time)

                        # 提升到更高级别缓存（缓存预热）
                        if level != CacheServiceLevel.L1_MEMORY:
                            await self._promote_to_higher_level(key, value, level)

                        return value

                except Exception as e:
                    logger.debug(f"Failed to get from {level}: {e}")
                    continue

            # 所有级别都未命中
            execution_time = (time.time() - start_time) * 1000
            await self._record_miss(execution_time)

            return default

        except Exception as e:
            logger.error(f"Error getting cache key '{key}': {e}")
            return default

    async def set(self,
                  key: str,
                  value: Any,
                  ttl: Optional[int] = None,
                  level: Optional[CacheServiceLevel] = None) -> bool:
        """
        设置缓存值

        Args:
            key: 缓存键
            value: 缓存值
            ttl: 生存时间（秒）
            level: 目标缓存级别

        Returns:
            是否设置成功
        """
        start_time = time.time()

        try:
            # 记录访问模式
            await self._record_access_pattern(key, CacheOperation.SET)

            # 确定目标级别
            target_levels = self._get_target_levels(level, value)

            success_count = 0
            for target_level in target_levels:
                try:
                    if await self._set_to_level(key, value, target_level, ttl):
                        success_count += 1

                        # 记录设置操作
                        execution_time = (time.time() - start_time) * 1000
                        await self._record_set(target_level, execution_time)

                except Exception as e:
                    logger.warning(f"Failed to set to {target_level}: {e}")

            return success_count > 0

        except Exception as e:
            logger.error(f"Error setting cache key '{key}': {e}")
            return False

    async def delete(self, key: str) -> bool:
        """
        删除缓存键

        Args:
            key: 缓存键

        Returns:
            是否删除成功
        """
        try:
            # 记录访问模式
            await self._record_access_pattern(key, CacheOperation.DELETE)

            # 从所有级别删除
            success_count = 0
            for level in CacheServiceLevel:
                try:
                    if await self._delete_from_level(key, level):
                        success_count += 1
                        await self._record_delete(level)

                except Exception as e:
                    logger.debug(f"Failed to delete from {level}: {e}")

            return success_count > 0

        except Exception as e:
            logger.error(f"Error deleting cache key '{key}': {e}")
            return False

    async def invalidate_pattern(self, pattern: str) -> int:
        """
        按模式失效缓存

        Args:
            pattern: 匹配模式

        Returns:
            失效的键数量
        """
        try:
            total_invalidated = 0

            for level in CacheServiceLevel:
                try:
                    count = await self._invalidate_pattern_in_level(pattern, level)
                    total_invalidated += count

                except Exception as e:
                    logger.warning(f"Failed to invalidate pattern in {level}: {e}")

            logger.info(f"Invalidated {total_invalidated} keys matching pattern '{pattern}'")
            return total_invalidated

        except Exception as e:
            logger.error(f"Error invalidating pattern '{pattern}': {e}")
            return 0

    async def preload(self, keys: List[str], loader: Callable[[str], Any]) -> int:
        """
        预加载缓存

        Args:
            keys: 要预加载的键列表
            loader: 数据加载函数

        Returns:
            成功预加载的键数量
        """
        if not self._config.preloading_enabled:
            return 0

        try:
            success_count = 0

            for key in keys:
                try:
                    # 检查是否已存在
                    existing_value = await self.get(key)
                    if existing_value is not None:
                        continue

                    # 加载数据
                    value = await asyncio.to_thread(loader, key)
                    if value is not None:
                        if await self.set(key, value):
                            success_count += 1

                except Exception as e:
                    logger.warning(f"Failed to preload key '{key}': {e}")

            logger.info(f"Preloaded {success_count} keys")
            return success_count

        except Exception as e:
            logger.error(f"Error in preload operation: {e}")
            return 0

    def get_cache_stats(self) -> Dict[str, Any]:
        """获取缓存统计"""
        with self._metrics_lock:
            stats = {}

            for level, metrics in self._metrics.items():
                stats[level.value] = {
                    'hits': metrics.hits,
                    'misses': metrics.misses,
                    'sets': metrics.sets,
                    'deletes': metrics.deletes,
                    'evictions': metrics.evictions,
                    'hit_ratio': metrics.hit_ratio,
                    'avg_access_time_ms': metrics.avg_access_time_ms,
                    'total_size_bytes': metrics.total_size_bytes,
                    'entry_count': metrics.entry_count,
                    'last_updated': metrics.last_updated.isoformat()
                }

            # 添加聚合统计
            total_hits = sum(m.hits for m in self._metrics.values())
            total_misses = sum(m.misses for m in self._metrics.values())
            total_operations = total_hits + total_misses

            stats['aggregate'] = {
                'total_hits': total_hits,
                'total_misses': total_misses,
                'overall_hit_ratio': total_hits / total_operations if total_operations > 0 else 0,
                'hot_keys_count': len(self._hot_keys),
                'cold_keys_count': len(self._cold_keys),
                'operation_history_size': len(self._operation_history)
            }

            return stats

    def get_performance_recommendations(self) -> List[str]:
        """获取性能优化建议"""
        recommendations = []

        try:
            stats = self.get_cache_stats()
            aggregate = stats.get('aggregate', {})

            # 命中率分析
            overall_hit_ratio = aggregate.get('overall_hit_ratio', 0)
            if overall_hit_ratio < 0.7:
                recommendations.append(f"Overall hit ratio is low ({overall_hit_ratio:.1%}). Consider increasing cache size or TTL.")

            # L1缓存分析
            l1_stats = stats.get(CacheServiceLevel.L1_MEMORY.value, {})
            l1_hit_ratio = l1_stats.get('hit_ratio', 0)
            if l1_hit_ratio < 0.5:
                recommendations.append("L1 memory cache hit ratio is low. Consider increasing memory cache size.")

            # 热键分析
            hot_keys_count = aggregate.get('hot_keys_count', 0)
            if hot_keys_count > 1000:
                recommendations.append(f"High number of hot keys ({hot_keys_count}). Consider implementing key sharding.")

            # 访问模式分析
            if len(self._access_patterns) > 0:
                with self._pattern_lock:
                    sequential_patterns = sum(
                        1 for pattern in self._access_patterns.values()
                        if hasattr(pattern, 'is_sequential') and pattern.is_sequential
                    )
                    if sequential_patterns > len(self._access_patterns) * 0.3:
                        recommendations.append("High sequential access detected. Consider implementing prefetching.")

            if not recommendations:
                recommendations.append("Cache performance is optimal.")

        except Exception as e:
            logger.error(f"Error generating performance recommendations: {e}")
            recommendations.append("Unable to analyze cache performance.")

        return recommendations

    async def _get_from_level(self, key: str, level: CacheServiceLevel) -> Any:
        """从指定级别获取缓存"""
        if level == CacheServiceLevel.L1_MEMORY and self._l1_cache:
            return await asyncio.to_thread(self._l1_cache.get, key)
        elif level == CacheServiceLevel.L2_DISK and self._l2_cache:
            return await asyncio.to_thread(self._l2_cache.get, key)
        elif level == CacheServiceLevel.L3_DISTRIBUTED and self._l3_cache:
            return self._l3_cache.get(key)
        elif level == CacheServiceLevel.L4_PERSISTENT and self._l4_cache:
            return await self._get_from_persistent(key)

        return None

    async def _set_to_level(self, key: str, value: Any, level: CacheServiceLevel, ttl: Optional[int] = None) -> bool:
        """设置到指定级别"""
        try:
            if level == CacheServiceLevel.L1_MEMORY and self._l1_cache:
                await asyncio.to_thread(self._l1_cache.set, key, value)
                return True
            elif level == CacheServiceLevel.L2_DISK and self._l2_cache:
                await asyncio.to_thread(self._l2_cache.set, key, value)
                return True
            elif level == CacheServiceLevel.L3_DISTRIBUTED and self._l3_cache:
                self._l3_cache[key] = value
                return True
            elif level == CacheServiceLevel.L4_PERSISTENT and self._l4_cache:
                return await self._set_to_persistent(key, value, ttl)

            return False

        except Exception as e:
            logger.error(f"Failed to set to {level}: {e}")
            return False

    async def _delete_from_level(self, key: str, level: CacheServiceLevel) -> bool:
        """从指定级别删除"""
        try:
            if level == CacheServiceLevel.L1_MEMORY and self._l1_cache:
                await asyncio.to_thread(self._l1_cache.delete, key)
                return True
            elif level == CacheServiceLevel.L2_DISK and self._l2_cache:
                await asyncio.to_thread(self._l2_cache.delete, key)
                return True
            elif level == CacheServiceLevel.L3_DISTRIBUTED and self._l3_cache:
                if key in self._l3_cache:
                    del self._l3_cache[key]
                    return True
            elif level == CacheServiceLevel.L4_PERSISTENT and self._l4_cache:
                return await self._delete_from_persistent(key)

            return False

        except Exception as e:
            logger.error(f"Failed to delete from {level}: {e}")
            return False

    async def _get_from_persistent(self, key: str) -> Any:
        """从持久化缓存获取"""
        # 简化实现，实际可以使用SQLite
        return None

    async def _set_to_persistent(self, key: str, value: Any, ttl: Optional[int] = None) -> bool:
        """设置到持久化缓存"""
        # 简化实现，实际可以使用SQLite
        return True

    async def _delete_from_persistent(self, key: str) -> bool:
        """从持久化缓存删除"""
        # 简化实现，实际可以使用SQLite
        return True

    def _get_search_levels(self, preferred_level: Optional[CacheServiceLevel] = None) -> List[CacheServiceLevel]:
        """获取搜索级别顺序"""
        if preferred_level:
            # 从首选级别开始，然后按顺序
            levels = [preferred_level]
            for level in CacheServiceLevel:
                if level != preferred_level:
                    levels.append(level)
            return levels
        else:
            # 默认顺序：L1 -> L2 -> L3 -> L4
            return list(CacheServiceLevel)

    def _get_target_levels(self, level: Optional[CacheServiceLevel], value: Any) -> List[CacheServiceLevel]:
        """获取目标级别"""
        if level:
            return [level]

        # 根据值的大小和类型决定存储级别
        levels = [CacheServiceLevel.L1_MEMORY]  # 总是存储到L1

        # 大对象也存储到L2
        try:
            value_size = len(pickle.dumps(value))
            if value_size > 1024:  # 大于1KB
                levels.append(CacheServiceLevel.L2_DISK)
        except:
            levels.append(CacheServiceLevel.L2_DISK)

        return levels

    async def _promote_to_higher_level(self, key: str, value: Any, current_level: CacheServiceLevel) -> None:
        """提升到更高级别"""
        if current_level == CacheServiceLevel.L2_DISK:
            await self._set_to_level(key, value, CacheServiceLevel.L1_MEMORY)
        elif current_level == CacheServiceLevel.L3_DISTRIBUTED:
            await self._set_to_level(key, value, CacheServiceLevel.L1_MEMORY)
            await self._set_to_level(key, value, CacheServiceLevel.L2_DISK)
        elif current_level == CacheServiceLevel.L4_PERSISTENT:
            await self._set_to_level(key, value, CacheServiceLevel.L1_MEMORY)

    async def _record_access_pattern(self, key: str, operation: CacheOperation) -> None:
        """记录访问模式"""
        try:
            with self._pattern_lock:
                if key not in self._access_patterns:
                    self._access_patterns[key] = CacheAccessPattern(key=key)

                pattern = self._access_patterns[key]
                pattern.access_count += 1
                pattern.last_access = datetime.now()

                # 更新热/冷键
                if pattern.access_count > 100:  # 热键阈值
                    self._hot_keys.add(key)
                    self._cold_keys.discard(key)
                elif pattern.access_count < 5:  # 冷键阈值
                    self._cold_keys.add(key)
                    self._hot_keys.discard(key)

        except Exception as e:
            logger.debug(f"Error recording access pattern: {e}")

    async def _record_hit(self, level: CacheServiceLevel, execution_time: float) -> None:
        """记录缓存命中"""
        with self._metrics_lock:
            metrics = self._metrics[level]
            metrics.hits += 1

            # 更新平均访问时间
            total_operations = metrics.hits + metrics.misses
            metrics.avg_access_time_ms = (
                (metrics.avg_access_time_ms * (total_operations - 1) + execution_time) / total_operations
            )

            # 更新命中率
            metrics.hit_ratio = metrics.hits / total_operations
            metrics.last_updated = datetime.now()

    async def _record_miss(self, execution_time: float) -> None:
        """记录缓存未命中"""
        with self._metrics_lock:
            # 记录到L1，因为通常首先查找L1
            metrics = self._metrics[CacheServiceLevel.L1_MEMORY]
            metrics.misses += 1

            # 更新统计
            total_operations = metrics.hits + metrics.misses
            metrics.avg_access_time_ms = (
                (metrics.avg_access_time_ms * (total_operations - 1) + execution_time) / total_operations
            )
            metrics.hit_ratio = metrics.hits / total_operations
            metrics.last_updated = datetime.now()

    async def _record_set(self, level: CacheServiceLevel, execution_time: float) -> None:
        """记录缓存设置"""
        with self._metrics_lock:
            metrics = self._metrics[level]
            metrics.sets += 1
            metrics.last_updated = datetime.now()

    async def _record_delete(self, level: CacheServiceLevel) -> None:
        """记录缓存删除"""
        with self._metrics_lock:
            metrics = self._metrics[level]
            metrics.deletes += 1
            metrics.last_updated = datetime.now()

    async def _invalidate_pattern_in_level(self, pattern: str, level: CacheServiceLevel) -> int:
        """在指定级别失效模式匹配的键"""
        # 简化实现，实际需要根据具体缓存类型实现
        return 0

    async def _monitor_performance(self) -> None:
        """性能监控任务"""
        while True:
            try:
                await asyncio.sleep(60)  # 每分钟监控一次

                # 更新缓存大小统计
                await self._update_size_metrics()

                # 生成性能建议
                recommendations = self.get_performance_recommendations()
                if recommendations and len(recommendations) > 1:  # 除了"optimal"之外有其他建议
                    logger.info(f"Cache performance recommendations: {recommendations}")

            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.error(f"Error in performance monitoring: {e}")

    async def _optimize_cache(self) -> None:
        """缓存优化任务"""
        while True:
            try:
                await asyncio.sleep(300)  # 每5分钟优化一次

                # 自动驱逐冷键
                if self._config.auto_eviction_enabled:
                    await self._evict_cold_keys()

                # 预加载热键
                if self._config.preloading_enabled:
                    await self._preload_hot_keys()

            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.error(f"Error in cache optimization: {e}")

    async def _cleanup_expired(self) -> None:
        """清理过期缓存"""
        while True:
            try:
                await asyncio.sleep(120)  # 每2分钟清理一次

                # 清理过期的访问模式
                cutoff_time = datetime.now() - timedelta(hours=24)
                with self._pattern_lock:
                    expired_keys = [
                        key for key, pattern in self._access_patterns.items()
                        if pattern.last_access < cutoff_time
                    ]

                    for key in expired_keys:
                        del self._access_patterns[key]
                        self._hot_keys.discard(key)
                        self._cold_keys.discard(key)

                # 清理操作历史
                while len(self._operation_history) > 5000:
                    self._operation_history.popleft()

            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.error(f"Error in cleanup: {e}")

    async def _update_size_metrics(self) -> None:
        """更新大小指标"""
        try:
            for level in CacheServiceLevel:
                metrics = self._metrics[level]

                if level == CacheServiceLevel.L1_MEMORY and self._l1_cache:
                    # 更新L1指标
                    metrics.entry_count = len(self._l1_cache._cache) if hasattr(self._l1_cache, '_cache') else 0
                elif level == CacheServiceLevel.L2_DISK and self._l2_cache:
                    # 更新L2指标
                    metrics.entry_count = len(self._l2_cache._cache) if hasattr(self._l2_cache, '_cache') else 0

                metrics.last_updated = datetime.now()

        except Exception as e:
            logger.debug(f"Error updating size metrics: {e}")

    async def _evict_cold_keys(self) -> None:
        """驱逐冷键"""
        try:
            with self._pattern_lock:
                cold_keys_to_evict = list(self._cold_keys)[:100]  # 限制批量大小

            for key in cold_keys_to_evict:
                await self.delete(key)

            if cold_keys_to_evict:
                logger.debug(f"Evicted {len(cold_keys_to_evict)} cold keys")

        except Exception as e:
            logger.error(f"Error evicting cold keys: {e}")

    async def _preload_hot_keys(self) -> None:
        """预加载热键"""
        # 简化实现，实际需要根据业务逻辑实现
        pass

    async def health_check(self) -> Dict[str, Any]:
        """健康检查"""
        health_status = {
            'status': 'healthy',
            'timestamp': datetime.now().isoformat(),
            'levels': {},
            'issues': []
        }

        try:
            # 检查各级缓存
            for level in CacheServiceLevel:
                try:
                    # 简单的读写测试
                    test_key = f"health_check_{level.value}_{int(time.time())}"
                    test_value = "health_check_value"

                    # 写入测试
                    if await self._set_to_level(test_key, test_value, level):
                        # 读取测试
                        retrieved_value = await self._get_from_level(test_key, level)
                        if retrieved_value == test_value:
                            health_status['levels'][level.value] = 'healthy'
                        else:
                            health_status['levels'][level.value] = 'degraded'
                            health_status['issues'].append(f"Level {level.value} read/write mismatch")

                        # 清理测试数据
                        await self._delete_from_level(test_key, level)
                    else:
                        health_status['levels'][level.value] = 'unhealthy'
                        health_status['issues'].append(f"Level {level.value} write failed")

                except Exception as e:
                    health_status['levels'][level.value] = f'error: {e}'
                    health_status['issues'].append(f"Level {level.value} health check failed: {e}")

            # 检查是否有问题
            if health_status['issues']:
                health_status['status'] = 'degraded'

        except Exception as e:
            health_status['status'] = 'unhealthy'
            health_status['issues'].append(f"Health check failed: {e}")

        return health_status

    async def shutdown(self) -> None:
        """关闭服务"""
        try:
            logger.info("Shutting down unified cache service...")

            # 取消后台任务
            tasks = [self._monitoring_task, self._optimization_task, self._cleanup_task]
            for task in tasks:
                if task:
                    task.cancel()
                    try:
                        await task
                    except asyncio.CancelledError:
                        pass

            # 关闭缓存管理器
            if self._multi_level_manager:
                # 关闭多级缓存管理器
                pass

            if self._intelligent_coordinator:
                try:
                    await asyncio.to_thread(self._intelligent_coordinator.stop_coordination)
                except Exception as e:
                    logger.error(f"Error stopping intelligent coordinator: {e}")

            # 清理资源
            self._metrics.clear()
            self._operation_history.clear()
            self._access_patterns.clear()
            self._hot_keys.clear()
            self._cold_keys.clear()

            logger.info("✅ Unified cache service shutdown complete")

        except Exception as e:
            logger.error(f"Error during cache service shutdown: {e}")


# 全局实例获取函数
_unified_cache_service: Optional[UnifiedCacheService] = None


def get_unified_cache_service() -> UnifiedCacheService:
    """获取统一缓存服务实例"""
    global _unified_cache_service

    if _unified_cache_service is None:
        _unified_cache_service = UnifiedCacheService()

    return _unified_cache_service
