#!/usr/bin/env python3
"""
å¼‚æ­¥æ•°æ®å¯¼å…¥ç®¡ç†å™¨

æä¾›å¼‚æ­¥çš„DuckDBæ•°æ®å¯¼å…¥åŠŸèƒ½ï¼Œä½¿ç”¨Qtä¿¡å·æœºåˆ¶
é¿å…é˜»å¡ä¸»çº¿ç¨‹ï¼Œæä¾›å®æ—¶è¿›åº¦æ›´æ–°ã€‚
"""

import logging
import threading
import time
from typing import Dict, Any, Optional, List, Callable
from datetime import datetime
from PyQt5.QtCore import QObject, QThread, pyqtSignal, QTimer
from PyQt5.QtWidgets import QApplication

logger = logging.getLogger(__name__)


class AsyncDataImportWorker(QThread):
    """å¼‚æ­¥æ•°æ®å¯¼å…¥å·¥ä½œçº¿ç¨‹"""

    # ä¿¡å·å®šä¹‰
    progress_updated = pyqtSignal(int, str)  # è¿›åº¦ç™¾åˆ†æ¯”, çŠ¶æ€æ¶ˆæ¯
    import_started = pyqtSignal(str)  # å¯¼å…¥ä»»åŠ¡ID
    import_completed = pyqtSignal(str, dict)  # ä»»åŠ¡ID, ç»“æœç»Ÿè®¡
    import_failed = pyqtSignal(str, str)  # ä»»åŠ¡ID, é”™è¯¯æ¶ˆæ¯
    data_chunk_imported = pyqtSignal(str, int, int)  # ä»»åŠ¡ID, å·²å¯¼å…¥æ•°é‡, æ€»æ•°é‡

    def __init__(self, import_config: dict, parent=None):
        super().__init__(parent)
        self.import_config = import_config
        self.task_id = import_config.get('task_id', f"import_{int(time.time())}")
        self._stop_requested = False
        self._import_engine = None
        self._config_manager = None  # ä¿å­˜é…ç½®ç®¡ç†å™¨å¼•ç”¨

    def run(self):
        """æ‰§è¡Œæ•°æ®å¯¼å…¥è¿‡ç¨‹"""
        try:
            logger.info(f"å¼€å§‹å¼‚æ­¥æ•°æ®å¯¼å…¥ä»»åŠ¡: {self.task_id}")
            self.import_started.emit(self.task_id)
            self.progress_updated.emit(0, "åˆå§‹åŒ–æ•°æ®å¯¼å…¥...")

            # åˆå§‹åŒ–å¯¼å…¥å¼•æ“
            logger.info("ğŸ”„ å¼€å§‹åˆå§‹åŒ–å¯¼å…¥å¼•æ“...")
            self._initialize_import_engine()
            logger.info("âœ… å¯¼å…¥å¼•æ“åˆå§‹åŒ–å®Œæˆ")

            if self._stop_requested:
                logger.info("âš ï¸ ä»»åŠ¡è¢«è¯·æ±‚åœæ­¢ï¼Œé€€å‡ºæ‰§è¡Œ")
                return
            else:
                logger.info("âœ… ä»»åŠ¡æœªè¢«åœæ­¢ï¼Œç»§ç»­æ‰§è¡Œ")

            # æ‰§è¡Œæ•°æ®å¯¼å…¥
            logger.info("ğŸš€ å¼€å§‹æ‰§è¡Œæ•°æ®å¯¼å…¥...")
            result = self._execute_import()
            logger.info(f"ğŸ“Š æ•°æ®å¯¼å…¥æ‰§è¡Œå®Œæˆï¼Œç»“æœ: {result}")

            if self._stop_requested:
                logger.info("âš ï¸ ä»»åŠ¡åœ¨æ‰§è¡Œåè¢«è¯·æ±‚åœæ­¢")
                return

            # å®Œæˆå¯¼å…¥
            self.progress_updated.emit(100, "æ•°æ®å¯¼å…¥å®Œæˆ")
            self.import_completed.emit(self.task_id, result)
            logger.info(f"âœ… å¼‚æ­¥æ•°æ®å¯¼å…¥ä»»åŠ¡å®Œæˆ: {self.task_id}")

        except Exception as e:
            logger.error(f"âŒ å¼‚æ­¥æ•°æ®å¯¼å…¥å¤±è´¥: {e}")
            import traceback
            logger.error(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}")
            self.import_failed.emit(self.task_id, str(e))

    def _initialize_import_engine(self):
        """åˆå§‹åŒ–å¯¼å…¥å¼•æ“"""
        try:
            self.progress_updated.emit(5, "åˆå§‹åŒ–å¯¼å…¥å¼•æ“...")

            # å¯¼å…¥æ•°æ®å¯¼å…¥ç›¸å…³æ¨¡å—
            from core.importdata.import_execution_engine import DataImportExecutionEngine
            from core.importdata.import_config_manager import ImportConfigManager

            # åˆ›å»ºé…ç½®ç®¡ç†å™¨å’Œæ‰§è¡Œå¼•æ“
            self._config_manager = ImportConfigManager()

            # å°è¯•ä»æœåŠ¡å®¹å™¨è·å–æ•°æ®ç®¡ç†å™¨ï¼Œé¿å…é‡å¤åˆå§‹åŒ–
            data_manager = None
            try:
                from core.containers import get_service_container
                from core.services.unified_data_manager import UnifiedDataManager

                service_container = get_service_container()
                if service_container.is_registered(UnifiedDataManager):
                    data_manager = service_container.resolve(UnifiedDataManager)
                    logger.info("âœ… ä½¿ç”¨æœåŠ¡å®¹å™¨ä¸­çš„æ•°æ®ç®¡ç†å™¨")
                else:
                    logger.info("âš ï¸ æœåŠ¡å®¹å™¨ä¸­æœªæ‰¾åˆ°æ•°æ®ç®¡ç†å™¨ï¼Œå°†å»¶è¿Ÿåˆå§‹åŒ–")
            except Exception as e:
                logger.warning(f"âš ï¸ è·å–æ•°æ®ç®¡ç†å™¨å¤±è´¥: {e}")

            self._import_engine = DataImportExecutionEngine(self._config_manager, data_manager)

            # è¿æ¥è¿›åº¦ä¿¡å·
            self._import_engine.task_progress.connect(self._on_engine_progress)

            self.progress_updated.emit(10, "å¯¼å…¥å¼•æ“åˆå§‹åŒ–å®Œæˆ")

        except Exception as e:
            logger.error(f"åˆå§‹åŒ–å¯¼å…¥å¼•æ“å¤±è´¥: {e}")
            raise

    def _execute_import(self) -> dict:
        """æ‰§è¡Œæ•°æ®å¯¼å…¥"""
        try:
            self.progress_updated.emit(15, "å¼€å§‹æ•°æ®å¯¼å…¥...")

            # è§£æå¯¼å…¥é…ç½®
            import_mode = self.import_config.get('mode', 'incremental')
            data_sources = self.import_config.get('data_sources', [])
            date_range = self.import_config.get('date_range', {})

            result = {
                'task_id': self.task_id,
                'status': 'success',
                'imported_count': 0,
                'failed_count': 0,
                'start_time': datetime.now().isoformat(),
                'data_sources': []
            }

            # æ‰§è¡ŒçœŸå®çš„æ•°æ®å¯¼å…¥é€»è¾‘
            total_sources = len(data_sources) if data_sources else 1
            logger.info(f"ğŸ“Š å¼€å§‹å¤„ç†æ•°æ®æºï¼Œæ€»æ•°: {total_sources}, æ•°æ®æºåˆ—è¡¨: {data_sources or ['default']}")

            for i, source in enumerate(data_sources or ['default']):
                if self._stop_requested:
                    break

                base_progress = 15 + (70 * i // total_sources)
                self.progress_updated.emit(base_progress, f"å¯¼å…¥æ•°æ®æº: {source}")
                logger.info(f"ğŸ”„ å¼€å§‹å¤„ç†æ•°æ®æº {i+1}/{total_sources}: {source}")

                # æ‰§è¡Œå•ä¸ªæ•°æ®æºçš„å¯¼å…¥
                source_result = self._import_single_source(source, base_progress)
                logger.info(f"ğŸ“ˆ æ•°æ®æº {source} å¤„ç†å®Œæˆ: {source_result}")
                result['data_sources'].append(source_result)
                result['imported_count'] += source_result.get('imported_count', 0)
                result['failed_count'] += source_result.get('failed_count', 0)

            result['end_time'] = datetime.now().isoformat()
            self.progress_updated.emit(90, "æ•°æ®å¯¼å…¥å¤„ç†å®Œæˆ")

            return result

        except Exception as e:
            logger.error(f"âŒ æ‰§è¡Œæ•°æ®å¯¼å…¥å¤±è´¥: {e}")
            import traceback
            logger.error(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}")
            raise

    def _import_single_source(self, source: str, base_progress: int) -> dict:
        """å¯¼å…¥å•ä¸ªæ•°æ®æº"""
        try:
            # è°ƒç”¨å®é™…çš„æ•°æ®å¯¼å…¥å¼•æ“
            if self._import_engine:
                # åˆ›å»ºä¸´æ—¶ä»»åŠ¡é…ç½®ç”¨äºå¯¼å…¥
                from core.importdata.import_config_manager import ImportTaskConfig, ImportMode, DataFrequency
                from datetime import datetime, timedelta
                import time

                # åˆ›å»ºä¸´æ—¶ä»»åŠ¡ID
                temp_task_id = f"async_import_{source}_{int(time.time())}"

                # åˆ›å»ºä»»åŠ¡é…ç½® - ä½¿ç”¨å®Œæ•´çš„é…ç½®å‚æ•°
                task_config = ImportTaskConfig(
                    task_id=temp_task_id,
                    name=f"å¼‚æ­¥å¯¼å…¥_{source}",
                    data_source=source,  # æ·»åŠ å¿…éœ€å‚æ•°ï¼šæ•°æ®æºåç§°
                    asset_type="è‚¡ç¥¨",    # æ·»åŠ å¿…éœ€å‚æ•°ï¼šèµ„äº§ç±»å‹
                    data_type="Kçº¿æ•°æ®",  # æ·»åŠ å¿…éœ€å‚æ•°ï¼šæ•°æ®ç±»å‹
                    mode=ImportMode.BATCH,  # ä¿®å¤ï¼šä½¿ç”¨å­˜åœ¨çš„æšä¸¾å€¼
                    symbols=['000001'],  # ç®€åŒ–ä¸ºå•ä¸ªæµ‹è¯•è‚¡ç¥¨ä»£ç 
                    frequency=DataFrequency.DAILY,
                    start_date=(datetime.now() - timedelta(days=7)).strftime('%Y-%m-%d'),  # ç¼©çŸ­ä¸º7å¤©
                    end_date=datetime.now().strftime('%Y-%m-%d'),
                    batch_size=50,  # å‡å°æ‰¹å¤„ç†å¤§å°
                    max_workers=1   # å‡å°‘å¹¶å‘æ•°
                )

                # å°†ä»»åŠ¡é…ç½®æ·»åŠ åˆ°é…ç½®ç®¡ç†å™¨ï¼ˆä½¿ç”¨åŒä¸€ä¸ªå®ä¾‹ï¼‰
                if not self._config_manager:
                    logger.error("âŒ é…ç½®ç®¡ç†å™¨æœªåˆå§‹åŒ–")
                    return {
                        'source': source,
                        'imported_count': 0,
                        'failed_count': 1,
                        'status': 'failed',
                        'error': 'é…ç½®ç®¡ç†å™¨æœªåˆå§‹åŒ–'
                    }

                self._config_manager.add_import_task(task_config)
                logger.info(f"âœ… ä»»åŠ¡é…ç½®å·²æ·»åŠ åˆ°é…ç½®ç®¡ç†å™¨: {temp_task_id}")

                # å¯åŠ¨ä»»åŠ¡
                logger.info(f"ğŸš€ å°è¯•å¯åŠ¨å¯¼å…¥ä»»åŠ¡: {temp_task_id}")
                success = self._import_engine.start_task(temp_task_id)
                logger.info(f"ğŸ“Š ä»»åŠ¡å¯åŠ¨ç»“æœ: {success}")

                if success:
                    # ç­‰å¾…ä»»åŠ¡å®Œæˆï¼ˆç®€åŒ–å¤„ç†ï¼‰
                    max_wait = 30  # æœ€å¤šç­‰å¾…30ç§’
                    wait_count = 0

                    while wait_count < max_wait:
                        task_result = self._import_engine.get_task_status(temp_task_id)
                        if task_result and task_result.status.name in ['COMPLETED', 'FAILED']:
                            break
                        time.sleep(1)
                        wait_count += 1

                        # æ›´æ–°è¿›åº¦
                        progress = base_progress + (20 * wait_count // max_wait)
                        self.progress_updated.emit(progress, f"æ­£åœ¨å¯¼å…¥ {source}...")

                    # è·å–æœ€ç»ˆç»“æœ
                    final_result = self._import_engine.get_task_status(temp_task_id)
                    if final_result:
                        return {
                            'source': source,
                            'imported_count': final_result.processed_records,
                            'failed_count': final_result.failed_records,
                            'status': 'completed' if final_result.status.name == 'COMPLETED' else 'failed'
                        }
                    else:
                        return {
                            'source': source,
                            'imported_count': 0,
                            'failed_count': 1,
                            'status': 'failed',
                            'error': 'ä»»åŠ¡æ‰§è¡Œè¶…æ—¶'
                        }
                else:
                    return {
                        'source': source,
                        'imported_count': 0,
                        'failed_count': 1,
                        'status': 'failed',
                        'error': 'ä»»åŠ¡å¯åŠ¨å¤±è´¥'
                    }
            else:
                # æ²¡æœ‰å¯¼å…¥å¼•æ“ï¼Œè®°å½•é”™è¯¯
                logger.error(f"å¯¼å…¥å¼•æ“ä¸å¯ç”¨ï¼Œæ— æ³•å¯¼å…¥æ•°æ®æº: {source}")
                return {
                    'source': source,
                    'imported_count': 0,
                    'failed_count': 1,
                    'status': 'failed',
                    'error': 'å¯¼å…¥å¼•æ“ä¸å¯ç”¨'
                }

        except Exception as e:
            logger.error(f"å¯¼å…¥æ•°æ®æº {source} å¤±è´¥: {e}")
            return {
                'source': source,
                'imported_count': 0,
                'failed_count': 1,
                'status': 'failed',
                'error': str(e)
            }

    def _on_engine_progress(self, task_id: str, progress: float, message: str):
        """å¤„ç†å¯¼å…¥å¼•æ“çš„è¿›åº¦æ›´æ–°"""
        self.progress_updated.emit(int(progress), message)

    def stop(self):
        """åœæ­¢æ•°æ®å¯¼å…¥"""
        self._stop_requested = True
        if self._import_engine:
            # åœæ­¢å¯¼å…¥å¼•æ“
            try:
                self._import_engine.stop_all_tasks()
            except Exception as e:
                logger.warning(f"åœæ­¢å¯¼å…¥å¼•æ“å¤±è´¥: {e}")

        self.quit()
        self.wait(5000)  # ç­‰å¾…æœ€å¤š5ç§’


class AsyncDataImportManager(QObject):
    """å¼‚æ­¥æ•°æ®å¯¼å…¥ç®¡ç†å™¨"""

    # ä¿¡å·å®šä¹‰
    import_started = pyqtSignal(str)  # ä»»åŠ¡ID
    progress_updated = pyqtSignal(int, str)  # è¿›åº¦, æ¶ˆæ¯
    import_completed = pyqtSignal(str, dict)  # ä»»åŠ¡ID, ç»“æœ
    import_failed = pyqtSignal(str, str)  # ä»»åŠ¡ID, é”™è¯¯æ¶ˆæ¯
    data_chunk_imported = pyqtSignal(str, int, int)  # ä»»åŠ¡ID, å·²å¯¼å…¥, æ€»æ•°

    def __init__(self, parent=None):
        super().__init__(parent)
        self.active_workers: Dict[str, AsyncDataImportWorker] = {}
        self.import_history: List[dict] = []

    def start_import(self, import_config: dict) -> str:
        """å¼€å§‹å¼‚æ­¥æ•°æ®å¯¼å…¥"""
        try:
            task_id = import_config.get('task_id', f"import_{int(time.time())}")

            if task_id in self.active_workers:
                logger.warning(f"å¯¼å…¥ä»»åŠ¡å·²å­˜åœ¨: {task_id}")
                return task_id

            logger.info(f"å¯åŠ¨å¼‚æ­¥æ•°æ®å¯¼å…¥ä»»åŠ¡: {task_id}")

            # åˆ›å»ºå·¥ä½œçº¿ç¨‹
            worker = AsyncDataImportWorker(import_config)

            # è¿æ¥ä¿¡å·
            worker.import_started.connect(self.import_started.emit)
            worker.progress_updated.connect(self.progress_updated.emit)
            worker.import_completed.connect(self._on_import_completed)
            worker.import_failed.connect(self._on_import_failed)
            worker.data_chunk_imported.connect(self.data_chunk_imported.emit)

            # å¯åŠ¨å·¥ä½œçº¿ç¨‹
            worker.start()
            self.active_workers[task_id] = worker

            logger.info(f"å¼‚æ­¥æ•°æ®å¯¼å…¥ä»»åŠ¡å·²å¯åŠ¨: {task_id}")
            return task_id

        except Exception as e:
            logger.error(f"å¯åŠ¨å¼‚æ­¥æ•°æ®å¯¼å…¥å¤±è´¥: {e}")
            raise

    def stop_import(self, task_id: str) -> bool:
        """åœæ­¢æ•°æ®å¯¼å…¥ä»»åŠ¡"""
        if task_id not in self.active_workers:
            logger.warning(f"å¯¼å…¥ä»»åŠ¡ä¸å­˜åœ¨: {task_id}")
            return False

        try:
            logger.info(f"åœæ­¢æ•°æ®å¯¼å…¥ä»»åŠ¡: {task_id}")
            worker = self.active_workers[task_id]
            worker.stop()
            del self.active_workers[task_id]
            return True

        except Exception as e:
            logger.error(f"åœæ­¢æ•°æ®å¯¼å…¥ä»»åŠ¡å¤±è´¥: {e}")
            return False

    def stop_all_imports(self):
        """åœæ­¢æ‰€æœ‰å¯¼å…¥ä»»åŠ¡"""
        logger.info("åœæ­¢æ‰€æœ‰æ•°æ®å¯¼å…¥ä»»åŠ¡...")
        for task_id in list(self.active_workers.keys()):
            self.stop_import(task_id)

    def get_active_imports(self) -> List[str]:
        """è·å–æ´»è·ƒçš„å¯¼å…¥ä»»åŠ¡åˆ—è¡¨"""
        return list(self.active_workers.keys())

    def get_import_history(self) -> List[dict]:
        """è·å–å¯¼å…¥å†å²è®°å½•"""
        return self.import_history.copy()

    def _on_import_completed(self, task_id: str, result: dict):
        """å¯¼å…¥å®Œæˆå¤„ç†"""
        if task_id in self.active_workers:
            del self.active_workers[task_id]

        # è®°å½•åˆ°å†å²
        self.import_history.append({
            'task_id': task_id,
            'status': 'completed',
            'result': result,
            'timestamp': datetime.now().isoformat()
        })

        self.import_completed.emit(task_id, result)
        logger.info(f"æ•°æ®å¯¼å…¥ä»»åŠ¡å®Œæˆ: {task_id}")

    def _on_import_failed(self, task_id: str, error_msg: str):
        """å¯¼å…¥å¤±è´¥å¤„ç†"""
        if task_id in self.active_workers:
            del self.active_workers[task_id]

        # è®°å½•åˆ°å†å²
        self.import_history.append({
            'task_id': task_id,
            'status': 'failed',
            'error': error_msg,
            'timestamp': datetime.now().isoformat()
        })

        self.import_failed.emit(task_id, error_msg)
        logger.error(f"æ•°æ®å¯¼å…¥ä»»åŠ¡å¤±è´¥: {task_id} - {error_msg}")


# å…¨å±€æœåŠ¡å®ä¾‹
_async_data_import_manager = None


def get_async_data_import_manager() -> AsyncDataImportManager:
    """è·å–å¼‚æ­¥æ•°æ®å¯¼å…¥ç®¡ç†å™¨å®ä¾‹"""
    global _async_data_import_manager
    if _async_data_import_manager is None:
        _async_data_import_manager = AsyncDataImportManager()
    return _async_data_import_manager
