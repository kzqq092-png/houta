#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å‘Šè­¦è§„åˆ™æ‰§è¡Œå¼•æ“

æä¾›å®Œæ•´çš„å‘Šè­¦è§„åˆ™ç›‘æ§ã€æ‰§è¡Œå’Œç®¡ç†åŠŸèƒ½
æ”¯æŒå¼‚æ­¥è¿è¡Œã€çƒ­åŠ è½½å’Œå®æ—¶åŒæ­¥
"""

import asyncio
import logging
import time
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Callable, Set
from dataclasses import dataclass
from enum import Enum
import threading

from ..events import EventBus
from .base_service import BaseService
from .alert_deduplication_service import AlertMessage, AlertLevel, get_alert_deduplication_service
from db.models.alert_config_models import get_alert_config_database, AlertRule, AlertHistory

logger = logging.getLogger(__name__)


class RuleStatus(Enum):
    """è§„åˆ™çŠ¶æ€æšä¸¾"""
    ACTIVE = "active"          # æ´»è·ƒè¿è¡Œä¸­
    INACTIVE = "inactive"      # æœªæ¿€æ´»
    ERROR = "error"           # é”™è¯¯çŠ¶æ€
    LOADING = "loading"       # åŠ è½½ä¸­


@dataclass
class RuleExecutionContext:
    """è§„åˆ™æ‰§è¡Œä¸Šä¸‹æ–‡"""
    rule_id: int
    rule: AlertRule
    current_metrics: Dict[str, Any]
    execution_time: datetime
    last_trigger_time: Optional[datetime] = None
    trigger_count: int = 0
    consecutive_triggers: int = 0
    is_silenced: bool = False


@dataclass
class MetricValue:
    """æŒ‡æ ‡å€¼æ•°æ®ç±»"""
    name: str
    value: float
    unit: str
    timestamp: datetime
    source: str = "system"


class AlertRuleEngine(BaseService):
    """
    å‘Šè­¦è§„åˆ™æ‰§è¡Œå¼•æ“

    åŠŸèƒ½ç‰¹æ€§ï¼š
    1. å¼‚æ­¥è§„åˆ™ç›‘æ§å’Œæ‰§è¡Œ
    2. çƒ­åŠ è½½æœºåˆ¶ï¼ˆé…ç½®å˜æ›´æ—¶è‡ªåŠ¨é‡è½½ï¼‰
    3. å®æ—¶å‘Šè­¦å†å²åŒæ­¥
    4. è§„åˆ™æ‰§è¡ŒçŠ¶æ€ç®¡ç†
    5. æ™ºèƒ½é™é»˜å’Œå»é‡
    6. æ€§èƒ½ä¼˜åŒ–å’Œèµ„æºç®¡ç†
    """

    def __init__(self, event_bus: Optional[EventBus] = None):
        super().__init__()

        # æ ¸å¿ƒç»„ä»¶
        self.db = get_alert_config_database()
        self.alert_service = get_alert_deduplication_service()

        # è¿è¡Œæ—¶çŠ¶æ€
        self._running = False
        self._rules_cache: Dict[int, AlertRule] = {}
        self._rule_contexts: Dict[int, RuleExecutionContext] = {}
        self._rule_status: Dict[int, RuleStatus] = {}
        self._metrics_cache: Dict[str, MetricValue] = {}

        # å¼‚æ­¥ç»„ä»¶
        self._loop: Optional[asyncio.AbstractEventLoop] = None
        self._monitor_task: Optional[asyncio.Task] = None
        self._reload_task: Optional[asyncio.Task] = None
        self._cleanup_task: Optional[asyncio.Task] = None

        # é…ç½®å‚æ•°
        self.check_interval = 10.0  # è§„åˆ™æ£€æŸ¥é—´éš”ï¼ˆç§’ï¼‰
        self.reload_check_interval = 30.0  # çƒ­åŠ è½½æ£€æŸ¥é—´éš”ï¼ˆç§’ï¼‰
        self.cleanup_interval = 300.0  # æ¸…ç†é—´éš”ï¼ˆç§’ï¼‰
        self.max_history_age_days = 30  # å†å²è®°å½•ä¿ç•™å¤©æ•°

        # æ€§èƒ½ç»Ÿè®¡
        self.stats = {
            'total_checks': 0,
            'triggered_alerts': 0,
            'suppressed_alerts': 0,
            'rule_reloads': 0,
            'execution_errors': 0,
            'average_check_time': 0.0
        }

        # çº¿ç¨‹å®‰å…¨é”
        self._lock = threading.RLock()

        logger.info("å‘Šè­¦è§„åˆ™æ‰§è¡Œå¼•æ“åˆå§‹åŒ–å®Œæˆ")

    def _do_initialize(self) -> None:
        """åˆå§‹åŒ–æœåŠ¡"""
        try:
            # åŠ è½½åˆå§‹è§„åˆ™
            self._load_rules()

            # åˆå§‹åŒ–æŒ‡æ ‡æ•°æ®æºè¿æ¥
            self._setup_metric_sources()

            logger.info("å‘Šè­¦è§„åˆ™æ‰§è¡Œå¼•æ“åˆå§‹åŒ–æˆåŠŸ")

        except Exception as e:
            logger.error(f"å‘Šè­¦è§„åˆ™æ‰§è¡Œå¼•æ“åˆå§‹åŒ–å¤±è´¥: {e}")
            raise

    def start(self) -> None:
        """å¯åŠ¨å¼•æ“"""
        if self._running:
            logger.warning("å‘Šè­¦è§„åˆ™å¼•æ“å·²åœ¨è¿è¡Œ")
            return

        try:
            self._running = True
            logger.info("å‘Šè­¦å¼•æ“å¯åŠ¨ä¸­...")

            # æ£€æŸ¥æ˜¯å¦æœ‰è¿è¡Œçš„äº‹ä»¶å¾ªç¯
            try:
                self._loop = asyncio.get_running_loop()
                # å¼‚æ­¥æ¨¡å¼ï¼šå¯åŠ¨åå°ä»»åŠ¡
                self._start_async_tasks()
                logger.info("ğŸš€ å‘Šè­¦è§„åˆ™å¼•æ“å·²å¯åŠ¨ - å¼‚æ­¥æ¨¡å¼")

            except RuntimeError:
                # åŒæ­¥æ¨¡å¼ï¼šåœ¨æ–°çº¿ç¨‹ä¸­è¿è¡Œäº‹ä»¶å¾ªç¯
                self._start_sync_mode()
                logger.info("ğŸš€ å‘Šè­¦è§„åˆ™å¼•æ“å·²å¯åŠ¨ - åŒæ­¥æ¨¡å¼")

            logger.info("å‘Šè­¦å¼•æ“è¿è¡Œä¸­")

        except Exception as e:
            self._running = False
            logger.error("å‘Šè­¦å¼•æ“å¯åŠ¨å¤±è´¥")
            logger.error(f"å¯åŠ¨å‘Šè­¦è§„åˆ™å¼•æ“å¤±è´¥: {e}")
            raise

    def stop(self) -> None:
        """åœæ­¢å¼•æ“"""
        if not self._running:
            return

        try:
            self._running = False
            logger.info("å‘Šè­¦å¼•æ“åœæ­¢ä¸­...")

            # å–æ¶ˆæ‰€æœ‰ä»»åŠ¡
            if self._monitor_task and not self._monitor_task.done():
                self._monitor_task.cancel()
            if self._reload_task and not self._reload_task.done():
                self._reload_task.cancel()
            if self._cleanup_task and not self._cleanup_task.done():
                self._cleanup_task.cancel()

            logger.info("å‘Šè­¦è§„åˆ™å¼•æ“å·²åœæ­¢")
            logger.info("å‘Šè­¦å¼•æ“å·²åœæ­¢")

        except Exception as e:
            logger.error(f"åœæ­¢å‘Šè­¦è§„åˆ™å¼•æ“å¤±è´¥: {e}")

    def _start_async_tasks(self) -> None:
        """å¯åŠ¨å¼‚æ­¥ä»»åŠ¡"""
        if self._loop:
            self._monitor_task = self._loop.create_task(self._monitor_rules_loop())
            self._reload_task = self._loop.create_task(self._hot_reload_loop())
            self._cleanup_task = self._loop.create_task(self._cleanup_loop())
            logger.info("âœ… å¼‚æ­¥ç›‘æ§ä»»åŠ¡å·²å¯åŠ¨")

    def _start_sync_mode(self) -> None:
        """å¯åŠ¨åŒæ­¥æ¨¡å¼ï¼ˆæ–°çº¿ç¨‹è¿è¡Œäº‹ä»¶å¾ªç¯ï¼‰"""
        import time

        def run_loop():
            self._loop = asyncio.new_event_loop()
            asyncio.set_event_loop(self._loop)
            try:
                self._start_async_tasks()
                self._loop.run_forever()
            except Exception as e:
                logger.error(f"äº‹ä»¶å¾ªç¯è¿è¡Œå¤±è´¥: {e}")
            finally:
                self._loop.close()

        thread = threading.Thread(target=run_loop, daemon=True)
        thread.start()

        # ç­‰å¾…äº‹ä»¶å¾ªç¯å¯åŠ¨
        time.sleep(0.2)

    async def _monitor_rules_loop(self) -> None:
        """è§„åˆ™ç›‘æ§å¾ªç¯"""
        logger.info("å¼€å§‹å‘Šè­¦è§„åˆ™ç›‘æ§å¾ªç¯")

        while self._running:
            try:
                start_time = time.time()

                # æ”¶é›†å½“å‰æŒ‡æ ‡æ•°æ®
                await self._collect_metrics()

                # æ‰§è¡Œæ‰€æœ‰æ´»è·ƒè§„åˆ™
                await self._execute_rules()

                # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
                execution_time = time.time() - start_time
                self._update_stats(execution_time)

                # ç­‰å¾…ä¸‹ä¸€ä¸ªæ£€æŸ¥å‘¨æœŸ
                await asyncio.sleep(self.check_interval)

            except asyncio.CancelledError:
                logger.info("è§„åˆ™ç›‘æ§å¾ªç¯è¢«å–æ¶ˆ")
                break
            except Exception as e:
                logger.error(f"è§„åˆ™ç›‘æ§å¾ªç¯å¼‚å¸¸: {e}")
                self.stats['execution_errors'] += 1
                await asyncio.sleep(5)  # é”™è¯¯åçŸ­æš‚ç­‰å¾…

    async def _hot_reload_loop(self) -> None:
        """çƒ­åŠ è½½å¾ªç¯"""
        logger.info("å¼€å§‹çƒ­åŠ è½½ç›‘æ§å¾ªç¯")
        last_reload_time = datetime.now()

        while self._running:
            try:
                # æ£€æŸ¥æ•°æ®åº“ä¸­è§„åˆ™çš„æ›´æ–°æ—¶é—´
                if await self._check_rules_updated(last_reload_time):
                    logger.info("æ£€æµ‹åˆ°è§„åˆ™é…ç½®å˜æ›´ï¼Œæ‰§è¡Œçƒ­åŠ è½½")
                    await self._reload_rules()
                    last_reload_time = datetime.now()
                    self.stats['rule_reloads'] += 1

                await asyncio.sleep(self.reload_check_interval)

            except asyncio.CancelledError:
                logger.info("çƒ­åŠ è½½å¾ªç¯è¢«å–æ¶ˆ")
                break
            except Exception as e:
                logger.error(f"çƒ­åŠ è½½å¾ªç¯å¼‚å¸¸: {e}")
                await asyncio.sleep(10)

    async def _cleanup_loop(self) -> None:
        """æ¸…ç†å¾ªç¯"""
        logger.info("å¼€å§‹æ¸…ç†ä»»åŠ¡å¾ªç¯")

        while self._running:
            try:
                # æ¸…ç†è¿‡æœŸçš„å‘Šè­¦å†å²
                await self._cleanup_old_history()

                # æ¸…ç†è¿‡æœŸçš„æŒ‡æ ‡ç¼“å­˜
                await self._cleanup_metrics_cache()

                # æ¸…ç†è§„åˆ™æ‰§è¡Œä¸Šä¸‹æ–‡
                await self._cleanup_rule_contexts()

                await asyncio.sleep(self.cleanup_interval)

            except asyncio.CancelledError:
                logger.info("æ¸…ç†å¾ªç¯è¢«å–æ¶ˆ")
                break
            except Exception as e:
                logger.error(f"æ¸…ç†å¾ªç¯å¼‚å¸¸: {e}")
                await asyncio.sleep(30)

    async def _collect_metrics(self) -> None:
        """æ”¶é›†å½“å‰æŒ‡æ ‡æ•°æ®"""
        try:
            current_time = datetime.now()

            # æ”¶é›†ç³»ç»Ÿèµ„æºæŒ‡æ ‡
            system_metrics = await self._collect_system_metrics()

            # æ”¶é›†åº”ç”¨æŒ‡æ ‡
            app_metrics = await self._collect_application_metrics()

            # æ›´æ–°æŒ‡æ ‡ç¼“å­˜
            with self._lock:
                self._metrics_cache.update(system_metrics)
                self._metrics_cache.update(app_metrics)

            # å‘é€æŒ‡æ ‡æ›´æ–°ä¿¡å·
            metrics_data = {name: metric.value for name, metric in self._metrics_cache.items()}
            logger.debug(f"æŒ‡æ ‡æ•°æ®å·²æ›´æ–°: {list(metrics_data.keys())}")

        except Exception as e:
            logger.error(f"æ”¶é›†æŒ‡æ ‡æ•°æ®å¤±è´¥: {e}")

    async def _collect_system_metrics(self) -> Dict[str, MetricValue]:
        """æ”¶é›†ç³»ç»ŸæŒ‡æ ‡"""
        metrics = {}
        current_time = datetime.now()

        try:
            import psutil

            # CPUä½¿ç”¨ç‡
            cpu_percent = psutil.cpu_percent(interval=0.1)
            metrics['cpu_usage'] = MetricValue(
                name='cpu_usage',
                value=cpu_percent,
                unit='%',
                timestamp=current_time,
                source='system'
            )

            # å†…å­˜ä½¿ç”¨ç‡
            memory = psutil.virtual_memory()
            metrics['memory_usage'] = MetricValue(
                name='memory_usage',
                value=memory.percent,
                unit='%',
                timestamp=current_time,
                source='system'
            )

            # ç£ç›˜ä½¿ç”¨ç‡
            disk = psutil.disk_usage('/')
            metrics['disk_usage'] = MetricValue(
                name='disk_usage',
                value=disk.percent,
                unit='%',
                timestamp=current_time,
                source='system'
            )

        except Exception as e:
            logger.error(f"æ”¶é›†ç³»ç»ŸæŒ‡æ ‡å¤±è´¥: {e}")

        return metrics

    async def _collect_application_metrics(self) -> Dict[str, MetricValue]:
        """æ”¶é›†åº”ç”¨æŒ‡æ ‡"""
        metrics = {}
        current_time = datetime.now()

        try:
            # ä»æŒ‡æ ‡èšåˆæœåŠ¡è·å–åº”ç”¨æŒ‡æ ‡
            from core.containers import get_service_container
            service_container = get_service_container()

            try:
                aggregation_service = service_container.resolve_by_name('MetricsAggregationService')
                if aggregation_service:
                    recent_metrics = aggregation_service.get_recent_metrics()

                    for metric_name, metric_data in recent_metrics.items():
                        if isinstance(metric_data, (int, float)):
                            metrics[f'app_{metric_name}'] = MetricValue(
                                name=f'app_{metric_name}',
                                value=float(metric_data),
                                unit='ms' if 'time' in metric_name else 'count',
                                timestamp=current_time,
                                source='application'
                            )
            except Exception as e:
                logger.debug(f"è·å–åº”ç”¨æŒ‡æ ‡å¤±è´¥: {e}")

        except Exception as e:
            logger.error(f"æ”¶é›†åº”ç”¨æŒ‡æ ‡å¤±è´¥: {e}")

        return metrics

    async def _execute_rules(self) -> None:
        """æ‰§è¡Œæ‰€æœ‰è§„åˆ™"""
        with self._lock:
            active_rules = [rule for rule in self._rules_cache.values() if rule.enabled]

        for rule in active_rules:
            try:
                await self._execute_single_rule(rule)

            except Exception as e:
                logger.error(f"æ‰§è¡Œè§„åˆ™ {rule.id} å¤±è´¥: {e}")
                self._update_rule_status(rule.id, RuleStatus.ERROR)

    async def _execute_single_rule(self, rule: AlertRule) -> None:
        """æ‰§è¡Œå•ä¸ªè§„åˆ™"""
        rule_id = rule.id
        current_time = datetime.now()

        # è·å–æˆ–åˆ›å»ºè§„åˆ™æ‰§è¡Œä¸Šä¸‹æ–‡
        context = self._get_rule_context(rule_id, rule)

        # æ£€æŸ¥é™é»˜æœŸ
        if self._is_rule_silenced(rule, context, current_time):
            return

        # è·å–æŒ‡æ ‡å€¼
        metric_value = self._get_metric_value(rule.metric_name)
        if metric_value is None:
            logger.debug(f"è§„åˆ™ {rule_id} çš„æŒ‡æ ‡ {rule.metric_name} æ— æ•°æ®")
            return

        # è¯„ä¼°è§„åˆ™æ¡ä»¶
        triggered = self._evaluate_rule_condition(rule, metric_value.value)

        if triggered:
            # æ£€æŸ¥æŒç»­æ—¶é—´è¦æ±‚
            if self._check_duration_requirement(context, current_time, rule.duration):
                await self._trigger_alert(rule, metric_value, context)
                context.consecutive_triggers += 1
                context.last_trigger_time = current_time
                context.trigger_count += 1
            else:
                context.consecutive_triggers += 1
        else:
            # é‡ç½®è¿ç»­è§¦å‘è®¡æ•°
            context.consecutive_triggers = 0

        # æ›´æ–°ä¸Šä¸‹æ–‡
        context.execution_time = current_time
        context.current_metrics = {rule.metric_name: metric_value.value}

    def _get_rule_context(self, rule_id: int, rule: AlertRule) -> RuleExecutionContext:
        """è·å–æˆ–åˆ›å»ºè§„åˆ™æ‰§è¡Œä¸Šä¸‹æ–‡"""
        if rule_id not in self._rule_contexts:
            self._rule_contexts[rule_id] = RuleExecutionContext(
                rule_id=rule_id,
                rule=rule,
                current_metrics={},
                execution_time=datetime.now()
            )
        return self._rule_contexts[rule_id]

    def _is_rule_silenced(self, rule: AlertRule, context: RuleExecutionContext, current_time: datetime) -> bool:
        """æ£€æŸ¥è§„åˆ™æ˜¯å¦åœ¨é™é»˜æœŸå†…"""
        if not context.last_trigger_time:
            return False

        # ä½¿ç”¨è§„åˆ™é…ç½®çš„é™é»˜æœŸ
        silence_duration = timedelta(seconds=getattr(rule, 'silence_period', 300))
        return current_time - context.last_trigger_time < silence_duration

    def _get_metric_value(self, metric_name: str) -> Optional[MetricValue]:
        """è·å–æŒ‡æ ‡å€¼"""
        # é¦–å…ˆå°è¯•ä»ç¼“å­˜è·å–
        with self._lock:
            cached_value = self._metrics_cache.get(metric_name)
            # å¦‚æœç¼“å­˜æ•°æ®è¾ƒæ–°ï¼ˆ1åˆ†é’Ÿå†…ï¼‰ï¼Œç›´æ¥è¿”å›
            if cached_value and (datetime.now() - cached_value.timestamp).total_seconds() < 60:
                return cached_value

        # ç¼“å­˜æ²¡æœ‰æˆ–è¿‡æœŸï¼Œä»æŒ‡æ ‡æœåŠ¡è·å–å®æ—¶æ•°æ®
        current_value = self._fetch_realtime_metric(metric_name)
        if current_value is not None:
            metric_value = MetricValue(
                name=metric_name,
                value=current_value,
                timestamp=datetime.now(),
                unit=self._get_metric_unit(metric_name)
            )

            # æ›´æ–°ç¼“å­˜
            with self._lock:
                self._metrics_cache[metric_name] = metric_value

            return metric_value

        return None

    def _fetch_realtime_metric(self, metric_name: str) -> Optional[float]:
        """ä»æŒ‡æ ‡æœåŠ¡è·å–å®æ—¶æŒ‡æ ‡å€¼"""
        try:
            metric_name_lower = metric_name.lower()

            # ç³»ç»Ÿèµ„æºæœåŠ¡åªè´Ÿè´£é‡‡é›†ï¼Œä¸æä¾›ç›´æ¥æŸ¥è¯¢æ¥å£
            # æ‰€ä»¥æˆ‘ä»¬ä¸»è¦ä¾èµ–æŒ‡æ ‡èšåˆæœåŠ¡

            # å¦‚æœæœ‰æŒ‡æ ‡èšåˆæœåŠ¡ï¼Œå°è¯•ä½¿ç”¨
            if self.metrics_service:
                try:
                    # ä»æŒ‡æ ‡èšåˆæœåŠ¡è·å–æœ€æ–°æ•°æ®
                    if hasattr(self.metrics_service, 'resource_metrics'):
                        # CPUä½¿ç”¨ç‡
                        if 'cpu' in metric_name_lower and self.metrics_service.resource_metrics.get('cpu'):
                            return self._get_latest_metric_value(self.metrics_service.resource_metrics['cpu'])
                        # å†…å­˜ä½¿ç”¨ç‡
                        elif 'memory' in metric_name_lower and self.metrics_service.resource_metrics.get('memory'):
                            return self._get_latest_metric_value(self.metrics_service.resource_metrics['memory'])
                        # ç£ç›˜ä½¿ç”¨ç‡
                        elif 'disk' in metric_name_lower and self.metrics_service.resource_metrics.get('disk'):
                            return self._get_latest_metric_value(self.metrics_service.resource_metrics['disk'])

                    # ä»åº”ç”¨æŒ‡æ ‡è·å–å…¶ä»–ç±»å‹æ•°æ®
                    if hasattr(self.metrics_service, 'app_metrics'):
                        # å“åº”æ—¶é—´
                        if 'response_time' in metric_name_lower or 'å“åº”æ—¶é—´' in metric_name:
                            response_metrics = self.metrics_service.app_metrics.get('response_time', [])
                            return self._get_latest_metric_value(response_metrics)
                        # é”™è¯¯ç‡
                        elif 'error_rate' in metric_name_lower or 'é”™è¯¯ç‡' in metric_name:
                            error_metrics = self.metrics_service.app_metrics.get('error_rate', [])
                            return self._get_latest_metric_value(error_metrics)
                        # ååé‡
                        elif 'throughput' in metric_name_lower or 'ååé‡' in metric_name:
                            throughput_metrics = self.metrics_service.app_metrics.get('throughput', [])
                            return self._get_latest_metric_value(throughput_metrics)
                        # è¿æ¥æ•°
                        elif 'connection' in metric_name_lower or 'è¿æ¥æ•°' in metric_name:
                            connection_metrics = self.metrics_service.app_metrics.get('connections', [])
                            return self._get_latest_metric_value(connection_metrics)
                        # ç½‘ç»œæµé‡
                        elif 'network' in metric_name_lower or 'ç½‘ç»œæµé‡' in metric_name:
                            network_metrics = self.metrics_service.app_metrics.get('network_traffic', [])
                            return self._get_latest_metric_value(network_metrics)

                except Exception as e:
                    logger.debug(f"ä»æŒ‡æ ‡èšåˆæœåŠ¡è·å– {metric_name} å¤±è´¥: {e}")

                    # æ²¡æœ‰æŒ‡æ ‡æœåŠ¡æ—¶ï¼Œè¿”å›None
            logger.debug(f"æ— æ³•è·å–æŒ‡æ ‡ {metric_name}: æ²¡æœ‰å¯ç”¨çš„æŒ‡æ ‡æœåŠ¡")
            return None

        except Exception as e:
            logger.error(f"è·å–æŒ‡æ ‡ {metric_name} å¤±è´¥: {e}")
            return None

    def _get_latest_metric_value(self, metrics_list: List) -> Optional[float]:
        """ä»æŒ‡æ ‡åˆ—è¡¨ä¸­è·å–æœ€æ–°å€¼"""
        if not metrics_list:
            return None

        latest_metric = metrics_list[-1]
        if isinstance(latest_metric, dict):
            return latest_metric.get('value', 0.0)
        else:
            return float(latest_metric)

    def _get_metric_unit(self, metric_name: str) -> str:
        """è·å–æŒ‡æ ‡å•ä½"""
        metric_name_lower = metric_name.lower()

        # ç™¾åˆ†æ¯”ç±»æŒ‡æ ‡
        if any(word in metric_name_lower for word in ['cpu', 'memory', 'disk', 'usage', 'percent', 'ä½¿ç”¨ç‡', 'é”™è¯¯ç‡']):
            return '%'
        # æ—¶é—´ç±»æŒ‡æ ‡
        elif any(word in metric_name_lower for word in ['time', 'duration', 'latency', 'response', 'å“åº”æ—¶é—´']):
            return 'ms'
        # æµé‡ç±»æŒ‡æ ‡
        elif any(word in metric_name_lower for word in ['network', 'traffic', 'throughput', 'ç½‘ç»œæµé‡', 'ååé‡']):
            return 'MB/s'
        # è®¡æ•°ç±»æŒ‡æ ‡
        elif any(word in metric_name_lower for word in ['count', 'number', 'total', 'connection', 'è¿æ¥æ•°', 'æ¬¡/ç§’']):
            return 'count'
        # å†…å­˜å¤§å°ç±»æŒ‡æ ‡
        elif any(word in metric_name_lower for word in ['memory_size', 'buffer', 'cache']):
            return 'MB'
        else:
            return 'unit'

    def _evaluate_rule_condition(self, rule: AlertRule, current_value: float) -> bool:
        """è¯„ä¼°è§„åˆ™æ¡ä»¶"""
        threshold = rule.threshold_value
        operator = rule.operator

        if operator == '>':
            return current_value > threshold
        elif operator == '>=':
            return current_value >= threshold
        elif operator == '<':
            return current_value < threshold
        elif operator == '<=':
            return current_value <= threshold
        elif operator == '==':
            return abs(current_value - threshold) < 0.001
        elif operator == '!=':
            return abs(current_value - threshold) >= 0.001
        else:
            logger.warning(f"æœªçŸ¥çš„æ¯”è¾ƒæ“ä½œç¬¦: {operator}")
            return False

    def _check_duration_requirement(self, context: RuleExecutionContext,
                                    current_time: datetime, duration_seconds: int) -> bool:
        """æ£€æŸ¥æŒç»­æ—¶é—´è¦æ±‚"""
        if duration_seconds <= 0:
            return True

        # ç®€åŒ–å®ç°ï¼šæ£€æŸ¥è¿ç»­è§¦å‘æ¬¡æ•°
        # å®é™…åº”è¯¥æ ¹æ®æ£€æŸ¥é—´éš”å’ŒæŒç»­æ—¶é—´è®¡ç®—
        required_triggers = max(1, duration_seconds // int(self.check_interval))
        return context.consecutive_triggers >= required_triggers

    async def _trigger_alert(self, rule: AlertRule, metric_value: MetricValue,
                             context: RuleExecutionContext) -> None:
        """è§¦å‘å‘Šè­¦"""
        try:
            # åˆ›å»ºå‘Šè­¦æ¶ˆæ¯
            alert = AlertMessage(
                id=f"rule_{rule.id}_{int(time.time())}",
                timestamp=datetime.now(),
                level=self._get_alert_level(rule, metric_value.value),
                category=rule.rule_type,
                metric_name=rule.metric_name,
                message=self._generate_alert_message(rule, metric_value),
                current_value=metric_value.value,
                threshold_value=rule.threshold_value
            )

            # é€šè¿‡å»é‡æœåŠ¡å¤„ç†
            should_send = self.alert_service.process_alert(alert)

            if should_send:
                # ä¿å­˜åˆ°æ•°æ®åº“
                await self._save_alert_history(alert, rule)

                # å‘é€ä¿¡å·æ›´æ–°UI
                alert_data = {
                    'rule_id': rule.id,
                    'message': alert.message,
                    'level': alert.level.value,
                    'timestamp': alert.timestamp.isoformat(),
                    'current_value': alert.current_value,
                    'threshold_value': alert.threshold_value
                }

                logger.info(f"å‘Šè­¦è§¦å‘äº‹ä»¶: è§„åˆ™ID {rule.id}, æ¶ˆæ¯: {alert_data.get('message', '')}")
                logger.debug("å‘Šè­¦å†å²å·²æ›´æ–°")

                self.stats['triggered_alerts'] += 1
                logger.info(f"è§¦å‘å‘Šè­¦: {alert.message}")
            else:
                self.stats['suppressed_alerts'] += 1
                logger.debug(f"å‘Šè­¦è¢«æŠ‘åˆ¶: {alert.message}")

        except Exception as e:
            logger.error(f"è§¦å‘å‘Šè­¦å¤±è´¥: {e}")

    def _get_alert_level(self, rule: AlertRule, current_value: float) -> AlertLevel:
        """æ ¹æ®è§„åˆ™ä¼˜å…ˆçº§å’Œè¶…å‡ºç¨‹åº¦ç¡®å®šå‘Šè­¦çº§åˆ«"""
        try:
            threshold = rule.threshold_value
            exceed_ratio = abs(current_value - threshold) / threshold if threshold != 0 else 1

            if rule.priority == "é«˜" or exceed_ratio >= 0.5:
                return AlertLevel.ERROR
            elif rule.priority == "ä¸­" or exceed_ratio >= 0.2:
                return AlertLevel.WARNING
            else:
                return AlertLevel.INFO

        except:
            return AlertLevel.WARNING

    def _generate_alert_message(self, rule: AlertRule, metric_value: MetricValue) -> str:
        """ç”Ÿæˆå‘Šè­¦æ¶ˆæ¯"""
        template = rule.message_template
        if template:
            try:
                return template.format(
                    rule_name=rule.name,
                    metric_name=rule.metric_name,
                    current_value=metric_value.value,
                    threshold_value=rule.threshold_value,
                    operator=rule.operator,
                    unit=rule.threshold_unit
                )
            except:
                pass

        # é»˜è®¤æ¶ˆæ¯æ¨¡æ¿
        return (f"å‘Šè­¦è§„åˆ™ '{rule.name}' è§¦å‘: "
                f"{rule.metric_name} {rule.operator} {rule.threshold_value}{rule.threshold_unit}, "
                f"å½“å‰å€¼: {metric_value.value}{rule.threshold_unit}")

    async def _save_alert_history(self, alert: AlertMessage, rule: AlertRule) -> None:
        """ä¿å­˜å‘Šè­¦å†å²åˆ°æ•°æ®åº“"""
        try:
            history = AlertHistory(
                timestamp=alert.timestamp.strftime('%Y-%m-%d %H:%M:%S'),
                level=alert.level.value,
                category=alert.category,
                message=alert.message,
                status='å·²è§¦å‘',
                rule_id=rule.id,
                metric_name=alert.metric_name,
                current_value=alert.current_value,
                threshold_value=alert.threshold_value,
                recommendation=self._generate_recommendation(rule, alert)
            )

            history_id = self.db.save_alert_history(history)
            if history_id:
                logger.debug(f"å‘Šè­¦å†å²å·²ä¿å­˜ï¼ŒID: {history_id}")
            else:
                logger.warning("ä¿å­˜å‘Šè­¦å†å²å¤±è´¥")

        except Exception as e:
            logger.error(f"ä¿å­˜å‘Šè­¦å†å²å¤±è´¥: {e}")

    def _generate_recommendation(self, rule: AlertRule, alert: AlertMessage) -> str:
        """ç”Ÿæˆå¤„ç†å»ºè®®"""
        metric_name = rule.metric_name.lower()

        if 'cpu' in metric_name:
            return "å»ºè®®æ£€æŸ¥CPUå¯†é›†å‹è¿›ç¨‹ï¼Œä¼˜åŒ–ç®—æ³•å¤æ‚åº¦ï¼Œæˆ–å¢åŠ è®¡ç®—èµ„æº"
        elif 'memory' in metric_name:
            return "å»ºè®®æ£€æŸ¥å†…å­˜æ³„æ¼ï¼Œä¼˜åŒ–æ•°æ®ç»“æ„ï¼Œæˆ–æ¸…ç†ä¸å¿…è¦çš„ç¼“å­˜"
        elif 'disk' in metric_name:
            return "å»ºè®®æ¸…ç†ä¸´æ—¶æ–‡ä»¶ï¼Œå½’æ¡£å†å²æ•°æ®ï¼Œæˆ–æ‰©å±•å­˜å‚¨ç©ºé—´"
        else:
            return f"è¯·æ£€æŸ¥ {rule.metric_name} ç›¸å…³é…ç½®å’Œç³»ç»ŸçŠ¶æ€"

    def _load_rules(self) -> None:
        """åŠ è½½è§„åˆ™"""
        try:
            rules = self.db.load_alert_rules()
            with self._lock:
                self._rules_cache.clear()
                for rule in rules:
                    self._rules_cache[rule.id] = rule
                    self._update_rule_status(rule.id,
                                             RuleStatus.ACTIVE if rule.enabled else RuleStatus.INACTIVE)

            logger.info(f"å·²åŠ è½½ {len(rules)} ä¸ªå‘Šè­¦è§„åˆ™")

        except Exception as e:
            logger.error(f"åŠ è½½å‘Šè­¦è§„åˆ™å¤±è´¥: {e}")

    async def _reload_rules(self) -> None:
        """é‡æ–°åŠ è½½è§„åˆ™"""
        logger.info("æ‰§è¡Œè§„åˆ™çƒ­åŠ è½½")
        self._load_rules()

    async def _check_rules_updated(self, last_check: datetime) -> bool:
        """æ£€æŸ¥è§„åˆ™æ˜¯å¦æœ‰æ›´æ–°"""
        try:
            # ç®€åŒ–å®ç°ï¼šæ£€æŸ¥æ•°æ®åº“ä¸­æ˜¯å¦æœ‰æ–°çš„è§„åˆ™æˆ–æ›´æ–°æ—¶é—´
            rules = self.db.load_alert_rules()
            current_rule_count = len(rules)
            cached_rule_count = len(self._rules_cache)

            # å¦‚æœè§„åˆ™æ•°é‡å˜åŒ–ï¼Œè¯´æ˜æœ‰æ›´æ–°
            if current_rule_count != cached_rule_count:
                return True

            # æ£€æŸ¥è§„åˆ™å†…å®¹æ˜¯å¦å˜åŒ–
            for rule in rules:
                cached_rule = self._rules_cache.get(rule.id)
                if not cached_rule or self._rule_changed(cached_rule, rule):
                    return True

            return False

        except Exception as e:
            logger.error(f"æ£€æŸ¥è§„åˆ™æ›´æ–°å¤±è´¥: {e}")
            return False

    def _rule_changed(self, old_rule: AlertRule, new_rule: AlertRule) -> bool:
        """æ£€æŸ¥è§„åˆ™æ˜¯å¦å˜åŒ–"""
        # æ¯”è¾ƒå…³é”®å­—æ®µ
        return (old_rule.name != new_rule.name or
                old_rule.enabled != new_rule.enabled or
                old_rule.metric_name != new_rule.metric_name or
                old_rule.operator != new_rule.operator or
                old_rule.threshold_value != new_rule.threshold_value or
                old_rule.threshold_unit != new_rule.threshold_unit)

    def _setup_metric_sources(self) -> None:
        """è®¾ç½®æŒ‡æ ‡æ•°æ®æº"""
        try:
            # è·å–æŒ‡æ ‡èšåˆæœåŠ¡å®ä¾‹
            from core.containers import get_service_container
            service_container = get_service_container()

            try:
                self.metrics_service = service_container.resolve_by_name('MetricsAggregationService')
                logger.info("âœ… å·²è¿æ¥åˆ°æŒ‡æ ‡èšåˆæœåŠ¡")
            except:
                self.metrics_service = None
                logger.warning("âš ï¸ æ— æ³•è¿æ¥åˆ°æŒ‡æ ‡èšåˆæœåŠ¡")

            # è·å–ç³»ç»Ÿèµ„æºæœåŠ¡
            try:
                self.resource_service = service_container.resolve_by_name('SystemResourceService')
                logger.info("âœ… å·²è¿æ¥åˆ°ç³»ç»Ÿèµ„æºæœåŠ¡")
            except:
                self.resource_service = None
                logger.warning("âš ï¸ æ— æ³•è¿æ¥åˆ°ç³»ç»Ÿèµ„æºæœåŠ¡")

            logger.info("è®¾ç½®æŒ‡æ ‡æ•°æ®æºè¿æ¥")

        except Exception as e:
            logger.error(f"è®¾ç½®æŒ‡æ ‡æ•°æ®æºå¤±è´¥: {e}")
            self.metrics_service = None
            self.resource_service = None

    def _update_rule_status(self, rule_id: int, status: RuleStatus) -> None:
        """æ›´æ–°è§„åˆ™çŠ¶æ€"""
        with self._lock:
            self._rule_status[rule_id] = status

        logger.debug(f"è§„åˆ™çŠ¶æ€å˜æ›´: ID {rule_id}, çŠ¶æ€: {status.value}")

    def _update_stats(self, execution_time: float) -> None:
        """æ›´æ–°ç»Ÿè®¡ä¿¡æ¯"""
        self.stats['total_checks'] += 1

        # æ›´æ–°å¹³å‡æ‰§è¡Œæ—¶é—´
        current_avg = self.stats['average_check_time']
        total_checks = self.stats['total_checks']
        self.stats['average_check_time'] = (current_avg * (total_checks - 1) + execution_time) / total_checks

    async def _cleanup_old_history(self) -> None:
        """æ¸…ç†è¿‡æœŸçš„å‘Šè­¦å†å²"""
        try:
            cutoff_date = datetime.now() - timedelta(days=self.max_history_age_days)
            # è¿™é‡Œåº”è¯¥è°ƒç”¨æ•°æ®åº“çš„æ¸…ç†æ–¹æ³•
            logger.debug(f"æ¸…ç† {cutoff_date} ä¹‹å‰çš„å‘Šè­¦å†å²")

        except Exception as e:
            logger.error(f"æ¸…ç†å‘Šè­¦å†å²å¤±è´¥: {e}")

    async def _cleanup_metrics_cache(self) -> None:
        """æ¸…ç†è¿‡æœŸçš„æŒ‡æ ‡ç¼“å­˜"""
        try:
            current_time = datetime.now()
            cutoff_time = current_time - timedelta(minutes=10)

            with self._lock:
                expired_keys = [
                    key for key, metric in self._metrics_cache.items()
                    if metric.timestamp < cutoff_time
                ]
                for key in expired_keys:
                    del self._metrics_cache[key]

            if expired_keys:
                logger.debug(f"æ¸…ç†äº† {len(expired_keys)} ä¸ªè¿‡æœŸæŒ‡æ ‡")

        except Exception as e:
            logger.error(f"æ¸…ç†æŒ‡æ ‡ç¼“å­˜å¤±è´¥: {e}")

    async def _cleanup_rule_contexts(self) -> None:
        """æ¸…ç†è§„åˆ™æ‰§è¡Œä¸Šä¸‹æ–‡"""
        try:
            current_time = datetime.now()
            cutoff_time = current_time - timedelta(hours=1)

            with self._lock:
                # æ¸…ç†é•¿æ—¶é—´æœªæ‰§è¡Œçš„è§„åˆ™ä¸Šä¸‹æ–‡
                inactive_rule_ids = [
                    rule_id for rule_id, context in self._rule_contexts.items()
                    if context.execution_time < cutoff_time
                ]
                for rule_id in inactive_rule_ids:
                    del self._rule_contexts[rule_id]

            if inactive_rule_ids:
                logger.debug(f"æ¸…ç†äº† {len(inactive_rule_ids)} ä¸ªä¸æ´»è·ƒçš„è§„åˆ™ä¸Šä¸‹æ–‡")

        except Exception as e:
            logger.error(f"æ¸…ç†è§„åˆ™ä¸Šä¸‹æ–‡å¤±è´¥: {e}")

    # å…¬å…±APIæ–¹æ³•

    def reload_rules_sync(self) -> None:
        """åŒæ­¥é‡æ–°åŠ è½½è§„åˆ™ï¼ˆä¾›å¤–éƒ¨è°ƒç”¨ï¼‰"""
        if self._loop and self._loop.is_running():
            asyncio.run_coroutine_threadsafe(self._reload_rules(), self._loop)
        else:
            self._load_rules()

    def get_engine_status(self) -> Dict[str, Any]:
        """è·å–å¼•æ“çŠ¶æ€"""
        return {
            'running': self._running,
            'rules_count': len(self._rules_cache),
            'active_rules': len([r for r in self._rules_cache.values() if r.enabled]),
            'metrics_count': len(self._metrics_cache),
            'stats': self.stats.copy(),
            'rule_status': {rule_id: status.value for rule_id, status in self._rule_status.items()}
        }

    def get_rule_status(self, rule_id: int) -> Optional[str]:
        """è·å–ç‰¹å®šè§„åˆ™çš„çŠ¶æ€"""
        status = self._rule_status.get(rule_id)
        return status.value if status else None

    def force_rule_check(self, rule_id: Optional[int] = None) -> None:
        """å¼ºåˆ¶æ‰§è¡Œè§„åˆ™æ£€æŸ¥"""
        if self._loop and self._loop.is_running():
            if rule_id:
                rule = self._rules_cache.get(rule_id)
                if rule:
                    asyncio.run_coroutine_threadsafe(
                        self._execute_single_rule(rule), self._loop
                    )
            else:
                asyncio.run_coroutine_threadsafe(self._execute_rules(), self._loop)

    def get_active_rules(self) -> Dict[int, AlertRule]:
        """è·å–æ´»è·ƒè§„åˆ™"""
        with self._lock:
            return self._rules_cache.copy()

    def get_statistics(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        stats = self.stats.copy()
        stats['active_rules_count'] = len(self._rules_cache)
        stats['total_rules_count'] = len(self._rules_cache)
        return stats


# å…¨å±€å¼•æ“å®ä¾‹
_alert_rule_engine: Optional[AlertRuleEngine] = None


def get_alert_rule_engine() -> AlertRuleEngine:
    """è·å–å‘Šè­¦è§„åˆ™å¼•æ“å®ä¾‹"""
    global _alert_rule_engine
    if _alert_rule_engine is None:
        _alert_rule_engine = AlertRuleEngine()
    return _alert_rule_engine


def initialize_alert_rule_engine(event_bus: Optional[EventBus] = None) -> AlertRuleEngine:
    """åˆå§‹åŒ–å‘Šè­¦è§„åˆ™å¼•æ“"""
    global _alert_rule_engine
    if _alert_rule_engine is None:
        _alert_rule_engine = AlertRuleEngine(event_bus)
        _alert_rule_engine.initialize()
    return _alert_rule_engine
