#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è‚¡ç¥¨å…ƒæ•°æ®å¢å¼ºå™¨

ç”¨äºä»å¤–éƒ¨APIè¡¥å……å®Œå–„è‚¡ç¥¨å…ƒæ•°æ®ï¼ˆè¡Œä¸šã€æ¿å—ç­‰ä¿¡æ¯ï¼‰
å½“Kçº¿æ•°æ®ä¸­ä¸åŒ…å«è¿™äº›ä¿¡æ¯æ—¶ï¼Œé€šè¿‡ä¸“é—¨çš„APIè·å–å¹¶æ›´æ–°

ä½œè€…: HIkyuu-UIå¼€å‘å›¢é˜Ÿ
ç‰ˆæœ¬: 2.0
æ—¥æœŸ: 2025-01-06
æ›´æ–°: æ·»åŠ ç¼“å­˜æœºåˆ¶ï¼Œä¼˜åŒ–æ€§èƒ½
"""

import pandas as pd
from typing import Dict, List, Optional, Any
from loguru import logger
import threading
import time

logger = logger.bind(module=__name__)


class StockMetadataEnhancer:
    """
    è‚¡ç¥¨å…ƒæ•°æ®å¢å¼ºå™¨
    
    æ”¯æŒä»å¤šä¸ªæ•°æ®æºè·å–è‚¡ç¥¨çš„è¡Œä¸šæ¿å—ä¿¡æ¯ï¼š
    - AKShare: stock_info_a_code_name, stock_individual_info_em
    - Tushare: stock_basic (éœ€è¦token)
    - EastMoney: è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯
    
    æ€§èƒ½ä¼˜åŒ–ï¼š
    - ç¼“å­˜æœºåˆ¶ï¼šç¼“å­˜è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯ï¼ˆå…¨éƒ¨è‚¡ç¥¨åˆ—è¡¨ï¼‰å’Œè¯¦ç»†ä¿¡æ¯
    - çº¿ç¨‹å®‰å…¨ï¼šä½¿ç”¨é”ä¿æŠ¤ç¼“å­˜è®¿é—®
    - TTLæœºåˆ¶ï¼šç¼“å­˜æœ‰æ•ˆæœŸ24å°æ—¶ï¼Œè¿‡æœŸåè‡ªåŠ¨åˆ·æ–°
    """
    
    def __init__(self):
        self.akshare_available = False
        self.tushare_available = False
        
        # âœ… ç¼“å­˜æœºåˆ¶
        self._stock_info_cache: Optional[pd.DataFrame] = None  # ç¼“å­˜å…¨éƒ¨è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯
        self._stock_info_cache_time: Optional[float] = None  # ç¼“å­˜æ—¶é—´æˆ³
        self._detailed_info_cache: Dict[str, Dict[str, Any]] = {}  # ç¼“å­˜æ¯ä¸ªè‚¡ç¥¨çš„è¯¦ç»†ä¿¡æ¯
        self._detailed_info_cache_time: Dict[str, float] = {}  # æ¯ä¸ªè‚¡ç¥¨è¯¦ç»†ä¿¡æ¯çš„ç¼“å­˜æ—¶é—´æˆ³
        self._cache_lock = threading.RLock()  # çº¿ç¨‹å®‰å…¨é”
        self._refreshing_stock_info = False  # é˜²æ­¢å¤šä¸ªçº¿ç¨‹åŒæ—¶åˆ·æ–°è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯
        self._refreshing_detailed_info: Dict[str, bool] = {}  # é˜²æ­¢å¤šä¸ªçº¿ç¨‹åŒæ—¶åˆ·æ–°åŒä¸€è‚¡ç¥¨çš„è¯¦ç»†ä¿¡æ¯
        self._cache_ttl = 24 * 3600  # ç¼“å­˜æœ‰æ•ˆæœŸï¼š24å°æ—¶ï¼ˆç§’ï¼‰
        self._detailed_cache_ttl = 24 * 3600  # è¯¦ç»†ä¿¡æ¯ç¼“å­˜æœ‰æ•ˆæœŸï¼š24å°æ—¶ï¼ˆç§’ï¼‰
        
        # å°è¯•å¯¼å…¥AKShare
        try:
            import akshare as ak
            self.ak = ak
            self.akshare_available = True
            logger.info("âœ… AKShareå¯ç”¨ï¼Œå°†ç”¨äºè¡¥å……è‚¡ç¥¨å…ƒæ•°æ®ï¼ˆå·²å¯ç”¨ç¼“å­˜æœºåˆ¶ï¼‰")
        except ImportError:
            logger.warning("AKShareä¸å¯ç”¨ï¼Œæ— æ³•ä½¿ç”¨AKShareè¡¥å……å…ƒæ•°æ®")
        
        # å°è¯•å¯¼å…¥Tushare
        try:
            import tushare as ts
            self.ts = ts
            self.tushare_available = True
            logger.info("âœ… Tushareå¯ç”¨ï¼Œå°†ç”¨äºè¡¥å……è‚¡ç¥¨å…ƒæ•°æ®")
        except ImportError:
            logger.warning("Tushareä¸å¯ç”¨ï¼Œæ— æ³•ä½¿ç”¨Tushareè¡¥å……å…ƒæ•°æ®")
    
    def enhance_stock_metadata_batch(self, symbols: List[str], 
                                      source: str = 'akshare') -> Dict[str, Dict[str, Any]]:
        """
        æ‰¹é‡å¢å¼ºè‚¡ç¥¨å…ƒæ•°æ®
        
        Args:
            symbols: è‚¡ç¥¨ä»£ç åˆ—è¡¨ (æ ¼å¼ï¼š000001 æˆ– 000001.SZ)
            source: æ•°æ®æº ('akshare', 'tushare', 'auto')
        
        Returns:
            Dict[symbol, metadata]: æ¯ä¸ªè‚¡ç¥¨çš„å…ƒæ•°æ®å­—å…¸
        """
        result = {}
        
        if source == 'auto':
            # è‡ªåŠ¨é€‰æ‹©å¯ç”¨æ•°æ®æº
            if self.akshare_available:
                source = 'akshare'
            elif self.tushare_available:
                source = 'tushare'
            else:
                logger.error("æ²¡æœ‰å¯ç”¨çš„æ•°æ®æºï¼Œæ— æ³•è¡¥å……å…ƒæ•°æ®")
                return result
        
        if source == 'akshare' and self.akshare_available:
            result = self._enhance_with_akshare_batch(symbols)
        elif source == 'tushare' and self.tushare_available:
            result = self._enhance_with_tushare_batch(symbols)
        else:
            logger.warning(f"æ•°æ®æº {source} ä¸å¯ç”¨")
        
        return result
    
    def _enhance_with_akshare_batch(self, symbols: List[str]) -> Dict[str, Dict[str, Any]]:
        """
        ä½¿ç”¨AKShareæ‰¹é‡è·å–è‚¡ç¥¨å…ƒæ•°æ®ï¼ˆå·²ä¼˜åŒ–ï¼šä½¿ç”¨ç¼“å­˜æœºåˆ¶ï¼‰
        
        Args:
            symbols: è‚¡ç¥¨ä»£ç åˆ—è¡¨
            
        Returns:
            Dict[symbol, metadata]: æ¯ä¸ªè‚¡ç¥¨çš„å…ƒæ•°æ®å­—å…¸
        """
        result = {}
        
        try:
            # âœ… ä¼˜åŒ–ï¼šä»ç¼“å­˜è·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯ï¼Œé¿å…é‡å¤è¯·æ±‚
            stock_info_df = self._get_stock_info_cached()
            
            if stock_info_df is not None and not stock_info_df.empty:
                # å¤„ç†æ¯ä¸ªæŸ¥è¯¢çš„è‚¡ç¥¨ä»£ç 
                for symbol in symbols:
                    # æ ‡å‡†åŒ–è‚¡ç¥¨ä»£ç ï¼ˆç§»é™¤å¸‚åœºåç¼€ï¼‰
                    clean_code = symbol.split('.')[0]
                    
                    # åœ¨DataFrameä¸­æŸ¥æ‰¾
                    match = stock_info_df[stock_info_df['code'] == clean_code]
                    
                    if not match.empty:
                        row = match.iloc[0]
                        metadata = {
                            'code': clean_code,
                            'name': row.get('name', ''),
                        }
                        
                        # AKShareçš„stock_info_a_code_nameå¯èƒ½ä¸å«è¡Œä¸šä¿¡æ¯
                        # âœ… ä¼˜åŒ–ï¼šä»ç¼“å­˜è·å–è¯¦ç»†ä¿¡æ¯ï¼Œé¿å…é‡å¤è¯·æ±‚
                        # âœ… ä¿®å¤ï¼šå³ä½¿è¯¦ç»†ä¿¡æ¯è·å–å¤±è´¥ï¼Œä¹Ÿè¿”å›åŸºæœ¬ä¿¡æ¯ï¼ˆè‡³å°‘åŒ…å«è‚¡ç¥¨åç§°ï¼‰
                        try:
                            detailed_info = self._get_detailed_info_akshare_cached(clean_code)
                            if detailed_info:
                                metadata.update(detailed_info)
                        except Exception as e:
                            # è¯¦ç»†ä¿¡æ¯è·å–å¤±è´¥ä¸å½±å“åŸºæœ¬ä¿¡æ¯è¿”å›
                            logger.debug(f"è·å–è‚¡ç¥¨è¯¦ç»†ä¿¡æ¯å¤±è´¥ {clean_code}: {e}ï¼Œä½†åŸºæœ¬ä¿¡æ¯å·²è·å–")
                        
                        result[symbol] = metadata
                    else:
                        logger.debug(f"AKShareä¸­æœªæ‰¾åˆ°è‚¡ç¥¨: {symbol}")
            
            if result:
                logger.info(f"âœ… AKShareè¡¥å……å®Œæˆï¼ŒæˆåŠŸè·å– {len(result)}/{len(symbols)} ä¸ªè‚¡ç¥¨çš„å…ƒæ•°æ®")
            
        except Exception as e:
            logger.error(f"âŒ AKShareæ‰¹é‡è·å–å¤±è´¥: {e}")
            import traceback
            logger.error(traceback.format_exc())
        
        return result
    
    def _get_stock_info_cached(self) -> Optional[pd.DataFrame]:
        """
        è·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯ï¼ˆå¸¦ç¼“å­˜æœºåˆ¶ï¼Œæ”¯æŒå¹¶å‘æ§åˆ¶ï¼‰
        
        Returns:
            è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯DataFrameï¼Œå¦‚æœè·å–å¤±è´¥åˆ™è¿”å›None
        """
        current_time = time.time()
        
        # ç¬¬ä¸€æ¬¡æ£€æŸ¥ï¼šç¼“å­˜æ˜¯å¦æœ‰æ•ˆ
        with self._cache_lock:
            if (self._stock_info_cache is not None and 
                self._stock_info_cache_time is not None and
                current_time - self._stock_info_cache_time < self._cache_ttl):
                # ç¼“å­˜æœ‰æ•ˆï¼Œç›´æ¥è¿”å›
                logger.debug(f"âœ… ä½¿ç”¨ç¼“å­˜çš„è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯ï¼ˆç¼“å­˜å¹´é¾„: {int(current_time - self._stock_info_cache_time)}ç§’ï¼‰")
                return self._stock_info_cache.copy()  # è¿”å›å‰¯æœ¬ï¼Œé¿å…å¤–éƒ¨ä¿®æ”¹
        
        # ç¼“å­˜æ— æ•ˆæˆ–ä¸å­˜åœ¨ï¼Œéœ€è¦åˆ·æ–°
        # æ£€æŸ¥æ˜¯å¦æœ‰å…¶ä»–çº¿ç¨‹æ­£åœ¨åˆ·æ–°
        with self._cache_lock:
            if self._refreshing_stock_info:
                # æœ‰å…¶ä»–çº¿ç¨‹æ­£åœ¨åˆ·æ–°ï¼Œç­‰å¾…å¹¶è¿”å›æ—§ç¼“å­˜ï¼ˆå³ä½¿è¿‡æœŸï¼‰
                logger.debug("â³ å…¶ä»–çº¿ç¨‹æ­£åœ¨åˆ·æ–°è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯ï¼Œä½¿ç”¨ç°æœ‰ç¼“å­˜")
                if self._stock_info_cache is not None:
                    return self._stock_info_cache.copy()
                # å¦‚æœæ²¡æœ‰æ—§ç¼“å­˜ï¼Œç­‰å¾…ä¸€ä¸‹å†æ£€æŸ¥
                return None
            
            # æ ‡è®°ä¸ºæ­£åœ¨åˆ·æ–°
            self._refreshing_stock_info = True
        
        # ä»APIè·å–ï¼ˆä¸åœ¨é”å†…ï¼Œé¿å…é˜»å¡å…¶ä»–çº¿ç¨‹ï¼‰
        try:
            logger.info("ğŸ“¥ ä»AKShareè·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯ï¼ˆç¼“å­˜æœªå‘½ä¸­ï¼Œæ­£åœ¨åˆ·æ–°ï¼‰...")
            stock_info_df = self.ak.stock_info_a_code_name()
            
            if stock_info_df is not None and not stock_info_df.empty:
                logger.info(f"âœ… è·å–åˆ° {len(stock_info_df)} æ¡è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯ï¼Œå·²ç¼“å­˜")
                
                # æ›´æ–°ç¼“å­˜
                with self._cache_lock:
                    self._stock_info_cache = stock_info_df.copy()
                    self._stock_info_cache_time = time.time()
                    self._refreshing_stock_info = False
                
                return stock_info_df
            else:
                logger.warning("âš ï¸ ä»AKShareè·å–çš„è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯ä¸ºç©º")
                with self._cache_lock:
                    self._refreshing_stock_info = False
                return None
                
        except Exception as e:
            logger.error(f"âŒ ä»AKShareè·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯å¤±è´¥: {e}")
            # å¦‚æœè·å–å¤±è´¥ï¼Œå°è¯•è¿”å›æ—§ç¼“å­˜ï¼ˆå³ä½¿è¿‡æœŸï¼‰
            with self._cache_lock:
                self._refreshing_stock_info = False
                if self._stock_info_cache is not None:
                    logger.warning("âš ï¸ ä½¿ç”¨è¿‡æœŸçš„ç¼“å­˜æ•°æ®ï¼ˆAPIè·å–å¤±è´¥ï¼‰")
                    return self._stock_info_cache.copy()
            return None
    
    def _get_detailed_info_akshare_cached(self, code: str) -> Optional[Dict[str, Any]]:
        """
        è·å–å•ä¸ªè‚¡ç¥¨çš„è¯¦ç»†ä¿¡æ¯ï¼ˆå¸¦ç¼“å­˜æœºåˆ¶ï¼Œæ”¯æŒå¹¶å‘æ§åˆ¶ï¼‰
        
        Args:
            code: è‚¡ç¥¨ä»£ç 
            
        Returns:
            è‚¡ç¥¨è¯¦ç»†ä¿¡æ¯å­—å…¸ï¼Œå¦‚æœè·å–å¤±è´¥åˆ™è¿”å›None
        """
        current_time = time.time()
        
        # ç¬¬ä¸€æ¬¡æ£€æŸ¥ï¼šç¼“å­˜æ˜¯å¦æœ‰æ•ˆ
        with self._cache_lock:
            if (code in self._detailed_info_cache and 
                code in self._detailed_info_cache_time and
                current_time - self._detailed_info_cache_time[code] < self._detailed_cache_ttl):
                # ç¼“å­˜æœ‰æ•ˆï¼Œç›´æ¥è¿”å›
                logger.debug(f"âœ… ä½¿ç”¨ç¼“å­˜çš„è‚¡ç¥¨è¯¦ç»†ä¿¡æ¯: {code}ï¼ˆç¼“å­˜å¹´é¾„: {int(current_time - self._detailed_info_cache_time[code])}ç§’ï¼‰")
                return self._detailed_info_cache[code].copy()  # è¿”å›å‰¯æœ¬ï¼Œé¿å…å¤–éƒ¨ä¿®æ”¹
        
        # ç¼“å­˜æ— æ•ˆæˆ–ä¸å­˜åœ¨ï¼Œéœ€è¦åˆ·æ–°
        # æ£€æŸ¥æ˜¯å¦æœ‰å…¶ä»–çº¿ç¨‹æ­£åœ¨åˆ·æ–°åŒä¸€ä¸ªè‚¡ç¥¨
        with self._cache_lock:
            if self._refreshing_detailed_info.get(code, False):
                # æœ‰å…¶ä»–çº¿ç¨‹æ­£åœ¨åˆ·æ–°ï¼Œç­‰å¾…å¹¶è¿”å›æ—§ç¼“å­˜ï¼ˆå³ä½¿è¿‡æœŸï¼‰
                logger.debug(f"â³ å…¶ä»–çº¿ç¨‹æ­£åœ¨åˆ·æ–°è‚¡ç¥¨è¯¦ç»†ä¿¡æ¯: {code}ï¼Œä½¿ç”¨ç°æœ‰ç¼“å­˜")
                if code in self._detailed_info_cache:
                    return self._detailed_info_cache[code].copy()
                # å¦‚æœæ²¡æœ‰æ—§ç¼“å­˜ï¼Œè¿”å›None
                return None
            
            # æ ‡è®°ä¸ºæ­£åœ¨åˆ·æ–°
            self._refreshing_detailed_info[code] = True
        
        # ä»APIè·å–ï¼ˆä¸åœ¨é”å†…ï¼Œé¿å…é˜»å¡å…¶ä»–çº¿ç¨‹ï¼‰
        try:
            # âœ… ä¼˜åŒ–ï¼šæ·»åŠ è¶…æ—¶æœºåˆ¶ï¼Œé¿å…APIè°ƒç”¨é˜»å¡å¤ªä¹…
            import threading
            detailed_info = None
            api_error = None
            
            def fetch_detailed_info():
                nonlocal detailed_info, api_error
                try:
                    detailed_info = self._get_detailed_info_akshare(code)
                except Exception as e:
                    api_error = e
            
            # åœ¨å•ç‹¬çº¿ç¨‹ä¸­æ‰§è¡Œï¼Œå¸¦è¶…æ—¶ï¼ˆæœ€å¤šç­‰å¾…3ç§’ï¼‰
            fetch_thread = threading.Thread(target=fetch_detailed_info, daemon=True)
            fetch_thread.start()
            fetch_thread.join(timeout=3.0)
            
            if fetch_thread.is_alive():
                # è¶…æ—¶ï¼Œè¿”å›Noneï¼ˆä¸å½±å“åŸºæœ¬ä¿¡æ¯è¿”å›ï¼‰
                logger.debug(f"è·å–è‚¡ç¥¨è¯¦ç»†ä¿¡æ¯è¶…æ—¶: {code}ï¼ˆä¸å½±å“åŸºæœ¬ä¿¡æ¯ï¼‰")
                with self._cache_lock:
                    self._refreshing_detailed_info[code] = False
                    # å¦‚æœæœ‰æ—§ç¼“å­˜ï¼Œè¿”å›æ—§ç¼“å­˜
                    if code in self._detailed_info_cache:
                        logger.debug(f"âš ï¸ ä½¿ç”¨è¿‡æœŸçš„ç¼“å­˜æ•°æ®ï¼ˆAPIè°ƒç”¨è¶…æ—¶ï¼‰: {code}")
                        return self._detailed_info_cache[code].copy()
                return None
            
            if detailed_info:
                # æ›´æ–°ç¼“å­˜
                with self._cache_lock:
                    self._detailed_info_cache[code] = detailed_info.copy()
                    self._detailed_info_cache_time[code] = time.time()
                    self._refreshing_detailed_info[code] = False
            else:
                with self._cache_lock:
                    self._refreshing_detailed_info[code] = False
            
            return detailed_info
            
        except Exception as e:
            logger.debug(f"è·å–è‚¡ç¥¨è¯¦ç»†ä¿¡æ¯å¤±è´¥ {code}: {e}")
            # å¦‚æœè·å–å¤±è´¥ï¼Œå°è¯•è¿”å›æ—§ç¼“å­˜ï¼ˆå³ä½¿è¿‡æœŸï¼‰
            with self._cache_lock:
                self._refreshing_detailed_info[code] = False
                if code in self._detailed_info_cache:
                    logger.debug(f"âš ï¸ ä½¿ç”¨è¿‡æœŸçš„ç¼“å­˜æ•°æ®ï¼ˆAPIè·å–å¤±è´¥ï¼‰: {code}")
                    return self._detailed_info_cache[code].copy()
            return None
    
    def _get_detailed_info_akshare(self, code: str) -> Optional[Dict[str, Any]]:
        """
        è·å–å•ä¸ªè‚¡ç¥¨çš„è¯¦ç»†ä¿¡æ¯ï¼ˆå«è¡Œä¸šæ¿å—ï¼‰
        
        ä½¿ç”¨AKShareçš„stock_individual_info_emæ¥å£
        æ³¨æ„ï¼šæ­¤æ–¹æ³•ä¸åŒ…å«ç¼“å­˜é€»è¾‘ï¼Œç”± _get_detailed_info_akshare_cached è°ƒç”¨
        
        Args:
            code: è‚¡ç¥¨ä»£ç 
            
        Returns:
            è‚¡ç¥¨è¯¦ç»†ä¿¡æ¯å­—å…¸ï¼Œå¦‚æœè·å–å¤±è´¥åˆ™è¿”å›None
        """
        try:
            # å°è¯•ä½¿ç”¨ä¸œæ–¹è´¢å¯Œä¸ªè‚¡ä¿¡æ¯æ¥å£
            detail_df = self.ak.stock_individual_info_em(symbol=code)
            
            if detail_df is not None and not detail_df.empty:
                # å°†DataFrameè½¬æ¢ä¸ºå­—å…¸ï¼ˆitem -> valueï¼‰
                info_dict = {}
                for _, row in detail_df.iterrows():
                    item = row.get('item', '')
                    value = row.get('value', '')
                    if item and value:
                        info_dict[item] = value
                
                # æå–è¡Œä¸šæ¿å—ä¿¡æ¯
                result = {}
                
                # è¡Œä¸šå­—æ®µå¯èƒ½çš„åç§°
                industry_keys = ['è¡Œä¸š', 'æ‰€å±è¡Œä¸š', 'industry']
                for key in industry_keys:
                    if key in info_dict:
                        result['industry'] = info_dict[key]
                        break
                
                # æ¿å—å­—æ®µå¯èƒ½çš„åç§°
                sector_keys = ['æ¿å—', 'æ‰€å±æ¿å—', 'sector', 'æ¦‚å¿µæ¿å—']
                for key in sector_keys:
                    if key in info_dict:
                        result['sector'] = info_dict[key]
                        break
                
                # ä¸Šå¸‚æ—¥æœŸ
                listing_keys = ['ä¸Šå¸‚æ—¶é—´', 'ä¸Šå¸‚æ—¥æœŸ', 'listing_date']
                for key in listing_keys:
                    if key in info_dict:
                        result['listing_date'] = info_dict[key]
                        break
                
                # æ€»è‚¡æœ¬/æµé€šè‚¡æœ¬
                if 'æ€»è‚¡æœ¬' in info_dict:
                    try:
                        result['total_shares'] = float(info_dict['æ€»è‚¡æœ¬'])
                    except:
                        pass
                
                if 'æµé€šè‚¡' in info_dict:
                    try:
                        result['circulating_shares'] = float(info_dict['æµé€šè‚¡'])
                    except:
                        pass
                
                logger.debug(f"è·å–è‚¡ç¥¨è¯¦ç»†ä¿¡æ¯: {code} -> {result}")
                return result
            
        except Exception as e:
            logger.debug(f"è·å–è‚¡ç¥¨è¯¦ç»†ä¿¡æ¯å¤±è´¥ {code}: {e}")
        
        return None
    
    def clear_cache(self, clear_detailed_info: bool = True):
        """
        æ¸…é™¤ç¼“å­˜
        
        Args:
            clear_detailed_info: æ˜¯å¦æ¸…é™¤è¯¦ç»†ä¿¡æ¯ç¼“å­˜ï¼Œé»˜è®¤ä¸ºTrue
        """
        with self._cache_lock:
            self._stock_info_cache = None
            self._stock_info_cache_time = None
            self._refreshing_stock_info = False
            if clear_detailed_info:
                self._detailed_info_cache.clear()
                self._detailed_info_cache_time.clear()
                self._refreshing_detailed_info.clear()
            logger.info("âœ… ç¼“å­˜å·²æ¸…é™¤")
    
    def get_cache_stats(self) -> Dict[str, Any]:
        """
        è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        with self._cache_lock:
            current_time = time.time()
            stats = {
                'stock_info_cached': self._stock_info_cache is not None,
                'stock_info_cache_age': None,
                'detailed_info_cache_count': len(self._detailed_info_cache),
                'detailed_info_cache_ages': {}
            }
            
            if self._stock_info_cache_time is not None:
                stats['stock_info_cache_age'] = int(current_time - self._stock_info_cache_time)
            
            for code, cache_time in self._detailed_info_cache_time.items():
                stats['detailed_info_cache_ages'][code] = int(current_time - cache_time)
            
            return stats
    
    def _enhance_with_tushare_batch(self, symbols: List[str]) -> Dict[str, Dict[str, Any]]:
        """
        ä½¿ç”¨Tushareæ‰¹é‡è·å–è‚¡ç¥¨å…ƒæ•°æ®
        """
        result = {}
        
        try:
            # éœ€è¦Tushare token
            # è¿™é‡Œæä¾›æ¥å£ä½†éœ€è¦ç”¨æˆ·é…ç½®
            logger.warning("Tushareè¡¥å……åŠŸèƒ½éœ€è¦é…ç½®tokenï¼Œæš‚æœªå®ç°")
            # ç¤ºä¾‹ä»£ç ï¼š
            # pro = self.ts.pro_api(token='YOUR_TOKEN')
            # df = pro.stock_basic(fields='ts_code,name,industry,area,list_date')
            
        except Exception as e:
            logger.error(f"Tushareæ‰¹é‡è·å–å¤±è´¥: {e}")
        
        return result
    
    def enhance_asset_metadata_table(self, db_manager, asset_type, market: str = 'all'):
        """
        ç›´æ¥å¢å¼ºæ•°æ®åº“ä¸­çš„asset_metadataè¡¨
        
        Args:
            db_manager: AssetSeparatedDatabaseManagerå®ä¾‹
            asset_type: èµ„äº§ç±»å‹
            market: å¸‚åœºè¿‡æ»¤
        """
        try:
            from ..plugin_types import AssetType
            
            logger.info(f"å¼€å§‹å¢å¼ºasset_metadataè¡¨çš„è¡Œä¸šä¿¡æ¯ (asset_type={asset_type}, market={market})")
            
            # 1. æŸ¥è¯¢æ‰€æœ‰ç¼ºå°‘è¡Œä¸šä¿¡æ¯çš„è‚¡ç¥¨
            db_path = db_manager.get_database_path(asset_type)
            
            query = """
                SELECT symbol, name, market
                FROM asset_metadata
                WHERE (industry IS NULL OR industry = '' OR industry = 'æœªçŸ¥')
                  AND (sector IS NULL OR sector = '' OR sector = 'æœªçŸ¥')
                  AND listing_status = 'active'
            """
            
            if market and market != 'all':
                query += f" AND market = '{market.upper()}'"
            
            logger.info(f"æŸ¥è¯¢ç¼ºå°‘è¡Œä¸šä¿¡æ¯çš„è‚¡ç¥¨...")
            
            from ..duckdb_manager import DuckDBManager
            duckdb_mgr = DuckDBManager()
            
            with duckdb_mgr.get_connection(db_path) as conn:
                result_df = conn.execute(query).fetchdf()
            
            if result_df.empty:
                logger.info("âœ… æ‰€æœ‰è‚¡ç¥¨éƒ½å·²æœ‰è¡Œä¸šä¿¡æ¯ï¼Œæ— éœ€è¡¥å……")
                return 0
            
            logger.info(f"ğŸ“Š æ‰¾åˆ° {len(result_df)} ä¸ªè‚¡ç¥¨éœ€è¦è¡¥å……è¡Œä¸šä¿¡æ¯")
            
            # 2. æ‰¹é‡è·å–å…ƒæ•°æ®
            symbols = result_df['symbol'].tolist()
            enhanced_data = self.enhance_stock_metadata_batch(symbols, source='akshare')
            
            # 3. æ›´æ–°æ•°æ®åº“
            update_count = 0
            for symbol, metadata in enhanced_data.items():
                if 'industry' in metadata or 'sector' in metadata:
                    success = db_manager.upsert_asset_metadata(
                        symbol=symbol,
                        asset_type=asset_type,
                        metadata=metadata
                    )
                    if success:
                        update_count += 1
            
            logger.info(f"âœ… æˆåŠŸè¡¥å…… {update_count} ä¸ªè‚¡ç¥¨çš„è¡Œä¸šä¿¡æ¯")
            return update_count
            
        except Exception as e:
            logger.error(f"å¢å¼ºasset_metadataè¡¨å¤±è´¥: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return 0


# å…¨å±€å•ä¾‹
_metadata_enhancer: Optional[StockMetadataEnhancer] = None


def get_metadata_enhancer() -> StockMetadataEnhancer:
    """è·å–å…ƒæ•°æ®å¢å¼ºå™¨å•ä¾‹"""
    global _metadata_enhancer
    if _metadata_enhancer is None:
        _metadata_enhancer = StockMetadataEnhancer()
    return _metadata_enhancer

