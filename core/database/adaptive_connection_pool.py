#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è‡ªé€‚åº”DuckDBè¿æ¥æ± ç®¡ç†ç³»ç»Ÿ

æ ¹æ®å®é™…è´Ÿè½½è‡ªåŠ¨åŠ¨æ€è°ƒæ•´è¿æ¥æ± é…ç½®ï¼Œå®ç°æ™ºèƒ½èµ„æºç®¡ç†ã€‚

æ ¸å¿ƒç‰¹æ€§:
1. å®æ—¶ç›‘æ§è¿æ¥æ± ä½¿ç”¨æƒ…å†µ
2. æ™ºèƒ½å†³ç­–ä½•æ—¶æ‰©å®¹/ç¼©å®¹
3. å¹³æ»‘çƒ­é‡è½½é…ç½®
4. é˜²æ­¢é¢‘ç¹è°ƒæ•´ï¼ˆå†·å´æœŸï¼‰
5. å®‰å…¨è¾¹ç•Œä¿æŠ¤

ä½œè€…: AI Assistant
æ—¥æœŸ: 2025-10-13
ç‰ˆæœ¬: 1.0
"""

import threading
import time
from collections import deque
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional
from dataclasses import dataclass
from loguru import logger

from .duckdb_connection_pool import DuckDBConnectionPool
from .connection_pool_config import ConnectionPoolConfig


@dataclass
class AdaptivePoolConfig:
    """è‡ªé€‚åº”è¿æ¥æ± é…ç½®"""

    # è¾¹ç•Œ
    min_pool_size: int = 3
    max_pool_size: int = 50

    # é˜ˆå€¼
    scale_up_usage_threshold: float = 0.8
    scale_down_usage_threshold: float = 0.3
    scale_up_overflow_threshold: float = 0.5  # æº¢å‡ºè¿æ¥/pool_size

    # æ—¶é—´çª—å£
    metrics_window_seconds: int = 60
    cooldown_seconds: int = 60

    # é‡‡é›†é—´éš”
    collection_interval: int = 10

    # è°ƒæ•´ç­–ç•¥
    scale_up_factor: float = 1.5
    scale_down_factor: float = 0.8

    # æ˜¯å¦å¯ç”¨
    enabled: bool = True

    def validate(self) -> bool:
        """éªŒè¯é…ç½®æœ‰æ•ˆæ€§"""
        if self.min_pool_size < 1 or self.max_pool_size > 100:
            return False
        if self.min_pool_size >= self.max_pool_size:
            return False
        if not (0 < self.scale_up_usage_threshold <= 1.0):
            return False
        if not (0 < self.scale_down_usage_threshold <= 1.0):
            return False
        return True


class MetricsCollector:
    """è¿æ¥æ± æŒ‡æ ‡æ”¶é›†å™¨"""

    def __init__(self, pool: DuckDBConnectionPool, interval: int = 10):
        """
        åˆå§‹åŒ–æŒ‡æ ‡æ”¶é›†å™¨

        Args:
            pool: DuckDBè¿æ¥æ± å®ä¾‹
            interval: é‡‡é›†é—´éš”ï¼ˆç§’ï¼‰
        """
        self.pool = pool
        self.interval = interval
        self.metrics_history = deque(maxlen=1000)  # æœ€è¿‘1000æ¡è®°å½•
        self._running = False
        self._thread = None
        self._lock = threading.Lock()

    def start(self):
        """å¯åŠ¨æŒ‡æ ‡æ”¶é›†"""
        if self._running:
            logger.warning("MetricsCollectorå·²åœ¨è¿è¡Œ")
            return

        self._running = True
        self._thread = threading.Thread(target=self._collect_loop, daemon=True, name="MetricsCollector")
        self._thread.start()
        logger.info(f"ğŸ“Š æŒ‡æ ‡æ”¶é›†å™¨å·²å¯åŠ¨ï¼Œé‡‡é›†é—´éš”={self.interval}ç§’")

    def stop(self):
        """åœæ­¢æŒ‡æ ‡æ”¶é›†"""
        self._running = False
        if self._thread:
            self._thread.join(timeout=5)
        logger.info("â¸ï¸ æŒ‡æ ‡æ”¶é›†å™¨å·²åœæ­¢")

    def _collect_loop(self):
        """æŒ‡æ ‡æ”¶é›†å¾ªç¯"""
        while self._running:
            try:
                metrics = self._collect_metrics()
                with self._lock:
                    self.metrics_history.append(metrics)
            except Exception as e:
                logger.error(f"æŒ‡æ ‡æ”¶é›†å¤±è´¥: {e}")

            time.sleep(self.interval)

    def _collect_metrics(self) -> Dict[str, Any]:
        """æ”¶é›†å½“å‰æŒ‡æ ‡"""
        try:
            status = self.pool.get_pool_status()

            pool_size = status.get('pool_size', 0)
            checked_out = status.get('checked_out', 0)
            overflow = status.get('overflow', 0)

            usage_rate = checked_out / pool_size if pool_size > 0 else 0.0

            return {
                'timestamp': datetime.now(),
                'pool_size': pool_size,
                'checked_out': checked_out,
                'checked_in': status.get('checked_in', 0),
                'overflow': overflow,
                'usage_rate': usage_rate
            }
        except Exception as e:
            logger.error(f"æ”¶é›†æŒ‡æ ‡å¤±è´¥: {e}")
            return {
                'timestamp': datetime.now(),
                'pool_size': 0,
                'checked_out': 0,
                'checked_in': 0,
                'overflow': 0,
                'usage_rate': 0.0
            }

    def get_recent_metrics(self, window_seconds: int = 60) -> List[Dict]:
        """
        è·å–æœ€è¿‘Nç§’çš„æŒ‡æ ‡

        Args:
            window_seconds: æ—¶é—´çª—å£ï¼ˆç§’ï¼‰

        Returns:
            æœ€è¿‘çš„æŒ‡æ ‡åˆ—è¡¨
        """
        cutoff = datetime.now() - timedelta(seconds=window_seconds)
        with self._lock:
            return [m for m in self.metrics_history if m['timestamp'] > cutoff]

    def get_latest_metrics(self) -> Optional[Dict]:
        """è·å–æœ€æ–°æŒ‡æ ‡"""
        with self._lock:
            return self.metrics_history[-1] if self.metrics_history else None


class AdaptiveDecisionEngine:
    """è‡ªé€‚åº”å†³ç­–å¼•æ“"""

    def __init__(self, collector: MetricsCollector, config: AdaptivePoolConfig):
        """
        åˆå§‹åŒ–å†³ç­–å¼•æ“

        Args:
            collector: æŒ‡æ ‡æ”¶é›†å™¨
            config: è‡ªé€‚åº”é…ç½®
        """
        self.collector = collector
        self.config = config
        self.last_adjustment_time = None
        self.adjustment_count = 0

    def should_adjust(self) -> tuple[bool, Optional[int], Optional[str]]:
        """
        åˆ¤æ–­æ˜¯å¦éœ€è¦è°ƒæ•´

        Returns:
            (æ˜¯å¦è°ƒæ•´, æ–°çš„pool_size, è°ƒæ•´åŸå› )
        """
        # å†·å´æœŸæ£€æŸ¥
        if self.last_adjustment_time:
            elapsed = (datetime.now() - self.last_adjustment_time).total_seconds()
            if elapsed < self.config.cooldown_seconds:
                return False, None, f"å†·å´æœŸä¸­ï¼ˆå‰©ä½™{self.config.cooldown_seconds - elapsed:.0f}ç§’ï¼‰"

        # è·å–æœ€è¿‘æŒ‡æ ‡
        recent = self.collector.get_recent_metrics(window_seconds=self.config.metrics_window_seconds)
        if not recent:
            return False, None, "æ— å¯ç”¨æŒ‡æ ‡"

        # è®¡ç®—å¹³å‡æŒ‡æ ‡
        avg_usage = sum(m['usage_rate'] for m in recent) / len(recent)
        avg_overflow = sum(m.get('overflow', 0) for m in recent) / len(recent)
        current_pool_size = recent[-1]['pool_size']

        # æ‰©å®¹å†³ç­–
        if self._should_scale_up(avg_usage, avg_overflow, current_pool_size):
            new_size = self._calculate_scale_up(current_pool_size)
            if new_size > current_pool_size:
                reason = f"é«˜è´Ÿè½½ï¼ˆä½¿ç”¨ç‡={avg_usage*100:.1f}%, æº¢å‡º={avg_overflow:.1f}ï¼‰"
                return True, new_size, reason

        # ç¼©å®¹å†³ç­–
        if self._should_scale_down(recent, avg_usage, current_pool_size):
            new_size = self._calculate_scale_down(current_pool_size)
            if new_size < current_pool_size:
                reason = f"ä½è´Ÿè½½ï¼ˆä½¿ç”¨ç‡={avg_usage*100:.1f}%ï¼‰"
                return True, new_size, reason

        return False, None, f"ç¨³å®šï¼ˆä½¿ç”¨ç‡={avg_usage*100:.1f}%ï¼‰"

    def _should_scale_up(self, avg_usage: float, avg_overflow: float, pool_size: int) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥æ‰©å®¹"""
        # ä½¿ç”¨ç‡è¿‡é«˜
        if avg_usage > self.config.scale_up_usage_threshold:
            return True

        # æº¢å‡ºè¿æ¥è¿‡å¤š
        if pool_size > 0 and avg_overflow > pool_size * self.config.scale_up_overflow_threshold:
            return True

        return False

    def _should_scale_down(self, recent: List[Dict], avg_usage: float, pool_size: int) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥ç¼©å®¹"""
        # å½“å‰æ± å¤§å°å·²ç»æ˜¯æœ€å°å€¼
        if pool_size <= self.config.min_pool_size:
            return False

        # æ‰€æœ‰recentæŒ‡æ ‡çš„ä½¿ç”¨ç‡éƒ½ä½äºé˜ˆå€¼
        if not all(m['usage_rate'] < self.config.scale_down_usage_threshold for m in recent):
            return False

        # æ²¡æœ‰æº¢å‡ºè¿æ¥
        if not all(m.get('overflow', 0) == 0 for m in recent):
            return False

        return True

    def _calculate_scale_up(self, current_size: int) -> int:
        """è®¡ç®—æ‰©å®¹åçš„å¤§å°"""
        new_size = int(current_size * self.config.scale_up_factor)
        return min(new_size, self.config.max_pool_size)

    def _calculate_scale_down(self, current_size: int) -> int:
        """è®¡ç®—ç¼©å®¹åçš„å¤§å°"""
        new_size = int(current_size * self.config.scale_down_factor)
        return max(new_size, self.config.min_pool_size)


class AdaptiveConnectionPoolManager:
    """è‡ªé€‚åº”è¿æ¥æ± ç®¡ç†å™¨"""

    def __init__(self, db, config: Optional[AdaptivePoolConfig] = None):
        """
        åˆå§‹åŒ–è‡ªé€‚åº”ç®¡ç†å™¨

        Args:
            db: FactorWeaveAnalyticsDBå®ä¾‹
            config: è‡ªé€‚åº”é…ç½®ï¼ˆå¯é€‰ï¼‰
        """
        self.db = db
        self.config = config or AdaptivePoolConfig()

        if not self.config.validate():
            raise ValueError("æ— æ•ˆçš„è‡ªé€‚åº”é…ç½®")

        self.collector = MetricsCollector(db.pool, interval=self.config.collection_interval)
        self.decision_engine = AdaptiveDecisionEngine(self.collector, self.config)
        self._running = False
        self._thread = None

    def start(self):
        """å¯åŠ¨è‡ªé€‚åº”ç®¡ç†"""
        if not self.config.enabled:
            logger.info("è‡ªé€‚åº”è¿æ¥æ± ç®¡ç†å·²ç¦ç”¨")
            return

        if self._running:
            logger.warning("è‡ªé€‚åº”ç®¡ç†å™¨å·²åœ¨è¿è¡Œ")
            return

        logger.info("ğŸ”„ å¯åŠ¨è‡ªé€‚åº”è¿æ¥æ± ç®¡ç†...")

        # å¯åŠ¨æŒ‡æ ‡æ”¶é›†
        self.collector.start()

        # å¯åŠ¨è°ƒæ•´å¾ªç¯
        self._running = True
        self._thread = threading.Thread(target=self._adjustment_loop, daemon=True, name="AdaptiveManager")
        self._thread.start()

        logger.info(f"âœ… è‡ªé€‚åº”è¿æ¥æ± ç®¡ç†å·²å¯åŠ¨ (min={self.config.min_pool_size}, max={self.config.max_pool_size})")

    def stop(self):
        """åœæ­¢è‡ªé€‚åº”ç®¡ç†"""
        self._running = False
        self.collector.stop()

        if self._thread:
            self._thread.join(timeout=5)

        logger.info("â¸ï¸ è‡ªé€‚åº”è¿æ¥æ± ç®¡ç†å·²åœæ­¢")

    def _adjustment_loop(self):
        """è°ƒæ•´å¾ªç¯"""
        check_interval = 30  # æ¯30ç§’æ£€æŸ¥ä¸€æ¬¡

        while self._running:
            try:
                should_adjust, new_pool_size, reason = self.decision_engine.should_adjust()

                if should_adjust and new_pool_size:
                    self._apply_adjustment(new_pool_size, reason)
                    self.decision_engine.last_adjustment_time = datetime.now()
                    self.decision_engine.adjustment_count += 1
                else:
                    # è®°å½•å†³ç­–æ—¥å¿—ï¼ˆè°ƒè¯•ç”¨ï¼‰
                    if logger.level("DEBUG").no <= logger._core.min_level:
                        logger.debug(f"è¿æ¥æ± ç¨³å®š: {reason}")

            except Exception as e:
                logger.error(f"è‡ªé€‚åº”è°ƒæ•´å¤±è´¥: {e}")
                import traceback
                logger.error(traceback.format_exc())

            time.sleep(check_interval)

    def _apply_adjustment(self, new_pool_size: int, reason: str):
        """åº”ç”¨è°ƒæ•´"""
        old_size = self.db.pool.pool.size()  # pool.poolæ˜¯QueuePoolå®ä¾‹

        logger.info(f"ğŸ”„ è‡ªåŠ¨è°ƒæ•´è¿æ¥æ± : {old_size} -> {new_pool_size} ({reason})")

        try:
            # åˆ›å»ºæ–°é…ç½®
            new_config = ConnectionPoolConfig(pool_size=new_pool_size)

            # çƒ­é‡è½½
            success = self.db.reload_pool(new_config)

            if success:
                logger.info(f"âœ… è¿æ¥æ± å·²è‡ªåŠ¨è°ƒæ•´: pool_size={new_pool_size}")
            else:
                logger.error(f"âŒ è¿æ¥æ± è‡ªåŠ¨è°ƒæ•´å¤±è´¥")

        except Exception as e:
            logger.error(f"âŒ è¿æ¥æ± è‡ªåŠ¨è°ƒæ•´å¼‚å¸¸: {e}")

    def get_status(self) -> Dict[str, Any]:
        """
        è·å–è‡ªé€‚åº”ç®¡ç†å™¨çŠ¶æ€

        Returns:
            çŠ¶æ€ä¿¡æ¯å­—å…¸
        """
        latest_metrics = self.collector.get_latest_metrics()

        return {
            'enabled': self.config.enabled,
            'running': self._running,
            'adjustment_count': self.decision_engine.adjustment_count,
            'last_adjustment': self.decision_engine.last_adjustment_time.isoformat()
            if self.decision_engine.last_adjustment_time else None,
            'current_pool_size': latest_metrics['pool_size'] if latest_metrics else None,
            'current_usage_rate': f"{latest_metrics['usage_rate']*100:.1f}%" if latest_metrics else None,
            'config': {
                'min_pool_size': self.config.min_pool_size,
                'max_pool_size': self.config.max_pool_size,
                'scale_up_threshold': f"{self.config.scale_up_usage_threshold*100:.0f}%",
                'scale_down_threshold': f"{self.config.scale_down_usage_threshold*100:.0f}%",
                'cooldown_seconds': self.config.cooldown_seconds
            }
        }


# ========================================
# å…¨å±€ç®¡ç†å™¨å®ä¾‹ï¼ˆå¯é€‰ï¼‰
# ========================================

_global_adaptive_manager: Optional[AdaptiveConnectionPoolManager] = None
_manager_lock = threading.Lock()


def get_adaptive_manager(db=None, config: Optional[AdaptivePoolConfig] = None) -> AdaptiveConnectionPoolManager:
    """
    è·å–å…¨å±€è‡ªé€‚åº”ç®¡ç†å™¨å®ä¾‹ï¼ˆå•ä¾‹ï¼‰

    Args:
        db: FactorWeaveAnalyticsDBå®ä¾‹ï¼ˆé¦–æ¬¡è°ƒç”¨æ—¶å¿…éœ€ï¼‰
        config: è‡ªé€‚åº”é…ç½®ï¼ˆå¯é€‰ï¼‰

    Returns:
        AdaptiveConnectionPoolManagerå®ä¾‹
    """
    global _global_adaptive_manager

    with _manager_lock:
        if _global_adaptive_manager is None:
            if db is None:
                raise ValueError("é¦–æ¬¡è°ƒç”¨get_adaptive_manageréœ€è¦æä¾›dbå‚æ•°")

            _global_adaptive_manager = AdaptiveConnectionPoolManager(db, config)

        return _global_adaptive_manager


def start_adaptive_management(db, config: Optional[AdaptivePoolConfig] = None):
    """
    å¯åŠ¨å…¨å±€è‡ªé€‚åº”ç®¡ç†ï¼ˆä¾¿æ·å‡½æ•°ï¼‰

    Args:
        db: FactorWeaveAnalyticsDBå®ä¾‹
        config: è‡ªé€‚åº”é…ç½®ï¼ˆå¯é€‰ï¼‰
    """
    manager = get_adaptive_manager(db, config)
    manager.start()
    return manager


def stop_adaptive_management():
    """åœæ­¢å…¨å±€è‡ªé€‚åº”ç®¡ç†ï¼ˆä¾¿æ·å‡½æ•°ï¼‰"""
    global _global_adaptive_manager

    with _manager_lock:
        if _global_adaptive_manager:
            _global_adaptive_manager.stop()
