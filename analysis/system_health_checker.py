"""
FactorWeave-Quant é‡åŒ–äº¤æ˜“ç³»ç»Ÿå¥åº·æ£€æŸ¥å™¨
ç›‘æ§å½¢æ€è¯†åˆ«ç³»ç»Ÿçš„æ•´ä½“å¥åº·çŠ¶æ€å’Œæ€§èƒ½æŒ‡æ ‡
"""

from analysis.pattern_base import PatternAlgorithmFactory
from analysis.pattern_recognition import (
    EnhancedPatternRecognizer,
    get_performance_monitor,
    get_pattern_cache,
    get_pattern_recognizer_info
)
import os
import sys
import time
import psutil
import traceback
from typing import Dict, List, Any, Optional
from datetime import datetime, timedelta
import pandas as pd
import numpy as np

# æ ¸å¿ƒæœåŠ¡å¯¼å…¥
from core.metrics.aggregation_service import MetricsAggregationService
from core.metrics.repository import MetricsRepository
from core.containers import ServiceContainer

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(__file__)))


class SystemHealthChecker:
    """ç³»ç»Ÿå¥åº·æ£€æŸ¥å™¨ - ç°åœ¨é€šè¿‡æ ¸å¿ƒæœåŠ¡è·å–æŒ‡æ ‡"""

    def __init__(self, aggregation_service: MetricsAggregationService, repository: MetricsRepository):
        self.check_results = {}
        self.start_time = datetime.now()
        self._aggregation_service = aggregation_service
        self._repository = repository

    def run_comprehensive_check(self) -> Dict[str, Any]:
        """è¿è¡Œå…¨é¢çš„ç³»ç»Ÿå¥åº·æ£€æŸ¥"""
        print("ğŸ” å¼€å§‹FactorWeave-Quant é‡åŒ–äº¤æ˜“ç³»ç»Ÿå¥åº·æ£€æŸ¥...")

        health_report = {
            'timestamp': datetime.now().isoformat(),
            'system_info': self._check_system_info(),
            'pattern_recognition': self._check_pattern_recognition(),
            'performance_metrics': self._check_performance_metrics(),
            'cache_system': self._check_cache_system(),
            'memory_usage': self._check_memory_usage(),
            'dependencies': self._check_dependencies(),
            'database_connectivity': self._check_database_connectivity(),
            'ui_components': self._check_ui_components(),
            'overall_health': 'unknown'
        }

        # è®¡ç®—æ€»ä½“å¥åº·çŠ¶æ€
        health_report['overall_health'] = self._calculate_overall_health(
            health_report)

        # ç”Ÿæˆå»ºè®®
        health_report['recommendations'] = self._generate_recommendations(
            health_report)

        print(f"âœ… ç³»ç»Ÿå¥åº·æ£€æŸ¥å®Œæˆï¼Œæ€»ä½“çŠ¶æ€: {health_report['overall_health']}")

        return health_report

    def _check_system_info(self) -> Dict[str, Any]:
        """æ£€æŸ¥ç³»ç»ŸåŸºæœ¬ä¿¡æ¯"""
        try:
            # ğŸ”§ ä¿®å¤ï¼šæ·»åŠ æ›´å®‰å…¨çš„ä¿¡æ¯è·å–
            try:
                info = get_pattern_recognizer_info()
            except Exception as e:
                print(f"âš ï¸ è·å–å½¢æ€è¯†åˆ«å™¨ä¿¡æ¯å¤±è´¥: {e}")
                # ä½¿ç”¨é»˜è®¤ä¿¡æ¯
                info = {
                    'version': 'unknown',
                    'supported_patterns': 0,
                    'performance_optimized': False,
                    'cache_enabled': False,
                    'monitoring_enabled': True,  # å‡è®¾ç›‘æ§æ˜¯å¯ç”¨çš„
                    'database_algorithms': False,
                    'ml_predictions': False
                }

            return {
                'status': 'healthy',
                'version': info.get('version', 'unknown'),
                'supported_patterns': info.get('supported_patterns', 0),
                'features': {
                    'performance_optimized': info.get('performance_optimized', False),
                    'cache_enabled': info.get('cache_enabled', False),
                    'monitoring_enabled': info.get('monitoring_enabled', False),
                    'database_algorithms': info.get('database_algorithms', False),
                    'ml_predictions': info.get('ml_predictions', False)
                }
            }
        except Exception as e:
            print(f"âŒ ç³»ç»Ÿä¿¡æ¯æ£€æŸ¥å¤±è´¥: {e}")
            return {
                'status': 'error',
                'error': str(e),
                'details': traceback.format_exc()
            }

    def _check_pattern_recognition(self) -> Dict[str, Any]:
        """æ£€æŸ¥å½¢æ€è¯†åˆ«åŠŸèƒ½"""
        try:
            # ğŸ”§ ä¿®å¤ï¼šæ·»åŠ æ›´å®‰å…¨çš„å½¢æ€è¯†åˆ«æ£€æŸ¥
            print("ğŸ” æ£€æŸ¥å½¢æ€è¯†åˆ«åŠŸèƒ½...")

            try:
                # åˆ›å»ºæµ‹è¯•æ•°æ®
                test_data = self._generate_test_kdata()
                print(f"âœ“ æµ‹è¯•æ•°æ®ç”ŸæˆæˆåŠŸï¼Œæ•°æ®é‡: {len(test_data)}")

                # æµ‹è¯•è¯†åˆ«å™¨åˆ›å»º
                recognizer = EnhancedPatternRecognizer(debug_mode=False)
                print("âœ“ å½¢æ€è¯†åˆ«å™¨åˆ›å»ºæˆåŠŸ")

                # æµ‹è¯•å½¢æ€è¯†åˆ«
                start_time = time.time()
                patterns = recognizer.identify_patterns(
                    test_data, confidence_threshold=0.1)
                processing_time = time.time() - start_time
                print(f"âœ“ å½¢æ€è¯†åˆ«å®Œæˆï¼Œè¯†åˆ«åˆ° {len(patterns)} ä¸ªå½¢æ€")

                return {
                    'status': 'healthy',
                    'recognizer_created': True,
                    'patterns_detected': len(patterns),
                    'processing_time': processing_time,
                    'test_data_size': len(test_data),
                    'average_confidence': np.mean([p.get('confidence', 0) for p in patterns]) if patterns else 0
                }
            except ImportError as e:
                print(f"âš ï¸ å½¢æ€è¯†åˆ«æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
                return {
                    'status': 'warning',
                    'error': f'æ¨¡å—å¯¼å…¥å¤±è´¥: {e}',
                    'recognizer_created': False,
                    'patterns_detected': 0,
                    'processing_time': 0,
                    'test_data_size': 0,
                    'average_confidence': 0
                }
        except Exception as e:
            print(f"âŒ å½¢æ€è¯†åˆ«æ£€æŸ¥å¤±è´¥: {e}")
            return {
                'status': 'error',
                'error': str(e),
                'details': traceback.format_exc()
            }

    def _check_performance_metrics(self) -> Dict[str, Any]:
        """ä»èšåˆæœåŠ¡å’Œä»“å‚¨æ£€æŸ¥æ€§èƒ½æŒ‡æ ‡"""
        try:
            # å°è¯•ä»èšåˆæœåŠ¡è·å–å®æ—¶ï¼ˆå†…å­˜ä¸­ï¼‰çš„æŒ‡æ ‡
            live_metrics = self._aggregation_service.get_latest_app_metrics()

            total_calls = 0
            total_errors = 0
            total_duration = 0

            for op_data in live_metrics.values():
                calls = len(op_data.get('durations', []))
                total_calls += calls
                total_errors += op_data.get('error_count', 0)
                total_duration += sum(op_data.get('durations', []))

            # ä»æ•°æ®åº“è·å–å†å²è¶‹åŠ¿ï¼ˆä¾‹å¦‚è¿‡å»1å°æ—¶ï¼‰
            end_time = datetime.now()
            start_time = end_time - timedelta(hours=1)
            historical_data = self._repository.query_historical_data(
                start_time=start_time,
                end_time=end_time,
                table='app_metrics_summary'
            )

            return {
                'status': 'healthy',
                'live_monitored_operations': len(live_metrics),
                'live_total_calls': total_calls,
                'live_success_rate': (total_calls - total_errors) / total_calls if total_calls > 0 else 1.0,
                'live_avg_duration': total_duration / total_calls if total_calls > 0 else 0,
                'historical_records_count': len(historical_data),
            }
        except Exception as e:
            return {
                'status': 'error',
                'error': f"æ— æ³•è·å–æ€§èƒ½æŒ‡æ ‡: {e}",
                'details': traceback.format_exc()
            }

    def _check_cache_system(self) -> Dict[str, Any]:
        """æ£€æŸ¥ç¼“å­˜ç³»ç»Ÿ"""
        try:
            cache = get_pattern_cache()
            stats = cache.get_stats()

            return {
                'status': 'healthy',
                'cache_size': stats.get('cache_size', 0),
                'max_size': stats.get('max_size', 0),
                'hit_count': stats.get('hit_count', 0),
                'miss_count': stats.get('miss_count', 0),
                'hit_rate': stats.get('hit_rate', 0),
                'memory_usage_estimate': stats.get('memory_usage_estimate', 0),
                'utilization': stats.get('cache_size', 0) / stats.get('max_size', 1)
            }
        except Exception as e:
            return {
                'status': 'error',
                'error': str(e),
                'details': traceback.format_exc()
            }

    def _check_memory_usage(self) -> Dict[str, Any]:
        """ä»èµ„æºæœåŠ¡æ£€æŸ¥å†…å­˜ä½¿ç”¨æƒ…å†µï¼ˆé€šè¿‡èšåˆå™¨ï¼‰"""
        try:
            # è¿™é‡Œçš„é€»è¾‘éœ€è¦è°ƒæ•´ï¼Œå› ä¸ºæˆ‘ä»¬ç°åœ¨ä¾èµ–äºäº‹ä»¶é©±åŠ¨çš„èšåˆæ•°æ®
            # æˆ‘ä»¬ä»æ•°æ®åº“æŸ¥è¯¢æœ€æ–°çš„èµ„æºè®°å½•
            end_time = datetime.now()
            start_time = end_time - timedelta(minutes=5)  # æŸ¥è¯¢è¿‡å»5åˆ†é’Ÿ

            recent_data = self._repository.query_historical_data(
                start_time, end_time, 'resource_metrics_summary'
            )

            if not recent_data:
                return {
                    'status': 'warning',
                    'message': 'æœ€è¿‘5åˆ†é’Ÿå†…æ²¡æœ‰å¯ç”¨çš„èµ„æºæŒ‡æ ‡æ•°æ®ã€‚ç›‘æ§æœåŠ¡å¯èƒ½å°šæœªå¯åŠ¨æˆ–å†™å…¥æ•°æ®åº“ã€‚'
                }

            latest_record = recent_data[-1]
            return {
                'status': 'healthy',
                'cpu_percent': latest_record.get('cpu'),
                'memory_percent': latest_record.get('mem'),
                'disk_percent': latest_record.get('disk'),
                'last_updated': latest_record.get('t_stamp')
            }
        except Exception as e:
            return {
                'status': 'error',
                'error': f"æ— æ³•è·å–å†…å­˜æŒ‡æ ‡: {e}",
                'details': traceback.format_exc()
            }

    def _check_dependencies(self) -> Dict[str, Any]:
        """æ£€æŸ¥ä¾èµ–åº“"""
        dependencies = {
            'pandas': 'pd',
            'numpy': 'np',
            'PyQt5': 'PyQt5',
            'psutil': 'psutil'
        }

        results = {}
        all_available = True

        for name, import_name in dependencies.items():
            try:
                __import__(import_name)
                results[name] = {'status': 'available', 'version': 'unknown'}

                # å°è¯•è·å–ç‰ˆæœ¬ä¿¡æ¯
                try:
                    module = sys.modules[import_name]
                    if hasattr(module, '__version__'):
                        results[name]['version'] = module.__version__
                except:
                    pass

            except ImportError as e:
                results[name] = {'status': 'missing', 'error': str(e)}
                all_available = False

        return {
            'status': 'healthy' if all_available else 'warning',
            'dependencies': results,
            'all_available': all_available
        }

    def _check_database_connectivity(self) -> Dict[str, Any]:
        """æ£€æŸ¥æ•°æ®åº“è¿æ¥"""
        try:
            # æ£€æŸ¥æ•°æ®åº“æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            db_paths = [
                'db/pattern_algorithms.db',
                'db/hikyuu.db',
                'db/stock_data.db'
            ]

            db_status = {}
            for db_path in db_paths:
                if os.path.exists(db_path):
                    db_status[db_path] = {
                        'exists': True,
                        'size_mb': os.path.getsize(db_path) / 1024 / 1024,
                        'modified': datetime.fromtimestamp(os.path.getmtime(db_path)).isoformat()
                    }
                else:
                    db_status[db_path] = {'exists': False}

            return {
                'status': 'healthy',
                'databases': db_status
            }
        except Exception as e:
            return {
                'status': 'error',
                'error': str(e),
                'details': traceback.format_exc()
            }

    def _check_ui_components(self) -> Dict[str, Any]:
        """æ£€æŸ¥UIç»„ä»¶"""
        try:
            # æ£€æŸ¥å…³é”®UIæ–‡ä»¶æ˜¯å¦å­˜åœ¨
            ui_files = [
                'gui/widgets/analysis_tabs/pattern_tab_pro.py',
                'gui/widgets/analysis_tabs/pattern_tab.py',
                'gui/widgets/base_analysis_tab.py'
            ]

            ui_status = {}
            for ui_file in ui_files:
                if os.path.exists(ui_file):
                    ui_status[ui_file] = {
                        'exists': True,
                        'size_kb': os.path.getsize(ui_file) / 1024,
                        'modified': datetime.fromtimestamp(os.path.getmtime(ui_file)).isoformat()
                    }
                else:
                    ui_status[ui_file] = {'exists': False}

            return {
                'status': 'healthy',
                'ui_files': ui_status
            }
        except Exception as e:
            return {
                'status': 'error',
                'error': str(e),
                'details': traceback.format_exc()
            }

    def _generate_test_kdata(self) -> pd.DataFrame:
        """ç”Ÿæˆæµ‹è¯•Kçº¿æ•°æ®"""
        dates = pd.date_range(start='2024-01-01', periods=100, freq='D')

        # ç”Ÿæˆæ¨¡æ‹Ÿä»·æ ¼æ•°æ®
        np.random.seed(42)
        base_price = 100
        price_changes = np.random.normal(0, 2, 100)
        prices = [base_price]

        for change in price_changes[1:]:
            new_price = max(prices[-1] + change, 1)  # ç¡®ä¿ä»·æ ¼ä¸ºæ­£
            prices.append(new_price)

        # åˆ›å»ºOHLCæ•°æ®
        data = []
        for i, (date, close) in enumerate(zip(dates, prices)):
            high = close + abs(np.random.normal(0, 1))
            low = close - abs(np.random.normal(0, 1))
            open_price = close + np.random.normal(0, 0.5)

            data.append({
                'date': date,
                'open': open_price,
                'high': max(open_price, high, close),
                'low': min(open_price, low, close),
                'close': close,
                'volume': np.random.randint(1000, 10000)
            })

        return pd.DataFrame(data)

    def _calculate_overall_health(self, report: Dict[str, Any]) -> str:
        """è®¡ç®—æ€»ä½“å¥åº·çŠ¶æ€"""
        error_count = 0
        warning_count = 0
        total_checks = 0

        for key, value in report.items():
            if key in ['timestamp', 'overall_health', 'recommendations']:
                continue

            total_checks += 1
            if isinstance(value, dict) and 'status' in value:
                if value['status'] == 'error':
                    error_count += 1
                elif value['status'] == 'warning':
                    warning_count += 1

        if error_count > 0:
            return 'critical'
        elif warning_count > 0:
            return 'warning'
        else:
            return 'healthy'

    def _generate_recommendations(self, report: Dict[str, Any]) -> List[str]:
        """ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        recommendations = []

        # æ£€æŸ¥æ€§èƒ½æŒ‡æ ‡
        perf = report.get('performance_metrics', {})
        if perf.get('success_rate', 1) < 0.9:
            recommendations.append("å½¢æ€è¯†åˆ«æˆåŠŸç‡è¾ƒä½ï¼Œå»ºè®®æ£€æŸ¥ç®—æ³•é…ç½®å’Œæ•°æ®è´¨é‡")

        if perf.get('live_avg_duration', 0) > 1.0:
            recommendations.append("å¤„ç†æ—¶é—´è¾ƒé•¿ï¼Œå»ºè®®ä¼˜åŒ–ç®—æ³•æˆ–å¢åŠ ç¼“å­˜")

        # æ£€æŸ¥ç¼“å­˜ç³»ç»Ÿ
        cache = report.get('cache_system', {})
        if cache.get('hit_rate', 0) < 0.5:
            recommendations.append("ç¼“å­˜å‘½ä¸­ç‡è¾ƒä½ï¼Œå»ºè®®è°ƒæ•´ç¼“å­˜ç­–ç•¥")

        if cache.get('utilization', 0) > 0.9:
            recommendations.append("ç¼“å­˜ä½¿ç”¨ç‡è¿‡é«˜ï¼Œå»ºè®®å¢åŠ ç¼“å­˜å¤§å°")

        # æ£€æŸ¥å†…å­˜ä½¿ç”¨
        memory = report.get('memory_usage', {})
        if memory.get('cpu_percent', 0) > 80:
            recommendations.append("CPUä½¿ç”¨ç‡è¿‡é«˜ï¼Œå»ºè®®ä¼˜åŒ–CPUä½¿ç”¨")

        if memory.get('memory_percent', 0) > 80:
            recommendations.append("å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜ï¼Œå»ºè®®ä¼˜åŒ–å†…å­˜ç®¡ç†")

        # æ£€æŸ¥ä¾èµ–
        deps = report.get('dependencies', {})
        if not deps.get('all_available', True):
            recommendations.append("å­˜åœ¨ç¼ºå¤±çš„ä¾èµ–åº“ï¼Œå»ºè®®å®‰è£…å®Œæ•´ä¾èµ–")

        if not recommendations:
            recommendations.append("ç³»ç»Ÿè¿è¡Œè‰¯å¥½ï¼Œæ— éœ€ç‰¹åˆ«ä¼˜åŒ–")

        return recommendations

    def generate_health_report(self, report: Dict[str, Any]) -> str:
        """ç”Ÿæˆå¯è¯»çš„å¥åº·æŠ¥å‘Š"""
        lines = []
        lines.append("=" * 60)
        lines.append("FactorWeave-Quant é‡åŒ–äº¤æ˜“ç³»ç»Ÿå¥åº·æŠ¥å‘Š")
        lines.append("=" * 60)
        lines.append(f"æ£€æŸ¥æ—¶é—´: {report['timestamp']}")
        lines.append(f"æ€»ä½“çŠ¶æ€: {report['overall_health'].upper()}")
        lines.append("")

        # ç³»ç»Ÿä¿¡æ¯
        sys_info = report.get('system_info', {})
        lines.append("ğŸ“Š ç³»ç»Ÿä¿¡æ¯:")
        lines.append(f"  ç‰ˆæœ¬: {sys_info.get('version', 'unknown')}")
        lines.append(f"  æ”¯æŒå½¢æ€: {sys_info.get('supported_patterns', 0)}ç§")
        lines.append("")

        # æ€§èƒ½æŒ‡æ ‡
        perf = report.get('performance_metrics', {})
        lines.append("âš¡ æ€§èƒ½æŒ‡æ ‡:")
        lines.append(f"  å®æ—¶ç›‘æ§æ“ä½œ: {perf.get('live_monitored_operations', 0)}")
        lines.append(f"  å®æ—¶æ€»è°ƒç”¨æ¬¡æ•°: {perf.get('live_total_calls', 0)}")
        lines.append(f"  å®æ—¶æˆåŠŸç‡: {perf.get('live_success_rate', 0):.2%}")
        lines.append(f"  å®æ—¶å¹³å‡å¤„ç†æ—¶é—´: {perf.get('live_avg_duration', 0):.3f}ç§’")
        lines.append(f"  å†å²è®°å½•æ€»æ•°: {perf.get('historical_records_count', 0)}")
        lines.append("")

        # å†…å­˜ä½¿ç”¨
        memory = report.get('memory_usage', {})
        lines.append("ğŸ’¾ å†…å­˜ä½¿ç”¨:")
        lines.append(f"  CPUä½¿ç”¨ç‡: {memory.get('cpu_percent', 0):.1f}%")
        lines.append(f"  å†…å­˜ä½¿ç”¨ç‡: {memory.get('memory_percent', 0):.1f}%")
        lines.append(f"  ç£ç›˜ä½¿ç”¨ç‡: {memory.get('disk_percent', 0):.1f}%")
        lines.append(f"  æœ€åæ›´æ–°æ—¶é—´: {memory.get('last_updated', 'æœªçŸ¥')}")
        lines.append("")

        # å»ºè®®
        recommendations = report.get('recommendations', [])
        lines.append("ğŸ’¡ ä¼˜åŒ–å»ºè®®:")
        for i, rec in enumerate(recommendations, 1):
            lines.append(f"  {i}. {rec}")

        lines.append("")
        lines.append("=" * 60)

        return "\n".join(lines)


def main():
    """ç”¨äºç‹¬ç«‹æµ‹è¯•çš„å…¥å£ç‚¹"""
    print("è¿è¡Œç³»ç»Ÿå¥åº·æ£€æŸ¥å™¨ï¼ˆç‹¬ç«‹æµ‹è¯•æ¨¡å¼ï¼‰...")

    # åœ¨æµ‹è¯•æ¨¡å¼ä¸‹ï¼Œæˆ‘ä»¬éœ€è¦æ¨¡æ‹ŸæœåŠ¡å®¹å™¨å’ŒæœåŠ¡
    from core.events import EventBus

    # 1. åˆ›å»ºæ¨¡æ‹Ÿç»„ä»¶
    event_bus = EventBus()
    container = ServiceContainer()

    # 2. åˆ›å»ºå¹¶æ³¨å†ŒçœŸå®çš„æœåŠ¡
    repo = MetricsRepository(db_path=':memory:')  # ä½¿ç”¨å†…å­˜æ•°æ®åº“è¿›è¡Œæµ‹è¯•
    agg_service = MetricsAggregationService(event_bus, repo)

    # 3. å®ä¾‹åŒ–æ£€æŸ¥å™¨
    checker = SystemHealthChecker(
        aggregation_service=agg_service, repository=repo)

    # 4. è¿è¡Œæ£€æŸ¥å¹¶æ‰“å°æŠ¥å‘Š
    report = checker.run_comprehensive_check()
    report_str = checker.generate_health_report(report)
    print("\n--- å¥åº·æ£€æŸ¥æŠ¥å‘Š ---")
    print(report_str)
    print("---------------------\n")


if __name__ == '__main__':
    main()
