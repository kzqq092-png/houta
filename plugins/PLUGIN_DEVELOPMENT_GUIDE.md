# HIkyuu-UI æ•°æ®æºæ’ä»¶å¼€å‘æŒ‡å—

## ğŸ“‹ æ¦‚è¿°

æœ¬æŒ‡å—æä¾›äº†ä¸ºHIkyuu-UIç³»ç»Ÿå¼€å‘æ ‡å‡†åŒ–æ•°æ®æºæ’ä»¶çš„å®Œæ•´æŒ‡å¯¼ï¼ŒåŒ…æ‹¬æ’ä»¶æ¶æ„ã€å¼€å‘è§„èŒƒã€æœ€ä½³å®è·µå’Œè´¨é‡ä¿è¯æµç¨‹ã€‚

**ç‰ˆæœ¬**: 2.0  
**æ›´æ–°æ—¥æœŸ**: 2024-09-17  
**é€‚ç”¨èŒƒå›´**: HIkyuu-UI v2.0+

---

## ğŸ—ï¸ æ’ä»¶æ¶æ„æ¦‚è§ˆ

### 1. æ’ä»¶ä½“ç³»ç»“æ„

```
HIkyuu-UIæ’ä»¶ä½“ç³»
â”œâ”€â”€ ç»Ÿä¸€æ’ä»¶æ•°æ®ç®¡ç†å™¨ (UniPluginDataManager)
â”‚   â”œâ”€â”€ æ’ä»¶ä¸­å¿ƒ (PluginCenter)
â”‚   â”œâ”€â”€ TETè·¯ç”±å¼•æ“ (TETRouterEngine)
â”‚   â””â”€â”€ é£é™©ç®¡ç†å™¨ (RiskManager)
â”œâ”€â”€ æ ‡å‡†æ’ä»¶æ¥å£ (IDataSourcePlugin)
â”œâ”€â”€ æ ‡å‡†æ’ä»¶æ¨¡æ¿ (StandardDataSourcePlugin)
â””â”€â”€ å…·ä½“æ’ä»¶å®ç°
    â”œâ”€â”€ ä¸œæ–¹è´¢å¯Œæ’ä»¶
    â”œâ”€â”€ æ–°æµªæ’ä»¶
    â”œâ”€â”€ åŒèŠ±é¡ºæ’ä»¶
    â””â”€â”€ è‡ªå®šä¹‰æ’ä»¶
```

### 2. æ ¸å¿ƒè®¾è®¡åŸåˆ™

- **ç»Ÿä¸€æ¥å£**: æ‰€æœ‰æ’ä»¶å¿…é¡»å®ç° `IDataSourcePlugin` æ¥å£
- **æ ‡å‡†åŒ–æ¨¡æ¿**: åŸºäº `StandardDataSourcePlugin` åŸºç±»å¼€å‘
- **è´¨é‡ä¼˜å…ˆ**: å†…ç½®æ•°æ®è´¨é‡éªŒè¯å’Œç›‘æ§
- **æ€§èƒ½å¯¼å‘**: æ”¯æŒç¼“å­˜ã€é‡è¯•å’Œå¼‚æ­¥å¤„ç†
- **å®‰å…¨å¯é **: å®Œå–„çš„é”™è¯¯å¤„ç†å’Œç†”æ–­å™¨æœºåˆ¶

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. åˆ›å»ºæ–°æ’ä»¶

```python
from plugins.templates.standard_data_source_plugin import StandardDataSourcePlugin, PluginConfig
from core.plugin_types import AssetType, DataType
import pandas as pd
from typing import Dict, List, Any

class YourDataSourcePlugin(StandardDataSourcePlugin):
    """æ‚¨çš„æ•°æ®æºæ’ä»¶"""
    
    def __init__(self):
        config = PluginConfig(
            api_endpoint="https://api.yourprovider.com/v1",
            timeout=30,
            retry_count=3,
            supported_markets=["SH", "SZ", "HK"],
            supported_frequencies=["1m", "5m", "15m", "30m", "60m", "D", "W", "M"]
        )
        super().__init__(
            plugin_id="your_provider",
            plugin_name="Your Data Provider",
            config=config
        )
    
    # å®ç°å¿…éœ€çš„æŠ½è±¡æ–¹æ³•
    def get_version(self) -> str:
        return "1.0.0"
    
    def get_description(self) -> str:
        return "Your data provider plugin for HIkyuu-UI"
    
    def get_author(self) -> str:
        return "Your Name <your.email@example.com>"
    
    def get_supported_asset_types(self) -> List[AssetType]:
        return [AssetType.STOCK, AssetType.INDEX, AssetType.FUND]
    
    def get_supported_data_types(self) -> List[DataType]:
        return [
            DataType.HISTORICAL_KLINE,
            DataType.REAL_TIME_QUOTE,
            DataType.ASSET_LIST
        ]
    
    def get_capabilities(self) -> Dict[str, Any]:
        return {
            "markets": self.config.supported_markets,
            "frequencies": self.config.supported_frequencies,
            "real_time_support": True,
            "historical_data": True,
            "max_symbols_per_request": 100,
            "rate_limit": "1000 requests/hour"
        }
    
    # å®ç°è¿æ¥ç®¡ç†
    def _internal_connect(self, **kwargs) -> bool:
        """å®ç°å…·ä½“çš„è¿æ¥é€»è¾‘"""
        try:
            # è¿™é‡Œå®ç°æ‚¨çš„è¿æ¥é€»è¾‘
            # ä¾‹å¦‚ï¼šéªŒè¯APIå¯†é’¥ã€æµ‹è¯•è¿æ¥ç­‰
            self.logger.info("è¿æ¥åˆ°æ•°æ®æº...")
            return True
        except Exception as e:
            self.logger.error(f"è¿æ¥å¤±è´¥: {e}")
            return False
    
    def _internal_disconnect(self) -> bool:
        """å®ç°å…·ä½“çš„æ–­å¼€è¿æ¥é€»è¾‘"""
        try:
            # è¿™é‡Œå®ç°æ‚¨çš„æ–­å¼€è¿æ¥é€»è¾‘
            self.logger.info("æ–­å¼€æ•°æ®æºè¿æ¥...")
            return True
        except Exception as e:
            self.logger.error(f"æ–­å¼€è¿æ¥å¤±è´¥: {e}")
            return False
    
    # å®ç°æ•°æ®è·å–æ–¹æ³•
    def _internal_get_asset_list(self, asset_type: AssetType, market: str = None) -> List[Dict[str, Any]]:
        """è·å–èµ„äº§åˆ—è¡¨"""
        # å®ç°è·å–èµ„äº§åˆ—è¡¨çš„é€»è¾‘
        return [
            {
                "symbol": "000001.SZ",
                "name": "å¹³å®‰é“¶è¡Œ",
                "market": "SZ",
                "asset_type": "STOCK"
            }
            # ... æ›´å¤šè‚¡ç¥¨æ•°æ®
        ]
    
    def _internal_get_kdata(self, symbol: str, freq: str = "D", 
                           start_date: str = None, end_date: str = None,
                           count: int = None) -> pd.DataFrame:
        """è·å–Kçº¿æ•°æ®"""
        # å®ç°è·å–Kçº¿æ•°æ®çš„é€»è¾‘
        # è¿”å›æ ‡å‡†æ ¼å¼çš„DataFrame
        return pd.DataFrame({
            'datetime': [],
            'open': [],
            'high': [],
            'low': [],
            'close': [],
            'volume': []
        })
    
    def _internal_get_real_time_quotes(self, symbols: List[str]) -> List[Dict[str, Any]]:
        """è·å–å®æ—¶è¡Œæƒ…"""
        # å®ç°è·å–å®æ—¶è¡Œæƒ…çš„é€»è¾‘
        return [
            {
                "symbol": symbol,
                "price": 10.50,
                "change": 0.15,
                "change_pct": 1.45,
                "volume": 1000000,
                "timestamp": "2024-09-17 15:00:00"
            }
            for symbol in symbols
        ]
```

### 2. æ’ä»¶æ–‡ä»¶ç»“æ„

```
plugins/
â”œâ”€â”€ your_provider/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ your_provider_plugin.py     # ä¸»æ’ä»¶æ–‡ä»¶
â”‚   â”œâ”€â”€ config.json                 # æ’ä»¶é…ç½®
â”‚   â”œâ”€â”€ requirements.txt            # ä¾èµ–åŒ…
â”‚   â”œâ”€â”€ README.md                   # æ’ä»¶è¯´æ˜
â”‚   â””â”€â”€ tests/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ test_your_provider.py   # å•å…ƒæµ‹è¯•
â”‚       â””â”€â”€ test_data/              # æµ‹è¯•æ•°æ®
```

### 3. æ’ä»¶é…ç½®æ–‡ä»¶ (config.json)

```json
{
    "plugin_info": {
        "id": "your_provider",
        "name": "Your Data Provider",
        "version": "1.0.0",
        "description": "Your data provider plugin for HIkyuu-UI",
        "author": "Your Name <your.email@example.com>",
        "plugin_type": "data_source",
        "category": "community"
    },
    "capabilities": {
        "supported_asset_types": ["STOCK", "INDEX", "FUND"],
        "supported_data_types": ["HISTORICAL_KLINE", "REAL_TIME_QUOTE", "ASSET_LIST"],
        "supported_markets": ["SH", "SZ", "HK"],
        "supported_frequencies": ["1m", "5m", "15m", "30m", "60m", "D", "W", "M"],
        "real_time_support": true,
        "historical_data": true
    },
    "config_schema": {
        "api_endpoint": {
            "type": "string",
            "default": "https://api.yourprovider.com/v1",
            "description": "APIç«¯ç‚¹åœ°å€"
        },
        "api_key": {
            "type": "string",
            "default": "",
            "description": "APIå¯†é’¥",
            "sensitive": true
        },
        "timeout": {
            "type": "integer",
            "default": 30,
            "min": 5,
            "max": 120,
            "description": "è¯·æ±‚è¶…æ—¶æ—¶é—´(ç§’)"
        }
    },
    "requirements": [
        "requests>=2.28.0",
        "pandas>=1.5.0"
    ]
}
```

---

## ğŸ“ å¼€å‘è§„èŒƒ

### 1. å‘½åè§„èŒƒ

#### æ’ä»¶æ–‡ä»¶å‘½å
- æ’ä»¶ç›®å½•: `your_provider/`
- ä¸»æ–‡ä»¶: `your_provider_plugin.py`
- æ’ä»¶ç±»: `YourProviderPlugin`
- æ’ä»¶ID: `your_provider`

#### æ–¹æ³•å‘½å
- å…¬å¼€æ–¹æ³•: ä½¿ç”¨æ¸…æ™°çš„åŠ¨è¯+åè¯æ ¼å¼ (`get_asset_list`, `connect`)
- å†…éƒ¨æ–¹æ³•: ä½¿ç”¨ `_internal_` å‰ç¼€ (`_internal_connect`)
- ç§æœ‰æ–¹æ³•: ä½¿ç”¨å•ä¸‹åˆ’çº¿å‰ç¼€ (`_validate_symbol`)

### 2. ä»£ç é£æ ¼

#### æ–‡æ¡£å­—ç¬¦ä¸²
```python
def get_kdata(self, symbol: str, freq: str = "D", 
              start_date: str = None, end_date: str = None,
              count: int = None) -> pd.DataFrame:
    """
    è·å–Kçº¿æ•°æ®
    
    Args:
        symbol: è‚¡ç¥¨ä»£ç  (ä¾‹å¦‚: "000001.SZ")
        freq: æ•°æ®é¢‘ç‡ ("1m", "5m", "15m", "30m", "60m", "D", "W", "M")
        start_date: å¼€å§‹æ—¥æœŸ (æ ¼å¼: "YYYY-MM-DD")
        end_date: ç»“æŸæ—¥æœŸ (æ ¼å¼: "YYYY-MM-DD")
        count: æ•°æ®æ¡æ•° (ä¸æ—¥æœŸå‚æ•°äº’æ–¥)
    
    Returns:
        pd.DataFrame: Kçº¿æ•°æ®ï¼ŒåŒ…å«åˆ—ï¼š
            - datetime: æ—¶é—´æˆ³
            - open: å¼€ç›˜ä»·
            - high: æœ€é«˜ä»·
            - low: æœ€ä½ä»·
            - close: æ”¶ç›˜ä»·
            - volume: æˆäº¤é‡
    
    Raises:
        PluginConnectionError: è¿æ¥å¤±è´¥
        PluginDataQualityError: æ•°æ®è´¨é‡ä¸è¾¾æ ‡
        ValueError: å‚æ•°é”™è¯¯
    """
```

#### ç±»å‹æ³¨è§£
```python
from typing import Dict, List, Optional, Union, Any
import pandas as pd

def process_data(self, raw_data: List[Dict[str, Any]], 
                 validate: bool = True) -> pd.DataFrame:
    """å¤„ç†åŸå§‹æ•°æ®å¹¶è¿”å›æ ‡å‡†åŒ–DataFrame"""
```

#### é”™è¯¯å¤„ç†
```python
def _internal_get_kdata(self, symbol: str, **kwargs) -> pd.DataFrame:
    """è·å–Kçº¿æ•°æ®çš„å†…éƒ¨å®ç°"""
    try:
        # å‚æ•°éªŒè¯
        if not symbol:
            raise ValueError("è‚¡ç¥¨ä»£ç ä¸èƒ½ä¸ºç©º")
        
        # APIè°ƒç”¨
        response = self._make_api_request("/kdata", {"symbol": symbol, **kwargs})
        
        # æ•°æ®è½¬æ¢
        df = self._convert_to_dataframe(response.json())
        
        # æ•°æ®éªŒè¯
        if df.empty:
            raise PluginDataQualityError(f"æœªè·å–åˆ°{symbol}çš„Kçº¿æ•°æ®")
        
        return df
        
    except requests.RequestException as e:
        self.logger.error(f"APIè¯·æ±‚å¤±è´¥: {e}")
        raise PluginConnectionError(f"è·å–Kçº¿æ•°æ®å¤±è´¥: {e}")
    except Exception as e:
        self.logger.error(f"å¤„ç†Kçº¿æ•°æ®æ—¶å‘ç”Ÿå¼‚å¸¸: {e}")
        raise
```

### 3. æ•°æ®æ ¼å¼è§„èŒƒ

#### Kçº¿æ•°æ®æ ¼å¼
```python
# è¿”å›çš„DataFrameå¿…é¡»åŒ…å«ä»¥ä¸‹åˆ—
kdata_columns = {
    'datetime': 'datetime64[ns]',  # æ—¶é—´æˆ³
    'open': 'float64',             # å¼€ç›˜ä»·
    'high': 'float64',             # æœ€é«˜ä»·
    'low': 'float64',              # æœ€ä½ä»·
    'close': 'float64',            # æ”¶ç›˜ä»·
    'volume': 'int64'              # æˆäº¤é‡
}

# å¯é€‰åˆ—
optional_columns = {
    'amount': 'float64',           # æˆäº¤é¢
    'turnover': 'float64',         # æ¢æ‰‹ç‡
    'pre_close': 'float64'         # å‰æ”¶ç›˜ä»·
}
```

#### èµ„äº§åˆ—è¡¨æ ¼å¼
```python
# èµ„äº§åˆ—è¡¨çš„æ¯ä¸ªå…ƒç´ å¿…é¡»åŒ…å«
asset_required_fields = {
    'symbol': str,      # è‚¡ç¥¨ä»£ç  (ä¾‹å¦‚: "000001.SZ")
    'name': str,        # è‚¡ç¥¨åç§° (ä¾‹å¦‚: "å¹³å®‰é“¶è¡Œ")
    'market': str,      # å¸‚åœºä»£ç  (ä¾‹å¦‚: "SZ")
    'asset_type': str   # èµ„äº§ç±»å‹ (ä¾‹å¦‚: "STOCK")
}

# å¯é€‰å­—æ®µ
asset_optional_fields = {
    'industry': str,    # è¡Œä¸š
    'sector': str,      # æ¿å—
    'listing_date': str, # ä¸Šå¸‚æ—¥æœŸ
    'market_cap': float  # å¸‚å€¼
}
```

#### å®æ—¶è¡Œæƒ…æ ¼å¼
```python
# å®æ—¶è¡Œæƒ…çš„æ¯ä¸ªå…ƒç´ å¿…é¡»åŒ…å«
quote_required_fields = {
    'symbol': str,      # è‚¡ç¥¨ä»£ç 
    'price': float,     # å½“å‰ä»·æ ¼
    'timestamp': str    # æ—¶é—´æˆ³
}

# æ¨èå­—æ®µ
quote_recommended_fields = {
    'change': float,        # æ¶¨è·Œé¢
    'change_pct': float,    # æ¶¨è·Œå¹…(%)
    'volume': int,          # æˆäº¤é‡
    'amount': float,        # æˆäº¤é¢
    'open': float,          # å¼€ç›˜ä»·
    'high': float,          # æœ€é«˜ä»·
    'low': float,           # æœ€ä½ä»·
    'pre_close': float      # å‰æ”¶ç›˜ä»·
}
```

---

## ğŸ”§ é«˜çº§åŠŸèƒ½

### 1. ç¼“å­˜æœºåˆ¶

```python
from functools import lru_cache
from datetime import datetime, timedelta

class YourDataSourcePlugin(StandardDataSourcePlugin):
    
    def __init__(self):
        super().__init__()
        self._cache_expire_time = timedelta(minutes=5)
        self._cache = {}
    
    def _get_from_cache(self, cache_key: str):
        """ä»ç¼“å­˜è·å–æ•°æ®"""
        if cache_key in self._cache:
            data, timestamp = self._cache[cache_key]
            if datetime.now() - timestamp < self._cache_expire_time:
                return data
            else:
                del self._cache[cache_key]
        return None
    
    def _save_to_cache(self, cache_key: str, data):
        """ä¿å­˜æ•°æ®åˆ°ç¼“å­˜"""
        self._cache[cache_key] = (data, datetime.now())
    
    def _internal_get_kdata(self, symbol: str, **kwargs) -> pd.DataFrame:
        # ç”Ÿæˆç¼“å­˜é”®
        cache_key = f"kdata_{symbol}_{kwargs.get('freq', 'D')}_{kwargs.get('start_date', '')}_{kwargs.get('end_date', '')}"
        
        # å°è¯•ä»ç¼“å­˜è·å–
        cached_data = self._get_from_cache(cache_key)
        if cached_data is not None:
            self.logger.debug(f"ä»ç¼“å­˜è·å–Kçº¿æ•°æ®: {symbol}")
            return cached_data
        
        # è·å–æ–°æ•°æ®
        data = self._fetch_kdata_from_api(symbol, **kwargs)
        
        # ä¿å­˜åˆ°ç¼“å­˜
        self._save_to_cache(cache_key, data)
        
        return data
```

### 2. é‡è¯•æœºåˆ¶

```python
import time
from functools import wraps

def retry_on_failure(max_retries: int = 3, delay: float = 1.0, backoff: float = 2.0):
    """é‡è¯•è£…é¥°å™¨"""
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            retries = 0
            current_delay = delay
            
            while retries < max_retries:
                try:
                    return func(*args, **kwargs)
                except Exception as e:
                    retries += 1
                    if retries >= max_retries:
                        raise
                    
                    # è®°å½•é‡è¯•æ—¥å¿—
                    logger.warning(f"å‡½æ•° {func.__name__} æ‰§è¡Œå¤±è´¥ï¼Œ{current_delay:.1f}ç§’åè¿›è¡Œç¬¬{retries}æ¬¡é‡è¯•: {e}")
                    time.sleep(current_delay)
                    current_delay *= backoff
            
            return None
        return wrapper
    return decorator

class YourDataSourcePlugin(StandardDataSourcePlugin):
    
    @retry_on_failure(max_retries=3, delay=1.0, backoff=2.0)
    def _make_api_request(self, endpoint: str, params: Dict = None):
        """å¸¦é‡è¯•çš„APIè¯·æ±‚"""
        response = requests.get(
            f"{self.config.api_endpoint}{endpoint}",
            params=params,
            timeout=self.config.timeout
        )
        response.raise_for_status()
        return response
```

### 3. å¼‚æ­¥æ”¯æŒ

```python
import asyncio
import aiohttp
from concurrent.futures import ThreadPoolExecutor

class AsyncYourDataSourcePlugin(StandardDataSourcePlugin):
    
    def __init__(self):
        super().__init__()
        self._session = None
        self._executor = ThreadPoolExecutor(max_workers=4)
    
    async def _async_connect(self, **kwargs) -> bool:
        """å¼‚æ­¥è¿æ¥"""
        try:
            self._session = aiohttp.ClientSession(
                timeout=aiohttp.ClientTimeout(total=self.config.timeout)
            )
            # æµ‹è¯•è¿æ¥
            async with self._session.get(f"{self.config.api_endpoint}/health") as response:
                return response.status == 200
        except Exception as e:
            self.logger.error(f"å¼‚æ­¥è¿æ¥å¤±è´¥: {e}")
            return False
    
    async def _async_get_kdata(self, symbol: str, **kwargs) -> pd.DataFrame:
        """å¼‚æ­¥è·å–Kçº¿æ•°æ®"""
        if not self._session:
            raise PluginConnectionError("æœªå»ºç«‹å¼‚æ­¥è¿æ¥")
        
        try:
            params = {"symbol": symbol, **kwargs}
            async with self._session.get(f"{self.config.api_endpoint}/kdata", params=params) as response:
                response.raise_for_status()
                data = await response.json()
                return self._convert_to_dataframe(data)
        except Exception as e:
            self.logger.error(f"å¼‚æ­¥è·å–Kçº¿æ•°æ®å¤±è´¥: {e}")
            raise
    
    def _internal_get_kdata(self, symbol: str, **kwargs) -> pd.DataFrame:
        """åŒæ­¥æ¥å£çš„å¼‚æ­¥å®ç°"""
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        try:
            return loop.run_until_complete(self._async_get_kdata(symbol, **kwargs))
        finally:
            loop.close()
```

### 4. æ•°æ®è´¨é‡éªŒè¯

```python
class DataQualityValidator:
    """æ•°æ®è´¨é‡éªŒè¯å™¨"""
    
    @staticmethod
    def validate_kdata(df: pd.DataFrame, symbol: str) -> Dict[str, Any]:
        """éªŒè¯Kçº¿æ•°æ®è´¨é‡"""
        validation_result = {
            "is_valid": True,
            "quality_score": 1.0,
            "issues": [],
            "metrics": {}
        }
        
        # æ£€æŸ¥å¿…éœ€åˆ—
        required_columns = ['datetime', 'open', 'high', 'low', 'close', 'volume']
        missing_columns = [col for col in required_columns if col not in df.columns]
        if missing_columns:
            validation_result["is_valid"] = False
            validation_result["issues"].append(f"ç¼ºå°‘å¿…éœ€åˆ—: {missing_columns}")
        
        # æ£€æŸ¥æ•°æ®å®Œæ•´æ€§
        if not df.empty:
            null_count = df.isnull().sum().sum()
            total_cells = df.shape[0] * df.shape[1]
            completeness = 1.0 - (null_count / total_cells)
            validation_result["metrics"]["completeness"] = completeness
            
            if completeness < 0.95:
                validation_result["quality_score"] *= 0.8
                validation_result["issues"].append(f"æ•°æ®å®Œæ•´æ€§ä¸è¶³: {completeness:.2%}")
        
        # æ£€æŸ¥æ•°æ®é€»è¾‘æ€§
        if 'open' in df.columns and 'high' in df.columns and 'low' in df.columns and 'close' in df.columns:
            # æ£€æŸ¥ high >= max(open, close) å’Œ low <= min(open, close)
            invalid_high = (df['high'] < df[['open', 'close']].max(axis=1)).sum()
            invalid_low = (df['low'] > df[['open', 'close']].min(axis=1)).sum()
            
            if invalid_high > 0 or invalid_low > 0:
                validation_result["quality_score"] *= 0.9
                validation_result["issues"].append(f"å­˜åœ¨é€»è¾‘é”™è¯¯: high={invalid_high}, low={invalid_low}")
        
        # æ£€æŸ¥å¼‚å¸¸å€¼
        numeric_columns = df.select_dtypes(include=['number']).columns
        for col in numeric_columns:
            if col in df.columns:
                Q1 = df[col].quantile(0.25)
                Q3 = df[col].quantile(0.75)
                IQR = Q3 - Q1
                outliers = df[(df[col] < Q1 - 1.5 * IQR) | (df[col] > Q3 + 1.5 * IQR)]
                
                if len(outliers) > 0.1 * len(df):  # è¶…è¿‡10%ä¸ºå¼‚å¸¸å€¼
                    validation_result["quality_score"] *= 0.95
                    validation_result["issues"].append(f"åˆ— {col} å­˜åœ¨å¤§é‡å¼‚å¸¸å€¼: {len(outliers)}/{len(df)}")
        
        # æœ€ç»ˆè´¨é‡åˆ¤æ–­
        if validation_result["quality_score"] < 0.8:
            validation_result["is_valid"] = False
        
        return validation_result

class YourDataSourcePlugin(StandardDataSourcePlugin):
    
    def _validate_data_quality(self, data: Any) -> float:
        """é‡å†™æ•°æ®è´¨é‡éªŒè¯"""
        if isinstance(data, pd.DataFrame):
            validation_result = DataQualityValidator.validate_kdata(data, "")
            
            # è®°å½•éªŒè¯è¯¦æƒ…
            if not validation_result["is_valid"]:
                self.logger.warning(f"æ•°æ®è´¨é‡éªŒè¯å¤±è´¥: {validation_result['issues']}")
            
            return validation_result["quality_score"]
        
        return super()._validate_data_quality(data)
```

---

## ğŸ§ª æµ‹è¯•æŒ‡å—

### 1. å•å…ƒæµ‹è¯•

```python
import unittest
import pandas as pd
from unittest.mock import Mock, patch
from your_provider_plugin import YourDataSourcePlugin

class TestYourDataSourcePlugin(unittest.TestCase):
    
    def setUp(self):
        """æµ‹è¯•åˆå§‹åŒ–"""
        self.plugin = YourDataSourcePlugin()
    
    def test_plugin_info(self):
        """æµ‹è¯•æ’ä»¶ä¿¡æ¯"""
        info = self.plugin.plugin_info
        self.assertEqual(info.id, "your_provider")
        self.assertEqual(info.name, "Your Data Provider")
        self.assertIn("STOCK", [t.value for t in info.supported_asset_types])
    
    def test_connect(self):
        """æµ‹è¯•è¿æ¥åŠŸèƒ½"""
        with patch.object(self.plugin, '_internal_connect', return_value=True):
            result = self.plugin.connect()
            self.assertTrue(result)
            self.assertTrue(self.plugin.is_connected())
    
    def test_get_kdata(self):
        """æµ‹è¯•Kçº¿æ•°æ®è·å–"""
        # æ¨¡æ‹Ÿæ•°æ®
        mock_data = pd.DataFrame({
            'datetime': pd.date_range('2024-01-01', periods=5),
            'open': [10.0, 10.1, 10.2, 10.3, 10.4],
            'high': [10.2, 10.3, 10.4, 10.5, 10.6],
            'low': [9.8, 9.9, 10.0, 10.1, 10.2],
            'close': [10.1, 10.2, 10.3, 10.4, 10.5],
            'volume': [1000, 1100, 1200, 1300, 1400]
        })
        
        with patch.object(self.plugin, '_internal_get_kdata', return_value=mock_data):
            self.plugin._is_connected = True
            result = self.plugin.get_kdata("000001.SZ", freq="D")
            
            self.assertIsInstance(result, pd.DataFrame)
            self.assertEqual(len(result), 5)
            self.assertIn('datetime', result.columns)
            self.assertIn('close', result.columns)
    
    def test_data_quality_validation(self):
        """æµ‹è¯•æ•°æ®è´¨é‡éªŒè¯"""
        # æµ‹è¯•ç©ºæ•°æ®
        empty_df = pd.DataFrame()
        quality_score = self.plugin._validate_data_quality(empty_df)
        self.assertEqual(quality_score, 0.0)
        
        # æµ‹è¯•æ­£å¸¸æ•°æ®
        normal_df = pd.DataFrame({
            'datetime': pd.date_range('2024-01-01', periods=3),
            'open': [10.0, 10.1, 10.2],
            'high': [10.2, 10.3, 10.4],
            'low': [9.8, 9.9, 10.0],
            'close': [10.1, 10.2, 10.3],
            'volume': [1000, 1100, 1200]
        })
        quality_score = self.plugin._validate_data_quality(normal_df)
        self.assertGreater(quality_score, 0.8)
    
    def test_error_handling(self):
        """æµ‹è¯•é”™è¯¯å¤„ç†"""
        with patch.object(self.plugin, '_internal_get_kdata', side_effect=Exception("API Error")):
            self.plugin._is_connected = True
            
            with self.assertRaises(Exception):
                self.plugin.get_kdata("000001.SZ")
    
    def tearDown(self):
        """æµ‹è¯•æ¸…ç†"""
        if self.plugin.is_connected():
            self.plugin.disconnect()

if __name__ == '__main__':
    unittest.main()
```

### 2. é›†æˆæµ‹è¯•

```python
import unittest
from core.services.uni_plugin_data_manager import UniPluginDataManager
from core.plugin_manager import PluginManager

class TestPluginIntegration(unittest.TestCase):
    
    def setUp(self):
        """é›†æˆæµ‹è¯•åˆå§‹åŒ–"""
        self.plugin_manager = PluginManager()
        self.data_manager = UniPluginDataManager(
            self.plugin_manager, None, None
        )
    
    def test_plugin_registration(self):
        """æµ‹è¯•æ’ä»¶æ³¨å†Œ"""
        # æ³¨å†Œæ’ä»¶
        registration_results = self.data_manager.plugin_center.discover_and_register_plugins()
        
        # éªŒè¯æ³¨å†Œç»“æœ
        self.assertIn("your_provider", registration_results)
        self.assertEqual(registration_results["your_provider"], "success")
    
    def test_data_retrieval_flow(self):
        """æµ‹è¯•å®Œæ•´çš„æ•°æ®è·å–æµç¨‹"""
        # è·å–è‚¡ç¥¨åˆ—è¡¨
        stock_list = self.data_manager.get_stock_list(market="SZ")
        self.assertIsInstance(stock_list, list)
        
        # è·å–Kçº¿æ•°æ®
        if stock_list:
            symbol = stock_list[0]['symbol']
            kdata = self.data_manager.get_kdata(symbol, freq="D", count=30)
            self.assertIsInstance(kdata, pd.DataFrame)
```

### 3. æ€§èƒ½æµ‹è¯•

```python
import time
import unittest
from concurrent.futures import ThreadPoolExecutor, as_completed

class TestPluginPerformance(unittest.TestCase):
    
    def setUp(self):
        self.plugin = YourDataSourcePlugin()
        self.plugin.connect()
    
    def test_response_time(self):
        """æµ‹è¯•å“åº”æ—¶é—´"""
        start_time = time.time()
        result = self.plugin.get_kdata("000001.SZ", freq="D", count=100)
        end_time = time.time()
        
        response_time = end_time - start_time
        self.assertLess(response_time, 5.0, "å“åº”æ—¶é—´åº”å°äº5ç§’")
    
    def test_concurrent_requests(self):
        """æµ‹è¯•å¹¶å‘è¯·æ±‚"""
        symbols = ["000001.SZ", "000002.SZ", "000003.SZ"]
        
        def get_data(symbol):
            return self.plugin.get_kdata(symbol, freq="D", count=50)
        
        start_time = time.time()
        with ThreadPoolExecutor(max_workers=3) as executor:
            futures = [executor.submit(get_data, symbol) for symbol in symbols]
            results = [future.result() for future in as_completed(futures)]
        end_time = time.time()
        
        # éªŒè¯æ‰€æœ‰è¯·æ±‚éƒ½æˆåŠŸ
        self.assertEqual(len(results), 3)
        for result in results:
            self.assertIsInstance(result, pd.DataFrame)
        
        # éªŒè¯å¹¶å‘æ€§èƒ½
        total_time = end_time - start_time
        self.assertLess(total_time, 10.0, "å¹¶å‘è¯·æ±‚æ€»æ—¶é—´åº”å°äº10ç§’")
    
    def test_memory_usage(self):
        """æµ‹è¯•å†…å­˜ä½¿ç”¨"""
        import psutil
        import os
        
        process = psutil.Process(os.getpid())
        initial_memory = process.memory_info().rss
        
        # æ‰§è¡Œå¤§é‡æ•°æ®è¯·æ±‚
        for i in range(100):
            self.plugin.get_kdata(f"00000{i%10+1}.SZ", freq="D", count=10)
        
        final_memory = process.memory_info().rss
        memory_increase = final_memory - initial_memory
        
        # å†…å­˜å¢é•¿åº”è¯¥åˆç†ï¼ˆè¿™é‡Œè®¾ç½®ä¸º100MBé™åˆ¶ï¼‰
        self.assertLess(memory_increase, 100 * 1024 * 1024, "å†…å­˜å¢é•¿åº”æ§åˆ¶åœ¨100MBä»¥å†…")
```

---

## ğŸ“š æœ€ä½³å®è·µ

### 1. æ€§èƒ½ä¼˜åŒ–

#### ç¼“å­˜ç­–ç•¥
```python
# å®ç°æ™ºèƒ½ç¼“å­˜
class SmartCache:
    def __init__(self, ttl_minutes: int = 5):
        self.cache = {}
        self.ttl = timedelta(minutes=ttl_minutes)
    
    def get(self, key: str, default=None):
        if key in self.cache:
            value, timestamp = self.cache[key]
            if datetime.now() - timestamp < self.ttl:
                return value
            else:
                del self.cache[key]
        return default
    
    def set(self, key: str, value):
        self.cache[key] = (value, datetime.now())
        
        # é™åˆ¶ç¼“å­˜å¤§å°
        if len(self.cache) > 1000:
            oldest_key = min(self.cache.keys(), 
                           key=lambda k: self.cache[k][1])
            del self.cache[oldest_key]
```

#### è¿æ¥æ± ç®¡ç†
```python
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry

class ConnectionPoolMixin:
    def _setup_session(self):
        """è®¾ç½®ä¼šè¯å’Œè¿æ¥æ± """
        self.session = requests.Session()
        
        # é…ç½®é‡è¯•ç­–ç•¥
        retry_strategy = Retry(
            total=3,
            backoff_factor=1,
            status_forcelist=[429, 500, 502, 503, 504],
        )
        
        adapter = HTTPAdapter(
            pool_connections=20,
            pool_maxsize=20,
            max_retries=retry_strategy
        )
        
        self.session.mount("http://", adapter)
        self.session.mount("https://", adapter)
```

### 2. é”™è¯¯å¤„ç†ç­–ç•¥

```python
class PluginErrorHandler:
    """æ’ä»¶é”™è¯¯å¤„ç†å™¨"""
    
    @staticmethod
    def handle_api_error(response):
        """å¤„ç†APIé”™è¯¯"""
        if response.status_code == 401:
            raise PluginConnectionError("APIè®¤è¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥å¯†é’¥")
        elif response.status_code == 403:
            raise PluginConnectionError("APIè®¿é—®è¢«æ‹’ç»ï¼Œè¯·æ£€æŸ¥æƒé™")
        elif response.status_code == 429:
            raise PluginConnectionError("APIè¯·æ±‚é¢‘ç‡è¿‡é«˜ï¼Œè¯·ç¨åé‡è¯•")
        elif response.status_code >= 500:
            raise PluginConnectionError(f"æœåŠ¡å™¨é”™è¯¯: {response.status_code}")
        else:
            response.raise_for_status()
    
    @staticmethod
    def handle_data_error(data, symbol: str):
        """å¤„ç†æ•°æ®é”™è¯¯"""
        if data is None:
            raise PluginDataQualityError(f"æœªè·å–åˆ°{symbol}çš„æ•°æ®")
        
        if isinstance(data, pd.DataFrame) and data.empty:
            raise PluginDataQualityError(f"{symbol}çš„æ•°æ®ä¸ºç©º")
        
        if isinstance(data, list) and len(data) == 0:
            raise PluginDataQualityError(f"{symbol}çš„æ•°æ®åˆ—è¡¨ä¸ºç©º")
```

### 3. é…ç½®ç®¡ç†

```python
class ConfigManager:
    """é…ç½®ç®¡ç†å™¨"""
    
    def __init__(self, config_path: str = "config.json"):
        self.config_path = config_path
        self.config = self._load_config()
    
    def _load_config(self) -> Dict[str, Any]:
        """åŠ è½½é…ç½®"""
        try:
            with open(self.config_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except FileNotFoundError:
            return self._get_default_config()
    
    def _get_default_config(self) -> Dict[str, Any]:
        """è·å–é»˜è®¤é…ç½®"""
        return {
            "api_endpoint": "",
            "api_key": "",
            "timeout": 30,
            "retry_count": 3,
            "enable_cache": True,
            "cache_ttl": 300
        }
    
    def save_config(self) -> None:
        """ä¿å­˜é…ç½®"""
        with open(self.config_path, 'w', encoding='utf-8') as f:
            json.dump(self.config, f, indent=2, ensure_ascii=False)
    
    def get(self, key: str, default=None):
        """è·å–é…ç½®é¡¹"""
        return self.config.get(key, default)
    
    def set(self, key: str, value):
        """è®¾ç½®é…ç½®é¡¹"""
        self.config[key] = value
        self.save_config()
```

### 4. æ—¥å¿—è®°å½•

```python
import logging
from loguru import logger

class PluginLogger:
    """æ’ä»¶æ—¥å¿—å™¨"""
    
    def __init__(self, plugin_id: str):
        self.plugin_id = plugin_id
        self.logger = logger.bind(plugin=plugin_id)
        
    def info(self, message: str, **kwargs):
        """è®°å½•ä¿¡æ¯æ—¥å¿—"""
        self.logger.info(f"[{self.plugin_id}] {message}", **kwargs)
    
    def warning(self, message: str, **kwargs):
        """è®°å½•è­¦å‘Šæ—¥å¿—"""
        self.logger.warning(f"[{self.plugin_id}] {message}", **kwargs)
    
    def error(self, message: str, **kwargs):
        """è®°å½•é”™è¯¯æ—¥å¿—"""
        self.logger.error(f"[{self.plugin_id}] {message}", **kwargs)
    
    def debug(self, message: str, **kwargs):
        """è®°å½•è°ƒè¯•æ—¥å¿—"""
        self.logger.debug(f"[{self.plugin_id}] {message}", **kwargs)
    
    def performance(self, operation: str, duration: float, **kwargs):
        """è®°å½•æ€§èƒ½æ—¥å¿—"""
        self.logger.info(
            f"[{self.plugin_id}] æ€§èƒ½: {operation} è€—æ—¶ {duration:.3f}s",
            **kwargs
        )
```

---

## ğŸ” è°ƒè¯•å’Œæ•…éšœæ’é™¤

### 1. å¸¸è§é—®é¢˜

#### è¿æ¥é—®é¢˜
```python
# é—®é¢˜ï¼šè¿æ¥è¶…æ—¶
# è§£å†³ï¼šå¢åŠ è¶…æ—¶æ—¶é—´ï¼Œæ£€æŸ¥ç½‘ç»œè¿æ¥
config.timeout = 60  # å¢åŠ åˆ°60ç§’

# é—®é¢˜ï¼šè®¤è¯å¤±è´¥
# è§£å†³ï¼šæ£€æŸ¥APIå¯†é’¥æ˜¯å¦æ­£ç¡®
def _verify_api_key(self):
    try:
        response = requests.get(
            f"{self.config.api_endpoint}/auth/verify",
            headers={"Authorization": f"Bearer {self.config.api_key}"}
        )
        return response.status_code == 200
    except:
        return False
```

#### æ•°æ®è´¨é‡é—®é¢˜
```python
# é—®é¢˜ï¼šæ•°æ®åŒ…å«å¼‚å¸¸å€¼
# è§£å†³ï¼šæ·»åŠ æ•°æ®æ¸…æ´—é€»è¾‘
def _clean_data(self, df: pd.DataFrame) -> pd.DataFrame:
    """æ¸…æ´—æ•°æ®"""
    # ç§»é™¤å¼‚å¸¸å€¼
    numeric_columns = df.select_dtypes(include=['number']).columns
    for col in numeric_columns:
        Q1 = df[col].quantile(0.25)
        Q3 = df[col].quantile(0.75)
        IQR = Q3 - Q1
        
        # ä½¿ç”¨IQRæ–¹æ³•ç§»é™¤å¼‚å¸¸å€¼
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR
        df = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]
    
    return df
```

### 2. è°ƒè¯•å·¥å…·

```python
class PluginDebugger:
    """æ’ä»¶è°ƒè¯•å™¨"""
    
    def __init__(self, plugin):
        self.plugin = plugin
        self.debug_info = {}
    
    def trace_method_calls(self, method_name: str):
        """è¿½è¸ªæ–¹æ³•è°ƒç”¨"""
        original_method = getattr(self.plugin, method_name)
        
        def wrapper(*args, **kwargs):
            start_time = time.time()
            self.debug_info[f"{method_name}_calls"] = self.debug_info.get(f"{method_name}_calls", 0) + 1
            
            try:
                result = original_method(*args, **kwargs)
                duration = time.time() - start_time
                self.debug_info[f"{method_name}_total_time"] = self.debug_info.get(f"{method_name}_total_time", 0) + duration
                return result
            except Exception as e:
                self.debug_info[f"{method_name}_errors"] = self.debug_info.get(f"{method_name}_errors", 0) + 1
                raise
        
        setattr(self.plugin, method_name, wrapper)
    
    def get_debug_report(self) -> Dict[str, Any]:
        """è·å–è°ƒè¯•æŠ¥å‘Š"""
        return {
            "plugin_id": self.plugin.plugin_id,
            "connection_status": self.plugin.is_connected(),
            "stats": self.plugin.get_stats(),
            "debug_info": self.debug_info,
            "timestamp": datetime.now()
        }
```

---

## ğŸ“ æäº¤å’Œå‘å¸ƒ

### 1. ä»£ç æ£€æŸ¥æ¸…å•

- [ ] å®ç°äº†æ‰€æœ‰å¿…éœ€çš„æŠ½è±¡æ–¹æ³•
- [ ] æ·»åŠ äº†å®Œæ•´çš„æ–‡æ¡£å­—ç¬¦ä¸²
- [ ] åŒ…å«äº†å•å…ƒæµ‹è¯•å’Œé›†æˆæµ‹è¯•
- [ ] é€šè¿‡äº†æ€§èƒ½æµ‹è¯•
- [ ] å®ç°äº†é€‚å½“çš„é”™è¯¯å¤„ç†
- [ ] é…ç½®äº†åˆç†çš„æ—¥å¿—è®°å½•
- [ ] éµå¾ªäº†ä»£ç é£æ ¼è§„èŒƒ
- [ ] å®Œæˆäº†æ•°æ®è´¨é‡éªŒè¯

### 2. æµ‹è¯•æ£€æŸ¥æ¸…å•

- [ ] å•å…ƒæµ‹è¯•è¦†ç›–ç‡ > 80%
- [ ] é›†æˆæµ‹è¯•é€šè¿‡
- [ ] æ€§èƒ½æµ‹è¯•è¾¾æ ‡
- [ ] é”™è¯¯å¤„ç†æµ‹è¯•å®Œæ•´
- [ ] è¾¹ç•Œæ¡ä»¶æµ‹è¯•
- [ ] å¹¶å‘å®‰å…¨æ€§æµ‹è¯•

### 3. æ–‡æ¡£æ£€æŸ¥æ¸…å•

- [ ] README.md æ–‡ä»¶å®Œæ•´
- [ ] APIæ–‡æ¡£é½å…¨
- [ ] é…ç½®è¯´æ˜æ¸…æ¥š
- [ ] ç¤ºä¾‹ä»£ç å¯è¿è¡Œ
- [ ] æ•…éšœæ’é™¤æŒ‡å—

### 4. å‘å¸ƒæµç¨‹

1. **ä»£ç å®¡æŸ¥**: æäº¤Pull Requestè¿›è¡Œä»£ç å®¡æŸ¥
2. **è‡ªåŠ¨åŒ–æµ‹è¯•**: ç¡®ä¿æ‰€æœ‰CI/CDæµ‹è¯•é€šè¿‡
3. **æ€§èƒ½è¯„ä¼°**: è¿è¡Œæ€§èƒ½åŸºå‡†æµ‹è¯•
4. **å®‰å…¨æ£€æŸ¥**: è¿›è¡Œå®‰å…¨æ¼æ´æ‰«æ
5. **ç”¨æˆ·æµ‹è¯•**: é‚€è¯·ç”¨æˆ·è¿›è¡ŒBetaæµ‹è¯•
6. **æ–‡æ¡£æ›´æ–°**: æ›´æ–°ç›¸å…³æ–‡æ¡£
7. **ç‰ˆæœ¬å‘å¸ƒ**: åˆ›å»ºreleaseç‰ˆæœ¬
8. **ç›‘æ§éƒ¨ç½²**: ç›‘æ§æ’ä»¶åœ¨ç”Ÿäº§ç¯å¢ƒçš„è¡¨ç°

---

## ğŸ“ æ”¯æŒå’Œç¤¾åŒº

### è·å–å¸®åŠ©
- **GitHub Issues**: æŠ¥å‘Šbugå’ŒåŠŸèƒ½è¯·æ±‚
- **è®¨è®ºåŒº**: å‚ä¸æŠ€æœ¯è®¨è®ºå’Œç»éªŒåˆ†äº«
- **æ–‡æ¡£Wiki**: æŸ¥çœ‹è¯¦ç»†çš„æŠ€æœ¯æ–‡æ¡£

### è´¡çŒ®æŒ‡å—
- éµå¾ªä»£ç é£æ ¼è§„èŒƒ
- æäº¤å‰è¿è¡Œå®Œæ•´æµ‹è¯•å¥—ä»¶
- ç¼–å†™æ¸…æ™°çš„æäº¤ä¿¡æ¯
- å‚ä¸ä»£ç å®¡æŸ¥

### è”ç³»ä¿¡æ¯
- **é‚®ç®±**: factorweave-quant@example.com
- **å¾®ä¿¡ç¾¤**: æ‰«æäºŒç»´ç åŠ å…¥æŠ€æœ¯äº¤æµç¾¤

---

**æ–‡æ¡£ç‰ˆæœ¬**: 2.0  
**æœ€åæ›´æ–°**: 2024-09-17  
**ç»´æŠ¤å›¢é˜Ÿ**: FactorWeave-Quantå¼€å‘å›¢é˜Ÿ
