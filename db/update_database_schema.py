#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ•°æ®åº“æ¶æ„æ›´æ–°è„šæœ¬

æ›´æ–°ç°æœ‰æ•°æ®åº“ä»¥æ”¯æŒå®Œæ•´çš„FactorWeave-QuantåŠŸèƒ½
"""

import sqlite3
import duckdb
import json
import os
import logging
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Any, Optional

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


class DatabaseSchemaUpdater:
    """æ•°æ®åº“æ¶æ„æ›´æ–°å™¨"""

    def __init__(self):
        self.db_dir = Path(__file__).parent
        self.sqlite_db_path = self.db_dir / "hikyuu_system.db"
        self.factorweave_db_path = self.db_dir / "factorweave_system.db"
        self.duckdb_analytics_path = self.db_dir / "factorweave_analytics.duckdb"

    def update_all_databases(self):
        """æ›´æ–°æ‰€æœ‰æ•°æ®åº“"""
        logger.info("ğŸ”„ å¼€å§‹æ›´æ–°FactorWeave-Quantæ•°æ®åº“æ¶æ„")

        try:
            # 1. æ›´æ–°SQLiteæ•°æ®åº“
            self.update_sqlite_databases()

            # 2. æ›´æ–°DuckDBåˆ†ææ•°æ®åº“
            self.update_duckdb_database()

            # 3. æ’å…¥åˆå§‹æ•°æ®
            self.insert_initial_data()

            # 4. éªŒè¯æ›´æ–°ç»“æœ
            self.verify_update_results()

            logger.info("âœ… æ•°æ®åº“æ¶æ„æ›´æ–°å®Œæˆ")
            return True

        except Exception as e:
            logger.error(f"âŒ æ•°æ®åº“æ›´æ–°å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False

    def update_sqlite_databases(self):
        """æ›´æ–°SQLiteæ•°æ®åº“"""
        logger.info("ğŸ“Š æ›´æ–°SQLiteæ•°æ®åº“æ¶æ„...")

        # ç¡®ä¿æ•°æ®åº“æ–‡ä»¶å­˜åœ¨
        if not self.sqlite_db_path.exists():
            logger.info("  åˆ›å»ºæ–°çš„SQLiteæ•°æ®åº“...")
            self._create_sqlite_database()
        else:
            logger.info("  æ›´æ–°ç°æœ‰SQLiteæ•°æ®åº“...")
            self._update_existing_sqlite_database()

        # ç¡®ä¿FactorWeaveç³»ç»Ÿæ•°æ®åº“å­˜åœ¨
        if not self.factorweave_db_path.exists():
            logger.info("  åˆ›å»ºFactorWeaveç³»ç»Ÿæ•°æ®åº“...")
            self._create_factorweave_database()

    def _create_sqlite_database(self):
        """åˆ›å»ºæ–°çš„SQLiteæ•°æ®åº“"""
        with sqlite3.connect(self.sqlite_db_path) as conn:
            cursor = conn.cursor()

            # æ‰§è¡Œå®Œæ•´çš„è¡¨åˆ›å»º
            self._create_all_sqlite_tables(cursor)
            conn.commit()

    def _update_existing_sqlite_database(self):
        """æ›´æ–°ç°æœ‰SQLiteæ•°æ®åº“"""
        with sqlite3.connect(self.sqlite_db_path) as conn:
            cursor = conn.cursor()

            # è·å–ç°æœ‰è¡¨åˆ—è¡¨
            cursor.execute("SELECT name FROM sqlite_master WHERE type='table'")
            existing_tables = {row[0] for row in cursor.fetchall()}

            # éœ€è¦çš„è¡¨å®šä¹‰
            required_tables = {
                'config': self._get_config_table_sql(),
                'data_source': self._get_data_source_table_sql(),
                'user_favorites': self._get_user_favorites_table_sql(),
                'industry': self._get_industry_table_sql(),
                'market': self._get_market_table_sql(),
                'stock': self._get_stock_table_sql(),
                'concept': self._get_concept_table_sql(),
                'indicator': self._get_indicator_table_sql(),
                'user_log': self._get_user_log_table_sql(),
                'history': self._get_history_table_sql(),
                'indicator_combination': self._get_indicator_combination_table_sql(),
                'themes': self._get_themes_table_sql(),
                'pattern_types': self._get_pattern_types_table_sql(),
                'pattern_history': self._get_pattern_history_table_sql(),
                'plugins': self._get_plugins_table_sql(),
                'ai_prediction_config': self._get_ai_prediction_config_table_sql(),
                'ai_config_history': self._get_ai_config_history_table_sql(),
                'duckdb_config_profiles': self._get_duckdb_config_profiles_table_sql(),
                'duckdb_config_history': self._get_duckdb_config_history_table_sql(),
                'data_source_plugin_configs': self._get_data_source_plugin_configs_table_sql(),
                'data_source_routing_configs': self._get_data_source_routing_configs_table_sql(),
                'strategies': self._get_strategies_table_sql(),
                'strategy_parameters': self._get_strategy_parameters_table_sql(),
            }

            # åˆ›å»ºç¼ºå¤±çš„è¡¨
            for table_name, table_sql in required_tables.items():
                if table_name not in existing_tables:
                    logger.info(f"    åˆ›å»ºè¡¨: {table_name}")
                    cursor.execute(table_sql)
                else:
                    logger.info(f"    è¡¨å·²å­˜åœ¨: {table_name}")
                    # è¿™é‡Œå¯ä»¥æ·»åŠ åˆ—æ›´æ–°é€»è¾‘
                    self._update_table_columns(cursor, table_name)

            conn.commit()

    def _create_factorweave_database(self):
        """åˆ›å»ºFactorWeaveç³»ç»Ÿæ•°æ®åº“"""
        with sqlite3.connect(self.factorweave_db_path) as conn:
            cursor = conn.cursor()

            # FactorWeaveç‰¹æœ‰çš„ç³»ç»Ÿé…ç½®è¡¨
            cursor.execute('''
            CREATE TABLE IF NOT EXISTS factorweave_config (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                module TEXT NOT NULL,
                config_key TEXT NOT NULL,
                config_value TEXT NOT NULL,
                config_type TEXT DEFAULT 'string',
                description TEXT,
                is_encrypted BOOLEAN DEFAULT 0,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                UNIQUE(module, config_key)
            )''')

            # ç³»ç»Ÿç›‘æ§é…ç½®è¡¨
            cursor.execute('''
            CREATE TABLE IF NOT EXISTS system_monitor_config (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                monitor_type TEXT NOT NULL,
                config_data TEXT NOT NULL,
                is_active BOOLEAN DEFAULT 1,
                check_interval INTEGER DEFAULT 60,
                alert_threshold TEXT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )''')

            conn.commit()

    def update_duckdb_database(self):
        """æ›´æ–°DuckDBåˆ†ææ•°æ®åº“"""
        logger.info("ğŸ“ˆ æ›´æ–°DuckDBåˆ†ææ•°æ®åº“...")

        conn = duckdb.connect(str(self.duckdb_analytics_path))

        try:
            # è·å–ç°æœ‰è¡¨
            existing_tables = conn.execute(
                "SELECT table_name FROM information_schema.tables WHERE table_schema = 'main'"
            ).fetchall()
            existing_table_names = {row[0] for row in existing_tables}

            logger.info(f"  ç°æœ‰è¡¨: {existing_table_names}")

            # åˆ›å»ºç¼ºå¤±çš„åºåˆ—
            sequences = [
                'strategy_execution_results_seq',
                'indicator_calculation_results_seq',
                'pattern_recognition_results_seq',
                'backtest_metrics_history_seq',
                'backtest_alerts_history_seq',
                'performance_metrics_seq',
                'optimization_logs_seq',
                'analysis_cache_seq'
            ]

            for seq_name in sequences:
                try:
                    conn.execute(f"CREATE SEQUENCE IF NOT EXISTS {seq_name}")
                except Exception as e:
                    logger.warning(f"åˆ›å»ºåºåˆ— {seq_name} å¤±è´¥: {e}")

            # éœ€è¦åˆ›å»ºçš„æ–°è¡¨ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
            new_tables = {
                'strategy_execution_results': '''
                    CREATE TABLE IF NOT EXISTS strategy_execution_results (
                        id INTEGER PRIMARY KEY DEFAULT nextval('strategy_execution_results_seq'),
                        strategy_name VARCHAR NOT NULL,
                        symbol VARCHAR NOT NULL,
                        execution_time TIMESTAMP NOT NULL,
                        signal_type VARCHAR NOT NULL,
                        price DOUBLE,
                        quantity INTEGER,
                        confidence DOUBLE,
                        reason TEXT,
                        metadata TEXT,
                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                    )
                '''
            }

            # åˆ›å»ºç¼ºå¤±çš„è¡¨
            for table_name, table_sql in new_tables.items():
                if table_name not in existing_table_names:
                    logger.info(f"    åˆ›å»ºè¡¨: {table_name}")
                    conn.execute(table_sql)
                else:
                    logger.info(f"    è¡¨å·²å­˜åœ¨: {table_name}")

            # æ›´æ–°ç°æœ‰è¡¨ç»“æ„ï¼ˆå¦‚æœéœ€è¦ï¼‰
            self._update_duckdb_table_structures(conn, existing_table_names)

            # åˆ›å»ºæˆ–æ›´æ–°ç´¢å¼•
            self._create_duckdb_indexes(conn)

            # æ£€æŸ¥ç°æœ‰æ•°æ®ï¼ˆç§»é™¤æ™ºèƒ½æ€§èƒ½æ´å¯Ÿæ£€æŸ¥ï¼‰
            logger.info("æ£€æŸ¥ç°æœ‰ç¼“å­˜æ•°æ®...")

            # æ’å…¥åŸºç¡€æµ‹è¯•æ•°æ®ï¼ˆç§»é™¤æ™ºèƒ½æ€§èƒ½æ´å¯Ÿæ•°æ®ï¼‰
            basic_test_data = [
                ("test_basic_analysis", "technical_analysis",
                 '{"indicators": {"RSI": 50.0, "MACD": 0.0}, "timestamp": "2024-08-21T20:00:00"}',
                 "2025-08-22 20:00:00", "2024-08-21 20:00:00"),
            ]

            for data in basic_test_data:
                conn.execute("""
                    INSERT OR IGNORE INTO analysis_cache 
                    (cache_key, cache_type, data, expires_at, created_at)
                    VALUES (?, ?, ?, ?, ?)
                """, data)

            conn.commit()
            logger.info("åŸºç¡€æµ‹è¯•æ•°æ®æ’å…¥å®Œæˆ")

            conn.commit()

        finally:
            conn.close()

    def _update_duckdb_table_structures(self, conn, existing_tables):
        """æ›´æ–°DuckDBè¡¨ç»“æ„"""

        # æ£€æŸ¥pattern_recognition_resultsè¡¨æ˜¯å¦éœ€è¦æ·»åŠ åˆ—
        if 'pattern_recognition_results' in existing_tables:
            try:
                # æ£€æŸ¥æ˜¯å¦æœ‰recognition_timeåˆ—
                columns = conn.execute("DESCRIBE pattern_recognition_results").fetchall()
                column_names = {col[0] for col in columns}

                if 'recognition_time' not in column_names and 'detection_time' in column_names:
                    logger.info("    pattern_recognition_resultsè¡¨ä½¿ç”¨detection_timeåˆ—ï¼Œæ— éœ€ä¿®æ”¹")

                # æ£€æŸ¥æ˜¯å¦ç¼ºå°‘å…¶ä»–å¿…è¦åˆ—
                required_columns = {
                    'pattern_type': 'VARCHAR',
                    'timeframe': 'VARCHAR',
                    'signal_type': 'VARCHAR',
                    'start_index': 'INTEGER',
                    'end_index': 'INTEGER',
                    'key_points': 'TEXT'
                }

                for col_name, col_type in required_columns.items():
                    if col_name not in column_names:
                        try:
                            conn.execute(f"ALTER TABLE pattern_recognition_results ADD COLUMN {col_name} {col_type}")
                            logger.info(f"      æ·»åŠ åˆ—: {col_name}")
                        except Exception as e:
                            logger.warning(f"      æ·»åŠ åˆ— {col_name} å¤±è´¥: {e}")

            except Exception as e:
                logger.warning(f"æ›´æ–°pattern_recognition_resultsè¡¨å¤±è´¥: {e}")

    def _create_duckdb_indexes(self, conn):
        """åˆ›å»ºDuckDBç´¢å¼•"""
        indexes = [
            "CREATE INDEX IF NOT EXISTS idx_strategy_execution_symbol ON strategy_execution_results(symbol)",
            "CREATE INDEX IF NOT EXISTS idx_strategy_execution_time ON strategy_execution_results(execution_time)",
            "CREATE INDEX IF NOT EXISTS idx_indicator_calculation_symbol ON indicator_calculation_results(symbol)",
            "CREATE INDEX IF NOT EXISTS idx_indicator_calculation_time ON indicator_calculation_results(calculation_time)",
            "CREATE INDEX IF NOT EXISTS idx_pattern_recognition_symbol ON pattern_recognition_results(symbol)",
            "CREATE INDEX IF NOT EXISTS idx_pattern_recognition_detection_time ON pattern_recognition_results(detection_time)",
            "CREATE INDEX IF NOT EXISTS idx_backtest_metrics_timestamp ON backtest_metrics_history(timestamp)",
            "CREATE INDEX IF NOT EXISTS idx_backtest_alerts_timestamp ON backtest_alerts_history(timestamp)",
            "CREATE INDEX IF NOT EXISTS idx_performance_metrics_pattern ON performance_metrics(pattern_name)",
            "CREATE INDEX IF NOT EXISTS idx_optimization_logs_session ON optimization_logs(optimization_session_id)",
            "CREATE INDEX IF NOT EXISTS idx_analysis_cache_type ON analysis_cache(cache_type)",
            "CREATE INDEX IF NOT EXISTS idx_analysis_cache_expires ON analysis_cache(expires_at)",
            "CREATE INDEX IF NOT EXISTS idx_analysis_cache_key ON analysis_cache(cache_key)",
        ]

        for index_sql in indexes:
            try:
                conn.execute(index_sql)
            except Exception as e:
                logger.warning(f"åˆ›å»ºç´¢å¼•å¤±è´¥: {e}")

    def insert_initial_data(self):
        """æ’å…¥åˆå§‹æ•°æ®"""
        logger.info("ğŸ“ æ’å…¥åˆå§‹æ•°æ®...")

        self._insert_sqlite_initial_data()
        self._insert_duckdb_initial_data()

    def _insert_sqlite_initial_data(self):
        """æ’å…¥SQLiteåˆå§‹æ•°æ®"""
        with sqlite3.connect(self.sqlite_db_path) as conn:
            cursor = conn.cursor()

            # æ’å…¥ç³»ç»Ÿé…ç½®ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
            config_data = [
                ('system.version', '2.0.0', 'FactorWeave-Quantç³»ç»Ÿç‰ˆæœ¬'),
                ('system.initialized', 'true', 'ç³»ç»Ÿæ˜¯å¦å·²åˆå§‹åŒ–'),
                ('system.theme', 'default', 'ç³»ç»Ÿé»˜è®¤ä¸»é¢˜'),
                ('database.sqlite_path', str(self.sqlite_db_path), 'SQLiteæ•°æ®åº“è·¯å¾„'),
                ('database.duckdb_path', str(self.duckdb_analytics_path), 'DuckDBæ•°æ®åº“è·¯å¾„'),
                ('ui.language', 'zh_CN', 'ç•Œé¢è¯­è¨€'),
                ('performance.enable_cache', 'true', 'å¯ç”¨ç¼“å­˜'),
            ]

            for key, value, desc in config_data:
                cursor.execute('''
                    INSERT OR IGNORE INTO config (key, value, description) 
                    VALUES (?, ?, ?)
                ''', (key, value, desc))

            # æ’å…¥å¸‚åœºæ•°æ®ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
            market_data = [
                ('SH', 'ä¸Šæµ·è¯åˆ¸äº¤æ˜“æ‰€', 'CN', 'Asia/Shanghai', '{}'),
                ('SZ', 'æ·±åœ³è¯åˆ¸äº¤æ˜“æ‰€', 'CN', 'Asia/Shanghai', '{}'),
                ('BJ', 'åŒ—äº¬è¯åˆ¸äº¤æ˜“æ‰€', 'CN', 'Asia/Shanghai', '{}'),
                ('HK', 'é¦™æ¸¯äº¤æ˜“æ‰€', 'HK', 'Asia/Hong_Kong', '{}'),
                ('US', 'ç¾å›½è‚¡å¸‚', 'US', 'America/New_York', '{}'),
            ]

            for code, name, region, timezone, extra in market_data:
                cursor.execute('''
                    INSERT OR IGNORE INTO market (code, name, region, timezone, extra) 
                    VALUES (?, ?, ?, ?, ?)
                ''', (code, name, region, timezone, extra))

            # æ’å…¥AIé¢„æµ‹é…ç½®ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
            current_time = datetime.now().isoformat()
            ai_config_data = [
                ('model.pattern.enabled', 'true', 'boolean', 'æ˜¯å¦å¯ç”¨å½¢æ€è¯†åˆ«æ¨¡å‹'),
                ('model.trend.enabled', 'true', 'boolean', 'æ˜¯å¦å¯ç”¨è¶‹åŠ¿é¢„æµ‹æ¨¡å‹'),
                ('prediction.confidence_threshold', '0.7', 'float', 'é¢„æµ‹ç½®ä¿¡åº¦é˜ˆå€¼'),
            ]

            for key, value, config_type, desc in ai_config_data:
                cursor.execute('''
                    INSERT OR IGNORE INTO ai_prediction_config 
                    (config_key, config_value, config_type, description, created_at, updated_at) 
                    VALUES (?, ?, ?, ?, ?, ?)
                ''', (key, value, config_type, desc, current_time, current_time))

            # æ’å…¥é»˜è®¤DuckDBé…ç½®ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
            cursor.execute('''
                INSERT OR IGNORE INTO duckdb_config_profiles 
                (profile_name, description, workload_type, is_active, is_default)
                VALUES ('default', 'é»˜è®¤OLAPé…ç½®', 'OLAP', 1, 1)
            ''')

            conn.commit()

    def _insert_duckdb_initial_data(self):
        """æ’å…¥DuckDBåˆå§‹æ•°æ®"""
        conn = duckdb.connect(str(self.duckdb_analytics_path))

        try:
            # æ’å…¥åŸºç¡€åˆ†æç¼“å­˜æ•°æ®ï¼ˆç§»é™¤æ™ºèƒ½æ€§èƒ½æ´å¯Ÿï¼‰
            basic_cache_data = [
                ("basic_analysis_1", "technical_analysis",
                 '{"indicators": {"RSI": 45.0, "MACD": -0.1}, "timestamp": "2024-08-21T21:45:00"}',
                 "2025-08-23 20:00:00", "2025-08-21 21:45:00"),
                ("basic_analysis_2", "market_sentiment",
                 '{"sentiment": "neutral", "score": 0.5, "timestamp": "2024-08-21T21:45:00"}',
                 "2025-08-23 20:00:00", "2025-08-21 21:45:00"),
            ]

            for data in basic_cache_data:
                try:
                    conn.execute("""
                        INSERT OR IGNORE INTO analysis_cache 
                        (cache_key, cache_type, data, expires_at, created_at)
                        VALUES (?, ?, ?, ?, ?)
                    """, data)
                except Exception as e:
                    logger.warning(f"æ’å…¥åŸºç¡€åˆ†ææ•°æ®å¤±è´¥: {e}")

            conn.commit()
            logger.info(f"  æ·»åŠ äº† {len(basic_cache_data)} æ¡åŸºç¡€åˆ†ææ•°æ®")

        finally:
            conn.close()

    def verify_update_results(self):
        """éªŒè¯æ›´æ–°ç»“æœ"""
        logger.info("ğŸ” éªŒè¯æ•°æ®åº“æ›´æ–°ç»“æœ...")

        # éªŒè¯SQLiteæ•°æ®åº“
        with sqlite3.connect(self.sqlite_db_path) as conn:
            cursor = conn.cursor()
            cursor.execute("SELECT COUNT(*) FROM sqlite_master WHERE type='table'")
            table_count = cursor.fetchone()[0]
            logger.info(f"  SQLiteæ•°æ®åº“è¡¨æ•°é‡: {table_count}")

        # éªŒè¯DuckDBæ•°æ®åº“
        conn = duckdb.connect(str(self.duckdb_analytics_path))
        try:
            result = conn.execute("SELECT COUNT(*) FROM information_schema.tables WHERE table_schema = 'main'").fetchone()
            table_count = result[0] if result else 0
            logger.info(f"  DuckDBæ•°æ®åº“è¡¨æ•°é‡: {table_count}")

            # æ£€æŸ¥åŸºç¡€åˆ†ææ•°æ®
            cache_count = conn.execute("SELECT COUNT(*) FROM analysis_cache").fetchone()[0]
            logger.info(f"  åˆ†æç¼“å­˜æ•°æ®: {cache_count} æ¡")
        finally:
            conn.close()

    def _update_table_columns(self, cursor, table_name):
        """æ›´æ–°è¡¨åˆ—ï¼ˆå¦‚æœéœ€è¦ï¼‰"""
        # è¿™é‡Œå¯ä»¥æ·»åŠ å…·ä½“çš„åˆ—æ›´æ–°é€»è¾‘
        pass

    # è¡¨å®šä¹‰æ–¹æ³•
    def _get_config_table_sql(self):
        return '''
        CREATE TABLE IF NOT EXISTS config (
            key TEXT PRIMARY KEY,
            value TEXT,
            description TEXT,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )'''

    def _get_data_source_table_sql(self):
        return '''
        CREATE TABLE IF NOT EXISTS data_source (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            name TEXT UNIQUE NOT NULL,
            type TEXT NOT NULL,
            config TEXT,
            is_active INTEGER DEFAULT 0,
            priority INTEGER DEFAULT 50,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )'''

    def _get_user_favorites_table_sql(self):
        return '''
        CREATE TABLE IF NOT EXISTS user_favorites (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            user_id TEXT NOT NULL,
            fav_type TEXT NOT NULL,
            fav_key TEXT NOT NULL,
            fav_value TEXT,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )'''

    def _get_industry_table_sql(self):
        return '''
        CREATE TABLE IF NOT EXISTS industry (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            name TEXT NOT NULL,
            parent_id INTEGER,
            level INTEGER DEFAULT 1,
            code TEXT UNIQUE,
            extra TEXT,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )'''

    def _get_market_table_sql(self):
        return '''
        CREATE TABLE IF NOT EXISTS market (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            name TEXT NOT NULL,
            code TEXT UNIQUE NOT NULL,
            region TEXT DEFAULT 'CN',
            timezone TEXT DEFAULT 'Asia/Shanghai',
            extra TEXT,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )'''

    def _get_stock_table_sql(self):
        return '''
        CREATE TABLE IF NOT EXISTS stock (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            code TEXT UNIQUE NOT NULL,
            name TEXT NOT NULL,
            market_code TEXT NOT NULL,
            type TEXT DEFAULT 'stock',
            valid INTEGER DEFAULT 1,
            start_date TEXT,
            end_date TEXT,
            industry_id INTEGER,
            extra TEXT,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )'''

    def _get_concept_table_sql(self):
        return '''
        CREATE TABLE IF NOT EXISTS concept (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            code TEXT UNIQUE NOT NULL,
            name TEXT NOT NULL,
            description TEXT,
            extra TEXT,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )'''

    def _get_indicator_table_sql(self):
        return '''
        CREATE TABLE IF NOT EXISTS indicator (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            name TEXT NOT NULL,
            category TEXT NOT NULL,
            params TEXT,
            description TEXT,
            formula TEXT,
            extra TEXT,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )'''

    def _get_user_log_table_sql(self):
        return '''
        CREATE TABLE IF NOT EXISTS user_log (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            user_id TEXT NOT NULL,
            action TEXT NOT NULL,
            detail TEXT,
            ip_address TEXT,
            user_agent TEXT,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )'''

    def _get_history_table_sql(self):
        return '''
        CREATE TABLE IF NOT EXISTS history (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            user_id TEXT NOT NULL,
            record_type TEXT NOT NULL,
            record_key TEXT NOT NULL,
            record_value TEXT,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )'''

    def _get_indicator_combination_table_sql(self):
        return '''
        CREATE TABLE IF NOT EXISTS indicator_combination (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            name TEXT NOT NULL,
            user_id TEXT NOT NULL,
            indicators TEXT NOT NULL,
            description TEXT,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            extra TEXT
        )'''

    def _get_themes_table_sql(self):
        return '''
        CREATE TABLE IF NOT EXISTS themes (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            name TEXT UNIQUE NOT NULL,
            type TEXT NOT NULL,
            content TEXT NOT NULL,
            origin TEXT DEFAULT 'system',
            created_at TEXT DEFAULT CURRENT_TIMESTAMP,
            updated_at TEXT DEFAULT CURRENT_TIMESTAMP
        )'''

    def _get_pattern_types_table_sql(self):
        return '''
        CREATE TABLE IF NOT EXISTS pattern_types (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            name TEXT UNIQUE NOT NULL,
            english_name TEXT,
            category TEXT NOT NULL,
            signal_type TEXT,
            description TEXT,
            min_periods INTEGER DEFAULT 5,
            max_periods INTEGER DEFAULT 60,
            confidence_threshold REAL DEFAULT 0.5,
            algorithm_code TEXT,
            parameters TEXT,
            success_rate REAL DEFAULT 0.7,
            risk_level TEXT DEFAULT 'medium',
            is_active INTEGER DEFAULT 1,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )'''

    def _get_pattern_history_table_sql(self):
        return '''
        CREATE TABLE IF NOT EXISTS pattern_history (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            pattern_type TEXT NOT NULL,
            stock_code TEXT NOT NULL,
            signal_type TEXT NOT NULL,
            confidence REAL NOT NULL,
            trigger_date TEXT NOT NULL,
            trigger_price REAL NOT NULL,
            result_date TEXT,
            result_price REAL,
            return_rate REAL,
            is_successful INTEGER,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )'''

    def _get_plugins_table_sql(self):
        return '''
        CREATE TABLE IF NOT EXISTS plugins (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            name TEXT UNIQUE NOT NULL,
            version TEXT NOT NULL,
            plugin_type TEXT NOT NULL,
            category TEXT,
            description TEXT,
            author TEXT,
            status TEXT DEFAULT 'disabled',
            config TEXT,
            metadata TEXT,
            file_path TEXT,
            class_name TEXT,
            priority INTEGER DEFAULT 50,
            last_enabled_at TIMESTAMP,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )'''

    def _get_ai_prediction_config_table_sql(self):
        return '''
        CREATE TABLE IF NOT EXISTS ai_prediction_config (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            config_key TEXT UNIQUE NOT NULL,
            config_value TEXT NOT NULL,
            config_type TEXT NOT NULL DEFAULT 'json',
            description TEXT,
            created_at TEXT NOT NULL,
            updated_at TEXT NOT NULL,
            is_active BOOLEAN DEFAULT 1
        )'''

    def _get_ai_config_history_table_sql(self):
        return '''
        CREATE TABLE IF NOT EXISTS ai_config_history (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            config_key TEXT NOT NULL,
            old_value TEXT,
            new_value TEXT,
            changed_by TEXT DEFAULT 'system',
            changed_at TEXT NOT NULL
        )'''

    def _get_duckdb_config_profiles_table_sql(self):
        return '''
        CREATE TABLE IF NOT EXISTS duckdb_config_profiles (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            profile_name TEXT UNIQUE NOT NULL,
            description TEXT,
            workload_type TEXT DEFAULT 'OLAP',
            memory_limit TEXT DEFAULT '4.0GB',
            max_memory TEXT DEFAULT '4.4GB',
            buffer_pool_size TEXT DEFAULT '1GB',
            temp_memory_limit TEXT DEFAULT '2GB',
            threads INTEGER DEFAULT 4,
            io_threads INTEGER DEFAULT 2,
            parallel_tasks INTEGER DEFAULT 4,
            worker_threads INTEGER DEFAULT 3,
            checkpoint_threshold TEXT DEFAULT '512MB',
            wal_autocheckpoint INTEGER DEFAULT 5000,
            temp_directory_size TEXT DEFAULT '20GB',
            enable_fsync BOOLEAN DEFAULT 1,
            enable_mmap BOOLEAN DEFAULT 1,
            enable_optimizer BOOLEAN DEFAULT 1,
            enable_profiling BOOLEAN DEFAULT 0,
            enable_progress_bar BOOLEAN DEFAULT 1,
            enable_object_cache BOOLEAN DEFAULT 1,
            max_expression_depth INTEGER DEFAULT 1000,
            enable_external_access BOOLEAN DEFAULT 1,
            enable_httpfs BOOLEAN DEFAULT 1,
            enable_parquet_statistics BOOLEAN DEFAULT 1,
            preserve_insertion_order BOOLEAN DEFAULT 0,
            enable_verification BOOLEAN DEFAULT 0,
            force_parallelism BOOLEAN DEFAULT 1,
            enable_join_order_optimizer BOOLEAN DEFAULT 1,
            enable_unnest_rewriter BOOLEAN DEFAULT 1,
            enable_object_cache_map BOOLEAN DEFAULT 1,
            enable_auto_analyze BOOLEAN DEFAULT 1,
            auto_analyze_sample_size INTEGER DEFAULT 100000,
            enable_compression BOOLEAN DEFAULT 1,
            compression_level INTEGER DEFAULT 6,
            http_timeout INTEGER DEFAULT 30000,
            http_retries INTEGER DEFAULT 3,
            is_active BOOLEAN DEFAULT 0,
            is_default BOOLEAN DEFAULT 0,
            created_at TEXT DEFAULT CURRENT_TIMESTAMP,
            updated_at TEXT DEFAULT CURRENT_TIMESTAMP,
            created_by TEXT DEFAULT 'system'
        )'''

    def _get_duckdb_config_history_table_sql(self):
        return '''
        CREATE TABLE IF NOT EXISTS duckdb_config_history (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            profile_id INTEGER NOT NULL,
            action TEXT NOT NULL,
            old_config TEXT,
            new_config TEXT,
            changed_by TEXT DEFAULT 'system',
            changed_at TEXT DEFAULT CURRENT_TIMESTAMP
        )'''

    def _get_data_source_plugin_configs_table_sql(self):
        return '''
        CREATE TABLE IF NOT EXISTS data_source_plugin_configs (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            plugin_id TEXT NOT NULL,
            config_data TEXT NOT NULL,
            priority INTEGER DEFAULT 50,
            weight REAL DEFAULT 1.0,
            enabled BOOLEAN DEFAULT 1,
            health_check_interval INTEGER DEFAULT 30,
            timeout_seconds INTEGER DEFAULT 30,
            retry_count INTEGER DEFAULT 3,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            UNIQUE(plugin_id)
        )'''

    def _get_data_source_routing_configs_table_sql(self):
        return '''
        CREATE TABLE IF NOT EXISTS data_source_routing_configs (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            asset_type TEXT NOT NULL,
            plugin_priorities TEXT NOT NULL,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            UNIQUE(asset_type)
        )'''

    def _get_strategies_table_sql(self):
        return '''
        CREATE TABLE IF NOT EXISTS strategies (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            name TEXT UNIQUE NOT NULL,
            strategy_type TEXT NOT NULL,
            version TEXT NOT NULL DEFAULT '1.0.0',
            author TEXT DEFAULT '',
            description TEXT DEFAULT '',
            category TEXT DEFAULT '',
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            is_active BOOLEAN DEFAULT 1,
            metadata TEXT DEFAULT '{}',
            class_path TEXT NOT NULL
        )'''

    def _get_strategy_parameters_table_sql(self):
        return '''
        CREATE TABLE IF NOT EXISTS strategy_parameters (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            strategy_id INTEGER NOT NULL,
            param_name TEXT NOT NULL,
            param_value TEXT NOT NULL,
            param_type TEXT NOT NULL,
            description TEXT DEFAULT '',
            min_value TEXT DEFAULT NULL,
            max_value TEXT DEFAULT NULL,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            UNIQUE(strategy_id, param_name)
        )'''

    def _create_all_sqlite_tables(self, cursor):
        """åˆ›å»ºæ‰€æœ‰SQLiteè¡¨"""
        table_methods = [
            self._get_config_table_sql,
            self._get_data_source_table_sql,
            self._get_user_favorites_table_sql,
            self._get_industry_table_sql,
            self._get_market_table_sql,
            self._get_stock_table_sql,
            self._get_concept_table_sql,
            self._get_indicator_table_sql,
            self._get_user_log_table_sql,
            self._get_history_table_sql,
            self._get_indicator_combination_table_sql,
            self._get_themes_table_sql,
            self._get_pattern_types_table_sql,
            self._get_pattern_history_table_sql,
            self._get_plugins_table_sql,
            self._get_ai_prediction_config_table_sql,
            self._get_ai_config_history_table_sql,
            self._get_duckdb_config_profiles_table_sql,
            self._get_duckdb_config_history_table_sql,
            self._get_data_source_plugin_configs_table_sql,
            self._get_data_source_routing_configs_table_sql,
            self._get_strategies_table_sql,
            self._get_strategy_parameters_table_sql,
        ]

        for method in table_methods:
            cursor.execute(method())


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("FactorWeave-Quant æ•°æ®åº“æ¶æ„æ›´æ–°ç³»ç»Ÿ")
    print("=" * 60)

    updater = DatabaseSchemaUpdater()

    if updater.update_all_databases():
        print("\nğŸ‰ æ•°æ®åº“æ¶æ„æ›´æ–°æˆåŠŸï¼")
        print("\nğŸ“Š æ›´æ–°å†…å®¹:")
        print("  âœ… SQLiteç³»ç»Ÿæ•°æ®åº“æ¶æ„")
        print("  âœ… DuckDBåˆ†ææ•°æ®åº“æ¶æ„")
        print("  âœ… ç¼ºå¤±è¡¨å’Œåˆ—çš„åˆ›å»º")
        print("  âœ… åˆå§‹é…ç½®å’Œæ•°æ®")
        print("  âœ… æ€§èƒ½ä¼˜åŒ–ç´¢å¼•")

        return True
    else:
        print("\nâŒ æ•°æ®åº“æ¶æ„æ›´æ–°å¤±è´¥ï¼")
        return False


if __name__ == "__main__":
    success = main()
    exit(0 if success else 1)
