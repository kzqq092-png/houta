# 并行任务监控与诊断指南

## 新增的监控日志说明

### 任务级别日志（线程池整体）

```
📊 [并行模式] 开始导入: 20个股票，max_workers=4
📊 [任务队列] 已提交20个任务到线程池，等待执行...
📊 [线程池状态] 已提交所有任务，开始执行...
📊 [进度] 5/20 | 成功:4 失败:1 | 平均耗时:3.25s | 预计剩余:48.8s
📊 [并行完成] 总耗时:65.30秒 | 成功:18 失败:2
```

**关键指标：**
- `max_workers`: 线程池大小
- `平均耗时`: 每个股票的平均处理时间
- `预计剩余`: 根据平均耗时估算的剩余时间

---

### 单股票任务日志（每个线程）

#### 正常流程：
```
🔵 [开始] 600000 (1/20) | 线程:ThreadPoolExecutor-0_0
⏱️ [网络请求开始] 600000 | 线程:ThreadPoolExecutor-0_0
⏱️ [网络请求完成] 600000 | 耗时:2.35秒 | 线程:ThreadPoolExecutor-0_0
✅ [数据获取成功] 600000 | 条数:1250 | 耗时:2.35秒
⏱️ [数据库写入开始] 600000 | 线程:ThreadPoolExecutor-0_0
⏱️ [数据库写入完成] 600000 | 耗时:0.87秒 | 线程:ThreadPoolExecutor-0_0
🟢 [完成] 600000 | 总耗时:3.22秒 (网络:2.35s, 数据库:0.87s) | 线程:ThreadPoolExecutor-0_0
```

#### 异常情况：
```
❌ [数据为空] 600001 | 总耗时:2.10秒
🔴 [失败] 600002 | 总耗时:5.50秒 | 错误:连接超时 | 线程:ThreadPoolExecutor-0_1
⏰ [超时] 600003 执行超过300秒，future.result()超时
```

---

## 阻塞问题诊断

### 问题1：线程池卡住，没有新任务启动

**日志特征：**
```
📊 [并行模式] 开始导入: 20个股票，max_workers=4
📊 [任务队列] 已提交20个任务到线程池，等待执行...
📊 [线程池状态] 已提交所有任务，开始执行...
🔵 [开始] 600000 (1/20) | 线程:ThreadPoolExecutor-0_0
🔵 [开始] 600001 (2/20) | 线程:ThreadPoolExecutor-0_1
🔵 [开始] 600002 (3/20) | 线程:ThreadPoolExecutor-0_2
🔵 [开始] 600003 (4/20) | 线程:ThreadPoolExecutor-0_3
⏱️ [网络请求开始] 600000 | 线程:ThreadPoolExecutor-0_0
⏱️ [网络请求开始] 600001 | 线程:ThreadPoolExecutor-0_1
⏱️ [网络请求开始] 600002 | 线程:ThreadPoolExecutor-0_2
⏱️ [网络请求开始] 600003 | 线程:ThreadPoolExecutor-0_3

# ⚠️ 长时间没有新的日志 (超过3分钟)
# ⚠️ 没有 "网络请求完成" 日志
# ⚠️ 没有新的 "🔵 [开始]" 日志
```

**诊断结论：** 所有4个线程都卡在 `get_real_kdata` 网络请求中

**可能原因：**
1. 通达信服务器响应极慢或不响应
2. 网络连接问题（防火墙/代理）
3. `auto_patch_requests` 的超时配置过长（默认30秒）
4. pytdx客户端没有正确设置socket超时

**解决方案：**
1. **降低网络超时**：
   ```python
   # 在 auto_patch_requests.py 中
   AUTO_PATCH_CONFIG['timeout'] = 15  # 从30秒降到15秒
   ```

2. **为pytdx添加socket超时**：
   ```python
   # 在 tongdaxin_plugin.py 的 _ensure_connection 中
   self.api_client.set_timeout(15)  # 如果pytdx支持
   ```

3. **检查网络连接**：
   ```bash
   # 测试通达信服务器连通性
   ping 119.147.212.81
   telnet 119.147.212.81 7709
   ```

---

### 问题2：网络请求完成，但数据库写入卡住

**日志特征：**
```
⏱️ [网络请求完成] 600000 | 耗时:2.35秒 | 线程:ThreadPoolExecutor-0_0
✅ [数据获取成功] 600000 | 条数:1250 | 耗时:2.35秒
⏱️ [数据库写入开始] 600000 | 线程:ThreadPoolExecutor-0_0

# ⚠️ 长时间没有 "数据库写入完成" 日志
# ⚠️ 其他线程也卡在 "数据库写入开始"
```

**诊断结论：** 多个线程在 `_save_kdata_to_database` 中竞争DuckDB锁

**可能原因：**
1. DuckDB在多线程写入时序列化执行（锁竞争严重）
2. 数据库文件被其他进程锁定
3. 磁盘I/O性能瓶颈

**解决方案：**
1. **批量写入优化**：
   ```python
   # 收集多个股票的数据后批量插入
   # 改造 _save_kdata_to_database 支持批量模式
   ```

2. **减少并发写入线程**：
   ```python
   # 如果max_workers=4，且都在等数据库锁，实际并发度为1
   # 可以调整为：2个线程下载，1个线程专门写库
   ```

3. **检查数据库锁**：
   ```bash
   # Windows: 查看占用数据库文件的进程
   handle.exe "stock_a_data.duckdb"
   
   # 关闭其他可能占用数据库的进程
   # 例如：数据库管理工具、其他Python进程
   ```

---

### 问题3：单个任务耗时过长（超过300秒）

**日志特征：**
```
🔵 [开始] 600005 (5/20) | 线程:ThreadPoolExecutor-0_0
⏱️ [网络请求开始] 600005 | 线程:ThreadPoolExecutor-0_0
⏱️ [网络请求完成] 600005 | 耗时:180.50秒 | 线程:ThreadPoolExecutor-0_0
⏱️ [数据库写入开始] 600005 | 线程:ThreadPoolExecutor-0_0
⏰ [超时] 600005 执行超过300秒，future.result()超时
```

**诊断结论：** 单个股票的网络请求耗时过长（180秒），触发了future.result()的300秒总超时

**可能原因：**
1. 该股票的数据量特别大（历史数据很长）
2. 通达信服务器对该股票的响应特别慢
3. 分批获取逻辑中的某一批卡住

**解决方案：**
1. **针对性调整超时**：
   ```python
   # 根据数据量调整超时时间
   if total_count > 5000:
       timeout = 600  # 大数据量任务给更多时间
   else:
       timeout = 300
   
   import_result = future.result(timeout=timeout)
   ```

2. **检查分批获取是否正常**：
   - 查看日志中是否有 `[并发批次X]` 或 `[串行分批]` 相关日志
   - 确认每批800条是否都能正常返回

3. **跳过问题股票，继续执行**：
   ```python
   # future.result()超时后，线程会被释放（任务仍在后台运行）
   # 已有的except TimeoutError处理会标记为失败并继续
   ```

---

## 理想的日志流

### 正常并行执行（max_workers=4，20只股票）

```
00:00:00 📊 [并行模式] 开始导入: 20个股票，max_workers=4
00:00:00 📊 [任务队列] 已提交20个任务到线程池，等待执行...
00:00:00 📊 [线程池状态] 已提交所有任务，开始执行...

# 第1批（线程0-3同时启动）
00:00:00 🔵 [开始] 600000 (1/20) | 线程:ThreadPoolExecutor-0_0
00:00:00 🔵 [开始] 600001 (2/20) | 线程:ThreadPoolExecutor-0_1
00:00:00 🔵 [开始] 600002 (3/20) | 线程:ThreadPoolExecutor-0_2
00:00:00 🔵 [开始] 600003 (4/20) | 线程:ThreadPoolExecutor-0_3

# 网络请求（交错进行）
00:00:02 ⏱️ [网络请求完成] 600000 | 耗时:2.00秒 | 线程:ThreadPoolExecutor-0_0
00:00:02 ⏱️ [数据库写入开始] 600000 | 线程:ThreadPoolExecutor-0_0
00:00:03 ⏱️ [网络请求完成] 600001 | 耗时:2.50秒 | 线程:ThreadPoolExecutor-0_1
00:00:03 ⏱️ [数据库写入开始] 600001 | 线程:ThreadPoolExecutor-0_1
00:00:03 ⏱️ [数据库写入完成] 600000 | 耗时:0.80秒 | 线程:ThreadPoolExecutor-0_0
00:00:03 🟢 [完成] 600000 | 总耗时:3.20秒 (网络:2.00s, 数据库:0.80s)

# 线程0空闲，立即启动新任务
00:00:03 🔵 [开始] 600004 (5/20) | 线程:ThreadPoolExecutor-0_0
00:00:04 ⏱️ [网络请求完成] 600002 | 耗时:3.00秒 | 线程:ThreadPoolExecutor-0_2

# ... 依此类推，线程完成一个任务后立即启动下一个 ...

00:01:05 📊 [并行完成] 总耗时:65.30秒 | 成功:18 失败:2
```

**关键观察点：**
- ✅ 4个线程的 `🔵 [开始]` 日志时间戳应该**交错出现**，而不是只有前4个
- ✅ 每个线程完成后（`🟢 [完成]`），应该**立即**出现新的 `🔵 [开始]`
- ✅ `网络请求` 和 `数据库写入` 的耗时应该**合理**（网络<10秒，数据库<3秒）
- ✅ `📊 [进度]` 日志应该**持续出现**，不应该长时间停滞

---

## 快速诊断检查清单

### 1. 线程池是否正常工作？
- [ ] 是否看到 `📊 [并行模式]` 日志？
- [ ] 是否有4个（或max_workers个）`🔵 [开始]` 日志？
- [ ] 是否有超过4个的 `🔵 [开始]` 日志（说明线程复用成功）？

### 2. 网络请求是否阻塞？
- [ ] 每个 `⏱️ [网络请求开始]` 是否都有对应的 `⏱️ [网络请求完成]`？
- [ ] 网络耗时是否合理（<10秒）？
- [ ] 是否有大量超过30秒的网络请求？

### 3. 数据库写入是否阻塞？
- [ ] 每个 `⏱️ [数据库写入开始]` 是否都有对应的 `⏱️ [数据库写入完成]`？
- [ ] 数据库耗时是否合理（<3秒）？
- [ ] 是否多个线程同时卡在 `数据库写入开始`？

### 4. 异常情况？
- [ ] 是否有 `⏰ [超时]` 日志？（说明单个任务超过300秒）
- [ ] 是否有 `🔴 [失败]` 日志？（查看错误信息）
- [ ] 是否有 `❌ [数据为空]` 日志？（某些股票可能没有数据）

---

## 性能基准

### 单股票正常耗时
- **网络请求**：1-5秒（800条以内），5-15秒（800-5000条，分批）
- **数据库写入**：0.5-2秒（800条以内），2-5秒（大数据量）
- **总耗时**：2-7秒（单股票）

### 20只股票（max_workers=4）预期
- **理想情况**：60-100秒（平均3-5秒/股票）
- **网络慢**：100-150秒（平均5-7.5秒/股票）
- **数据库锁竞争**：150-200秒（实际并发度降低）

### 异常情况判断
- **单股票超过20秒**：网络或数据库异常
- **总时间超过5分钟（20只股票）**：严重阻塞，需诊断
- **线程利用率低**：ThreadPoolExecutor只有1-2个线程在工作（其他卡住）

---

## 日志文件位置

查看完整日志：
```
logs/hikyuu_YYYYMMDD.log
```

实时监控（Windows PowerShell）：
```powershell
Get-Content logs\hikyuu_YYYYMMDD.log -Wait | Select-String "🔵|🟢|⏱️|📊|🔴|❌|⏰"
```

实时监控（Linux/Mac）：
```bash
tail -f logs/hikyuu_YYYYMMDD.log | grep -E "🔵|🟢|⏱️|📊|🔴|❌|⏰"
```

---

## 总结

通过新增的详细日志，可以清晰地观察到：
1. **线程池的并行度**：是否所有max_workers个线程都在工作
2. **任务的流转**：线程完成后是否立即接手新任务
3. **阻塞点定位**：网络请求还是数据库写入
4. **性能瓶颈**：平均耗时、预计剩余时间

**建议操作流程：**
1. 启动任务，观察日志输出
2. 如果出现阻塞，记录最后几行日志的时间戳和内容
3. 根据本指南的"阻塞问题诊断"部分定位原因
4. 应用相应的解决方案
5. 重新测试验证

---

**文档版本：** v1.0  
**更新日期：** 2025-11-07  
**适用版本：** hikyuu-ui (master branch)

