#!/usr/bin/env python3
"""
å…¨é¢æ¶æ„ä¿®å¤è„šæœ¬

è§£å†³æ•´ä¸ªé¡¹ç›®ä¸­çš„é‡å¤åˆå§‹åŒ–é—®é¢˜ï¼š
1. å°†æ‰€æœ‰ç›´æ¥å®ä¾‹åŒ–æ”¹ä¸ºä½¿ç”¨å•ä¾‹è·å–æ–¹å¼
2. ç»Ÿä¸€æ•°æ®ç®¡ç†å™¨è®¿é—®æ¨¡å¼
3. æ¶ˆé™¤ç³»ç»Ÿçº§åˆ«çš„é‡å¤åˆå§‹åŒ–
"""

import os
import re
import shutil
from pathlib import Path
from typing import List, Dict


class ComprehensiveArchitectureFix:
    """å…¨é¢æ¶æ„ä¿®å¤å™¨"""

    def __init__(self):
        self.fixed_files = []
        self.backup_files = []
        self.patterns_fixed = 0

    def backup_file(self, file_path: str):
        """å¤‡ä»½æ–‡ä»¶"""
        if os.path.exists(file_path):
            backup_path = f"{file_path}.comprehensive_backup"
            shutil.copy2(file_path, backup_path)
            self.backup_files.append(backup_path)
            return True
        return False

    def fix_direct_instantiation(self, file_path: str) -> bool:
        """ä¿®å¤æ–‡ä»¶ä¸­çš„ç›´æ¥å®ä¾‹åŒ–"""
        if not os.path.exists(file_path):
            return False

        # è·³è¿‡å¤‡ä»½æ–‡ä»¶å’Œè„šæœ¬æ–‡ä»¶
        if any(x in file_path for x in ['.backup', '.py.', 'fix_', 'diagnose_', 'thorough_', 'precise_', 'comprehensive_']):
            return False

        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()

            original_content = content

            # 1. ä¿®å¤ UnifiedDataManager() ç›´æ¥å®ä¾‹åŒ–
            # æ›¿æ¢ä¸ºä½¿ç”¨ get_unified_data_manager()
            patterns = [
                # ç›´æ¥å®ä¾‹åŒ–æ¨¡å¼
                (r'(\s*)([a-zA-Z_]\w*\s*=\s*)?UnifiedDataManager\(\)',
                 r'\1\2get_unified_data_manager()'),

                # åœ¨å‚æ•°ä¸­çš„ç›´æ¥å®ä¾‹åŒ–
                (r'(\s*[\(,]\s*)UnifiedDataManager\(\)',
                 r'\1get_unified_data_manager()'),

                # èµ‹å€¼è¯­å¥ä¸­çš„ç›´æ¥å®ä¾‹åŒ–
                (r'(self\.[a-zA-Z_]\w*\s*=\s*)UnifiedDataManager\(\)',
                 r'\1get_unified_data_manager()'),
            ]

            for pattern, replacement in patterns:
                new_content = re.sub(pattern, replacement, content)
                if new_content != content:
                    content = new_content
                    self.patterns_fixed += 1

            # 2. ç¡®ä¿å¯¼å…¥äº† get_unified_data_manager
            if 'get_unified_data_manager()' in content:
                # æ£€æŸ¥æ˜¯å¦å·²æœ‰å¯¼å…¥
                if 'from core.services.unified_data_manager import' in content:
                    # å·²æœ‰å¯¼å…¥ï¼Œæ£€æŸ¥æ˜¯å¦åŒ…å«get_unified_data_manager
                    if 'get_unified_data_manager' not in content.split('def get_unified_data_manager')[0]:
                        # æ·»åŠ åˆ°ç°æœ‰å¯¼å…¥
                        content = re.sub(
                            r'(from core\.services\.unified_data_manager import [^\\n]*)',
                            r'\1, get_unified_data_manager',
                            content
                        )
                elif 'from core.services.unified_data_manager import UnifiedDataManager' in content:
                    # æ›¿æ¢å¯¼å…¥
                    content = re.sub(
                        r'from core\.services\.unified_data_manager import UnifiedDataManager',
                        r'from core.services.unified_data_manager import UnifiedDataManager, get_unified_data_manager',
                        content
                    )
                else:
                    # æ·»åŠ æ–°çš„å¯¼å…¥ï¼Œåœ¨å…¶ä»–core.serviceså¯¼å…¥é™„è¿‘
                    import_lines = content.split('\n')
                    insert_pos = 0
                    for i, line in enumerate(import_lines):
                        if 'from core.services' in line or 'import core.services' in line:
                            insert_pos = i + 1
                            break
                        elif line.strip() and not line.strip().startswith('#') and not line.strip().startswith('"""'):
                            insert_pos = i
                            break

                    if insert_pos > 0:
                        import_lines.insert(insert_pos, 'from core.services.unified_data_manager import get_unified_data_manager')
                        content = '\n'.join(import_lines)

            # 3. ä¿®å¤ UniPluginDataManager() ç›´æ¥å®ä¾‹åŒ–ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            content = re.sub(
                r'(\s*)([a-zA-Z_]\w*\s*=\s*)?UniPluginDataManager\(\)',
                r'\1# TODO: ä½¿ç”¨ä¾èµ–æ³¨å…¥è·å–UniPluginDataManagerå®ä¾‹\n\1\2None  # éœ€è¦ä»æœåŠ¡å®¹å™¨è·å–',
                content
            )

            # å¦‚æœæœ‰å˜åŒ–ï¼Œå†™å›æ–‡ä»¶
            if content != original_content:
                self.backup_file(file_path)
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.write(content)
                self.fixed_files.append(file_path)
                return True

        except Exception as e:
            print(f"âŒ ä¿®å¤æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
            return False

        return False

    def get_files_with_direct_instantiation(self) -> List[str]:
        """è·å–åŒ…å«ç›´æ¥å®ä¾‹åŒ–çš„æ–‡ä»¶åˆ—è¡¨"""
        files = []

        # è·å–æ‰€æœ‰Pythonæ–‡ä»¶
        for root, dirs, filenames in os.walk('.'):
            # è·³è¿‡ä¸€äº›ç›®å½•
            dirs[:] = [d for d in dirs if not d.startswith('.') and d not in ['__pycache__', 'logs', 'cache']]

            for filename in filenames:
                if filename.endswith('.py'):
                    filepath = os.path.join(root, filename)
                    # è·³è¿‡å¤‡ä»½æ–‡ä»¶å’Œè„šæœ¬æ–‡ä»¶
                    if any(x in filepath for x in ['.backup', 'fix_', 'diagnose_', 'thorough_', 'precise_', 'comprehensive_']):
                        continue
                    files.append(filepath)

        return files

    def fix_all_files(self):
        """ä¿®å¤æ‰€æœ‰æ–‡ä»¶"""
        print("ğŸ” æ‰«æåŒ…å«ç›´æ¥å®ä¾‹åŒ–çš„æ–‡ä»¶...")

        files = self.get_files_with_direct_instantiation()
        print(f"ğŸ“ æ‰¾åˆ° {len(files)} ä¸ªPythonæ–‡ä»¶")

        fixed_count = 0
        for file_path in files:
            if self.fix_direct_instantiation(file_path):
                fixed_count += 1
                print(f"âœ… ä¿®å¤: {file_path}")

        return fixed_count

    def create_singleton_access_helper(self):
        """åˆ›å»ºå•ä¾‹è®¿é—®åŠ©æ‰‹"""
        helper_content = '''"""
å•ä¾‹è®¿é—®åŠ©æ‰‹æ¨¡å—

æä¾›ç»Ÿä¸€çš„æ•°æ®ç®¡ç†å™¨è®¿é—®æ–¹å¼ï¼Œç¡®ä¿æ•´ä¸ªç³»ç»Ÿä½¿ç”¨åŒä¸€ä¸ªå®ä¾‹
"""

from core.services.unified_data_manager import get_unified_data_manager
from core.containers import get_service_container

def get_data_manager():
    """
    è·å–ç»Ÿä¸€æ•°æ®ç®¡ç†å™¨å®ä¾‹
    
    Returns:
        UnifiedDataManager: ç»Ÿä¸€æ•°æ®ç®¡ç†å™¨å•ä¾‹å®ä¾‹
    """
    return get_unified_data_manager()

def get_plugin_manager():
    """
    è·å–æ’ä»¶ç®¡ç†å™¨å®ä¾‹
    
    Returns:
        PluginManager: æ’ä»¶ç®¡ç†å™¨å®ä¾‹
    """
    try:
        container = get_service_container()
        if container and container.is_registered('PluginManager'):
            return container.resolve('PluginManager')
    except Exception:
        pass
    return None

def get_service(service_type):
    """
    ä»æœåŠ¡å®¹å™¨è·å–æœåŠ¡å®ä¾‹
    
    Args:
        service_type: æœåŠ¡ç±»å‹
        
    Returns:
        æœåŠ¡å®ä¾‹æˆ–None
    """
    try:
        container = get_service_container()
        if container and container.is_registered(service_type):
            return container.resolve(service_type)
    except Exception:
        pass
    return None
'''

        with open('utils/singleton_helper.py', 'w', encoding='utf-8') as f:
            f.write(helper_content)

        print("âœ… åˆ›å»ºå•ä¾‹è®¿é—®åŠ©æ‰‹: utils/singleton_helper.py")


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹å…¨é¢æ¶æ„ä¿®å¤...")
    print("=" * 60)

    fixer = ComprehensiveArchitectureFix()

    try:
        # 1. ä¿®å¤æ‰€æœ‰æ–‡ä»¶ä¸­çš„ç›´æ¥å®ä¾‹åŒ–
        fixed_count = fixer.fix_all_files()

        # 2. åˆ›å»ºå•ä¾‹è®¿é—®åŠ©æ‰‹
        fixer.create_singleton_access_helper()

        print("\n" + "=" * 60)
        print("ğŸ‰ å…¨é¢æ¶æ„ä¿®å¤å®Œæˆï¼")
        print(f"\nğŸ“Š ä¿®å¤ç»Ÿè®¡:")
        print(f"  âœ… ä¿®å¤æ–‡ä»¶æ•°: {fixed_count}")
        print(f"  ğŸ”§ ä¿®å¤æ¨¡å¼æ•°: {fixer.patterns_fixed}")
        print(f"  ğŸ“¦ å¤‡ä»½æ–‡ä»¶æ•°: {len(fixer.backup_files)}")

        print(f"\nğŸ“‹ ä¿®å¤å†…å®¹:")
        print("âœ… æ‰€æœ‰ UnifiedDataManager() æ”¹ä¸º get_unified_data_manager()")
        print("âœ… æ·»åŠ äº†å¿…è¦çš„å¯¼å…¥è¯­å¥")
        print("âœ… å¤„ç†äº† UniPluginDataManager ç›´æ¥å®ä¾‹åŒ–")
        print("âœ… åˆ›å»ºäº†å•ä¾‹è®¿é—®åŠ©æ‰‹")

        print(f"\nâš ï¸  é‡è¦æç¤º:")
        print("1. æ‰€æœ‰åŸæ–‡ä»¶å·²å¤‡ä»½ä¸º .comprehensive_backup")
        print("2. è¯·é‡æ–°è¿è¡Œè¯Šæ–­å·¥å…·éªŒè¯ä¿®å¤æ•ˆæœ")
        print("3. å»ºè®®è¿›è¡Œå®Œæ•´çš„åŠŸèƒ½æµ‹è¯•")
        print("4. å¦‚æœ‰é—®é¢˜å¯å¿«é€Ÿæ¢å¤å¤‡ä»½æ–‡ä»¶")

        if fixer.fixed_files:
            print(f"\nğŸ“ ä¿®å¤çš„æ–‡ä»¶:")
            for file_path in fixer.fixed_files[:10]:  # æ˜¾ç¤ºå‰10ä¸ª
                print(f"     {file_path}")
            if len(fixer.fixed_files) > 10:
                print(f"     ... è¿˜æœ‰ {len(fixer.fixed_files) - 10} ä¸ªæ–‡ä»¶")

    except Exception as e:
        print(f"âŒ ä¿®å¤è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return False

    return True


if __name__ == "__main__":
    main()
