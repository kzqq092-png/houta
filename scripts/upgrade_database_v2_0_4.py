"""
æ•°æ®åº“å‡çº§è„šæœ¬ - V2.0.3 to V2.0.4
æ·»åŠ æ ‡å‡†é‡åŒ–è¡¨å­—æ®µï¼ˆ5ä¸ªæ–°å­—æ®µï¼‰

æ–°å¢å­—æ®µï¼š
1. adj_close - å¤æƒæ”¶ç›˜ä»·
2. adj_factor - å¤æƒå› å­
3. turnover_rate - æ¢æ‰‹ç‡
4. vwap - æˆäº¤é‡åŠ æƒå‡ä»·
5. data_source - æ•°æ®æ¥æº
"""
import sys
import duckdb
from pathlib import Path
from loguru import logger

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))


class DatabaseUpgrader:
    """æ•°æ®åº“å‡çº§å·¥å…·"""

    def __init__(self):
        self.upgraded_tables = []
        self.failed_tables = []

    def upgrade_database(self, db_path: str) -> bool:
        """å‡çº§å•ä¸ªæ•°æ®åº“"""
        try:
            if not Path(db_path).exists():
                logger.warning(f"æ•°æ®åº“ä¸å­˜åœ¨ï¼Œè·³è¿‡: {db_path}")
                return False

            logger.info(f"\n{'='*60}")
            logger.info(f"æ­£åœ¨å‡çº§æ•°æ®åº“: {db_path}")
            logger.info(f"{'='*60}")

            conn = duckdb.connect(db_path)

            # è·å–æ‰€æœ‰Kçº¿è¡¨
            tables = conn.execute("""
                SELECT table_name 
                FROM duckdb_tables() 
                WHERE table_name LIKE '%kline%'
            """).fetchall()

            if not tables:
                logger.warning("æœªå‘ç°Kçº¿è¡¨ï¼Œè·³è¿‡æ­¤æ•°æ®åº“")
                conn.close()
                return True

            logger.info(f"å‘ç° {len(tables)} ä¸ªKçº¿è¡¨éœ€è¦å‡çº§")

            for (table_name,) in tables:
                self._upgrade_table(conn, table_name)

            # éªŒè¯å‡çº§
            self._verify_upgrade(conn)

            conn.close()
            logger.success(f"âœ… æ•°æ®åº“ {db_path} å‡çº§å®Œæˆï¼")
            return True

        except Exception as e:
            logger.error(f"âŒ æ•°æ®åº“å‡çº§å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False

    def _upgrade_table(self, conn, table_name: str):
        """å‡çº§å•ä¸ªè¡¨"""
        try:
            logger.info(f"\næ­£åœ¨å‡çº§è¡¨: {table_name}")

            # æ£€æŸ¥å­—æ®µæ˜¯å¦å·²å­˜åœ¨
            existing_columns = self._get_table_columns(conn, table_name)

            # æ·»åŠ æ–°å­—æ®µ
            new_fields = {
                'adj_close': 'ALTER TABLE {} ADD COLUMN IF NOT EXISTS adj_close DOUBLE',
                'adj_factor': 'ALTER TABLE {} ADD COLUMN IF NOT EXISTS adj_factor DOUBLE DEFAULT 1.0',
                'turnover_rate': 'ALTER TABLE {} ADD COLUMN IF NOT EXISTS turnover_rate DOUBLE',
                'vwap': 'ALTER TABLE {} ADD COLUMN IF NOT EXISTS vwap DOUBLE',
                'data_source': "ALTER TABLE {} ADD COLUMN IF NOT EXISTS data_source VARCHAR DEFAULT 'unknown'"
            }

            added_fields = []
            for field_name, sql_template in new_fields.items():
                if field_name not in existing_columns:
                    sql = sql_template.format(table_name)
                    conn.execute(sql)
                    added_fields.append(field_name)
                    logger.debug(f"  âœ… æ·»åŠ å­—æ®µ: {field_name}")
                else:
                    logger.debug(f"  â­ï¸  å­—æ®µå·²å­˜åœ¨: {field_name}")

            if added_fields:
                # æ›´æ–°ç°æœ‰æ•°æ®çš„é»˜è®¤å€¼
                self._update_default_values(conn, table_name)
                logger.success(f"âœ… è¡¨ {table_name} å‡çº§æˆåŠŸï¼Œæ–°å¢ {len(added_fields)} ä¸ªå­—æ®µ")
                self.upgraded_tables.append(table_name)
            else:
                logger.info(f"â„¹ï¸  è¡¨ {table_name} å·²æ˜¯æœ€æ–°ç‰ˆæœ¬ï¼Œè·³è¿‡")

        except Exception as e:
            logger.error(f"âŒ è¡¨ {table_name} å‡çº§å¤±è´¥: {e}")
            self.failed_tables.append((table_name, str(e)))

    def _get_table_columns(self, conn, table_name: str) -> set:
        """è·å–è¡¨çš„æ‰€æœ‰åˆ—å"""
        try:
            result = conn.execute(f"""
                SELECT column_name 
                FROM duckdb_columns() 
                WHERE table_name = '{table_name}'
            """).fetchall()
            return {row[0] for row in result}
        except Exception as e:
            logger.error(f"è·å–è¡¨åˆ—åå¤±è´¥: {e}")
            return set()

    def _update_default_values(self, conn, table_name: str):
        """æ›´æ–°ç°æœ‰æ•°æ®çš„é»˜è®¤å€¼"""
        try:
            # æ£€æŸ¥è¡¨ä¸­æ˜¯å¦æœ‰æ•°æ®
            count = conn.execute(f"SELECT COUNT(*) FROM {table_name}").fetchone()[0]

            if count == 0:
                logger.debug("  è¡¨ä¸ºç©ºï¼Œè·³è¿‡é»˜è®¤å€¼æ›´æ–°")
                return

            logger.info(f"  æ­£åœ¨æ›´æ–° {count} æ¡è®°å½•çš„é»˜è®¤å€¼...")

            # æ›´æ–°adj_factorå’Œadj_close
            conn.execute(f"""
                UPDATE {table_name} 
                SET adj_factor = 1.0
                WHERE adj_factor IS NULL
            """)

            conn.execute(f"""
                UPDATE {table_name} 
                SET adj_close = close * adj_factor
                WHERE adj_close IS NULL AND close IS NOT NULL
            """)

            # æ›´æ–°vwap
            conn.execute(f"""
                UPDATE {table_name} 
                SET vwap = CASE 
                    WHEN volume > 0 THEN amount / volume 
                    ELSE NULL 
                END
                WHERE vwap IS NULL AND amount IS NOT NULL AND volume IS NOT NULL
            """)

            # æ›´æ–°data_source
            conn.execute(f"""
                UPDATE {table_name} 
                SET data_source = 'legacy'
                WHERE data_source = 'unknown' OR data_source IS NULL
            """)

            logger.debug("  âœ… é»˜è®¤å€¼æ›´æ–°å®Œæˆ")

        except Exception as e:
            logger.warning(f"  âš ï¸  é»˜è®¤å€¼æ›´æ–°å¤±è´¥: {e}")

    def _verify_upgrade(self, conn):
        """éªŒè¯å‡çº§ç»“æœ"""
        try:
            logger.info("\n" + "="*60)
            logger.info("å‡çº§éªŒè¯")
            logger.info("="*60)

            result = conn.execute("""
                SELECT 
                    table_name,
                    COUNT(*) as total_columns,
                    SUM(CASE WHEN column_name = 'adj_close' THEN 1 ELSE 0 END) as has_adj_close,
                    SUM(CASE WHEN column_name = 'adj_factor' THEN 1 ELSE 0 END) as has_adj_factor,
                    SUM(CASE WHEN column_name = 'turnover_rate' THEN 1 ELSE 0 END) as has_turnover_rate,
                    SUM(CASE WHEN column_name = 'vwap' THEN 1 ELSE 0 END) as has_vwap,
                    SUM(CASE WHEN column_name = 'data_source' THEN 1 ELSE 0 END) as has_data_source
                FROM duckdb_columns()
                WHERE table_name LIKE '%kline%'
                GROUP BY table_name
            """).fetchall()

            logger.info("\nå‡çº§åçš„è¡¨ç»“æ„ï¼š")
            for row in result:
                table_name, total_cols, has_adj_close, has_adj_factor, has_turnover_rate, has_vwap, has_data_source = row
                status = "âœ…" if all([has_adj_close, has_adj_factor, has_turnover_rate, has_vwap, has_data_source]) else "âš ï¸"
                logger.info(f"  {status} {table_name}: {total_cols}åˆ— (æ–°å­—æ®µ: {has_adj_close + has_adj_factor + has_turnover_rate + has_vwap + has_data_source}/5)")

        except Exception as e:
            logger.error(f"éªŒè¯å¤±è´¥: {e}")

    def print_summary(self):
        """æ‰“å°å‡çº§æ€»ç»“"""
        logger.info("\n" + "="*60)
        logger.info("å‡çº§æ€»ç»“")
        logger.info("="*60)

        logger.success(f"âœ… æˆåŠŸå‡çº§: {len(self.upgraded_tables)} ä¸ªè¡¨")
        if self.upgraded_tables:
            for table in self.upgraded_tables:
                logger.info(f"  - {table}")

        if self.failed_tables:
            logger.error(f"\nâŒ å¤±è´¥: {len(self.failed_tables)} ä¸ªè¡¨")
            for table, error in self.failed_tables:
                logger.error(f"  - {table}: {error}")

        logger.info("\nå‡çº§å†…å®¹ï¼š")
        logger.info("  âœ… adj_close - å¤æƒæ”¶ç›˜ä»·ï¼ˆé‡åŒ–å›æµ‹å¿…éœ€ï¼‰")
        logger.info("  âœ… adj_factor - å¤æƒå› å­ï¼ˆé»˜è®¤1.0ï¼‰")
        logger.info("  âœ… turnover_rate - æ¢æ‰‹ç‡ï¼ˆè¡Œä¸šæ ‡å‡†ï¼‰")
        logger.info("  âœ… vwap - æˆäº¤é‡åŠ æƒå‡ä»·ï¼ˆæœºæ„å¸¸ç”¨ï¼‰")
        logger.info("  âœ… data_source - æ•°æ®æ¥æºï¼ˆè¿½æº¯ç®¡ç†ï¼‰")


def main():
    """ä¸»å‡çº§æµç¨‹"""
    logger.info("="*60)
    logger.info("FactorWeave-Quant æ•°æ®åº“å‡çº§å·¥å…·")
    logger.info("ç‰ˆæœ¬ï¼šV2.0.3 â†’ V2.0.4")
    logger.info("å‡çº§å†…å®¹ï¼šKçº¿è¡¨å¢åŠ 5ä¸ªå­—æ®µï¼ˆæ ‡å‡†é‡åŒ–è¡¨ï¼‰")
    logger.info("="*60)

    # åˆ›å»ºå‡çº§å™¨
    upgrader = DatabaseUpgrader()

    # éœ€è¦å‡çº§çš„æ•°æ®åº“åˆ—è¡¨
    db_paths = [
        "data/factorweave_system.sqlite",
        "data/enhanced_risk_monitor.db",
        # è‡ªåŠ¨æœç´¢å…¶ä»–æ•°æ®åº“
    ]

    # è‡ªåŠ¨æœç´¢dbå’Œdataç›®å½•ä¸‹çš„æ‰€æœ‰æ•°æ®åº“æ–‡ä»¶
    search_dirs = [ 'data']
    for search_dir in search_dirs:
        if Path(search_dir).exists():
            for ext in ['*.sqlite', '*.duckdb']:
                db_paths.extend(Path(search_dir).rglob(ext))

    # å»é‡
    db_paths = list(set(str(p) for p in db_paths))

    logger.info(f"\nå‘ç° {len(db_paths)} ä¸ªæ•°æ®åº“æ–‡ä»¶")

    # é€ä¸ªå‡çº§
    success_count = 0
    for db_path in db_paths:
        if upgrader.upgrade_database(db_path):
            success_count += 1

    # æ‰“å°æ€»ç»“
    upgrader.print_summary()

    logger.info("\n" + "="*60)
    if success_count == len(db_paths):
        logger.success("ğŸ‰ æ‰€æœ‰æ•°æ®åº“å‡çº§å®Œæˆï¼")
    else:
        logger.warning(f"âš ï¸  éƒ¨åˆ†æ•°æ®åº“å‡çº§å¤±è´¥ ({success_count}/{len(db_paths)})")
    logger.info("="*60)

    return success_count == len(db_paths)


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
