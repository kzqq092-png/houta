#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
GPUé›†æˆæµ‹è¯•è„šæœ¬

åŠŸèƒ½ï¼š
1. æµ‹è¯•TensorFlow GPUç®¡ç†å™¨
2. æµ‹è¯•CUDAç¯å¢ƒéªŒè¯å™¨
3. é›†æˆæµ‹è¯•AIé¢„æµ‹æœåŠ¡çš„GPUåŠŸèƒ½
4. æä¾›å®Œæ•´çš„æµ‹è¯•æŠ¥å‘Š

ä½¿ç”¨æ–¹æ³•ï¼š
python scripts/test_gpu_integration.py [--verbose] [--full-test]

ä½œè€…: FactorWeave-Quantå›¢é˜Ÿ
ç‰ˆæœ¬: 1.0
"""

import os
import sys
import time
import json
import traceback
from pathlib import Path
from typing import Dict, List, Any, Optional
import logging

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

class GPUIntegrationTest:
    """GPUé›†æˆæµ‹è¯•å™¨"""
    
    def __init__(self):
        self.test_results = {}
        self.test_start_time = time.time()
        self.verbose = False
        
        # æµ‹è¯•ç»Ÿè®¡
        self.stats = {
            'total_tests': 0,
            'passed_tests': 0,
            'failed_tests': 0,
            'warning_tests': 0,
            'test_times': {}
        }
    
    def log_test_result(self, test_name: str, status: str, message: str, duration: float):
        """è®°å½•æµ‹è¯•ç»“æœ"""
        self.stats['total_tests'] += 1
        if status == 'PASS':
            self.stats['passed_tests'] += 1
        elif status == 'FAIL':
            self.stats['failed_tests'] += 1
        elif status == 'WARN':
            self.stats['warning_tests'] += 1
        
        self.test_results[test_name] = {
            'status': status,
            'message': message,
            'duration': duration
        }
        
        if self.verbose:
            status_icon = {'PASS': 'âœ…', 'FAIL': 'âŒ', 'WARN': 'âš ï¸'}[status]
            logger.info(f"{status_icon} {test_name}: {message} ({duration:.2f}s)")
        else:
            logger.info(f"{status} {test_name}")
    
    def test_tensorflow_gpu_manager(self) -> bool:
        """æµ‹è¯•TensorFlow GPUç®¡ç†å™¨"""
        logger.info("=== æµ‹è¯•TensorFlow GPUç®¡ç†å™¨ ===")
        test_name = "TensorFlow GPUç®¡ç†å™¨"
        start_time = time.time()
        
        try:
            # å¯¼å…¥GPUç®¡ç†å™¨
            try:
                from core.services.tensorflow_gpu_manager import TensorFlowGPUManager, auto_configure_gpu
                logger.info("  âœ… GPUç®¡ç†å™¨æ¨¡å—å¯¼å…¥æˆåŠŸ")
            except ImportError as e:
                self.log_test_result(test_name, 'FAIL', f'å¯¼å…¥å¤±è´¥: {e}', time.time() - start_time)
                return False
            
            # æµ‹è¯•GPUç®¡ç†å™¨åˆ›å»º
            gpu_manager = TensorFlowGPUManager()
            self.log_test_result(test_name + "_åˆ›å»º", 'PASS', 'GPUç®¡ç†å™¨å®ä¾‹åˆ›å»ºæˆåŠŸ', time.time() - start_time)
            
            # æµ‹è¯•GPUæ£€æµ‹
            start_time = time.time()
            gpu_info = gpu_manager.detect_gpu_hardware()
            duration = time.time() - start_time
            
            gpu_status = gpu_info.status.value if gpu_info else "unknown"
            self.log_test_result(test_name + "_æ£€æµ‹", 'PASS', f'æ£€æµ‹åˆ°GPUçŠ¶æ€: {gpu_status}', duration)
            
            # æµ‹è¯•CUDAç¯å¢ƒéªŒè¯
            start_time = time.time()
            cuda_ok = gpu_manager.verify_cuda_environment()
            duration = time.time() - start_time
            
            cuda_status = "é€šè¿‡" if cuda_ok else "å¤±è´¥"
            self.log_test_result(test_name + "_CUDAéªŒè¯", 'PASS' if cuda_ok else 'WARN', f'CUDAç¯å¢ƒéªŒè¯: {cuda_status}', duration)
            
            # æµ‹è¯•TensorFlow GPUé…ç½®
            start_time = time.time()
            config_ok = gpu_manager.configure_tensorflow_gpu()
            duration = time.time() - start_time
            
            config_status = "æˆåŠŸ" if config_ok else "å¤±è´¥"
            self.log_test_result(test_name + "_é…ç½®", 'PASS' if config_ok else 'FAIL', f'GPUé…ç½®: {config_status}', duration)
            
            # æµ‹è¯•è®¾å¤‡ç­–ç•¥
            device_strategy = gpu_manager.get_device_strategy()
            self.log_test_result(test_name + "_è®¾å¤‡ç­–ç•¥", 'PASS', f'è®¾å¤‡ç­–ç•¥: {device_strategy}', 0.1)
            
            # æ¸…ç†èµ„æº
            gpu_manager.cleanup()
            self.log_test_result(test_name + "_æ¸…ç†", 'PASS', 'èµ„æºæ¸…ç†å®Œæˆ', 0.1)
            
            return True
            
        except Exception as e:
            error_msg = f'å¼‚å¸¸: {str(e)}'
            logger.error(f"GPUç®¡ç†å™¨æµ‹è¯•å¤±è´¥: {error_msg}")
            logger.error(traceback.format_exc())
            self.log_test_result(test_name, 'FAIL', error_msg, time.time() - start_time)
            return False
    
    def test_cuda_environment_validator(self) -> bool:
        """æµ‹è¯•CUDAç¯å¢ƒéªŒè¯å™¨"""
        logger.info("=== æµ‹è¯•CUDAç¯å¢ƒéªŒè¯å™¨ ===")
        test_name = "CUDAç¯å¢ƒéªŒè¯å™¨"
        start_time = time.time()
        
        try:
            # å¯¼å…¥éªŒè¯å™¨
            try:
                from scripts.cuda_environment_validator import CUDAEnvironmentValidator
                logger.info("  âœ… CUDAéªŒè¯å™¨æ¨¡å—å¯¼å…¥æˆåŠŸ")
            except ImportError as e:
                self.log_test_result(test_name, 'FAIL', f'å¯¼å…¥å¤±è´¥: {e}', time.time() - start_time)
                return False
            
            # åˆ›å»ºéªŒè¯å™¨å®ä¾‹
            validator = CUDAEnvironmentValidator()
            self.log_test_result(test_name + "_åˆ›å»º", 'PASS', 'éªŒè¯å™¨å®ä¾‹åˆ›å»ºæˆåŠŸ', time.time() - start_time)
            
            # æµ‹è¯•Pythonç¯å¢ƒæ£€æµ‹
            start_time = time.time()
            python_info = validator.detect_python_environment()
            duration = time.time() - start_time
            
            python_version = python_info.get('version', 'unknown')
            self.log_test_result(test_name + "_Pythonç¯å¢ƒ", 'PASS', f'Pythonç‰ˆæœ¬: {python_version}', duration)
            
            # æµ‹è¯•CUDAå®‰è£…æ£€æµ‹
            start_time = time.time()
            cuda_info = validator.detect_cuda_installation()
            duration = time.time() - start_time
            
            cuda_installed = cuda_info.get('installed', False)
            cuda_version = cuda_info.get('version', 'unknown')
            self.log_test_result(test_name + "_CUDAæ£€æµ‹", 'PASS' if cuda_installed else 'WARN', 
                               f'CUDAå®‰è£…: {cuda_installed}, ç‰ˆæœ¬: {cuda_version}', duration)
            
            # æµ‹è¯•cuDNNæ£€æµ‹
            start_time = time.time()
            cudnn_info = validator.detect_cudnn_installation()
            duration = time.time() - start_time
            
            cudnn_installed = cudnn_info.get('installed', False)
            self.log_test_result(test_name + "_cuDNNæ£€æµ‹", 'PASS' if cudnn_installed else 'WARN', 
                               f'cuDNNå®‰è£…: {cudnn_installed}', duration)
            
            # æµ‹è¯•GPUé©±åŠ¨æ£€æµ‹
            start_time = time.time()
            driver_info = validator.detect_nvidia_driver()
            duration = time.time() - start_time
            
            driver_installed = driver_info.get('installed', False)
            gpu_count = driver_info.get('gpu_count', 0)
            self.log_test_result(test_name + "_GPUé©±åŠ¨", 'PASS' if driver_installed else 'WARN', 
                               f'é©±åŠ¨å®‰è£…: {driver_installed}, GPUæ•°é‡: {gpu_count}', duration)
            
            # æµ‹è¯•TensorFlowæ£€æµ‹
            start_time = time.time()
            tf_info = validator.detect_tensorflow()
            duration = time.time() - start_time
            
            tf_installed = tf_info.get('installed', False)
            tf_version = tf_info.get('version', 'unknown')
            self.log_test_result(test_name + "_TensorFlow", 'PASS' if tf_installed else 'WARN', 
                               f'TensorFlowå®‰è£…: {tf_installed}, ç‰ˆæœ¬: {tf_version}', duration)
            
            # æµ‹è¯•å…¼å®¹æ€§æ£€æŸ¥
            start_time = time.time()
            validator.cuda_info = cuda_info
            validator.cudnn_info = cudnn_info
            validator.gpu_info = driver_info
            validator.tensorflow_info = tf_info
            
            compatibility = validator.check_compatibility()
            duration = time.time() - start_time
            
            overall_status = compatibility.get('overall_status', 'unknown')
            self.log_test_result(test_name + "_å…¼å®¹æ€§", 'PASS' if overall_status in ['compatible', 'partial'] else 'WARN', 
                               f'å…¼å®¹æ€§çŠ¶æ€: {overall_status}', duration)
            
            # æµ‹è¯•æŠ¥å‘Šç”Ÿæˆ
            start_time = time.time()
            report = validator.generate_report()
            duration = time.time() - start_time
            
            report_length = len(report)
            self.log_test_result(test_name + "_æŠ¥å‘Šç”Ÿæˆ", 'PASS', f'æŠ¥å‘Šé•¿åº¦: {report_length}å­—ç¬¦', duration)
            
            return True
            
        except Exception as e:
            error_msg = f'å¼‚å¸¸: {str(e)}'
            logger.error(f"CUDAéªŒè¯å™¨æµ‹è¯•å¤±è´¥: {error_msg}")
            logger.error(traceback.format_exc())
            self.log_test_result(test_name, 'FAIL', error_msg, time.time() - start_time)
            return False
    
    def test_ai_prediction_service_integration(self) -> bool:
        """æµ‹è¯•AIé¢„æµ‹æœåŠ¡GPUé›†æˆ"""
        logger.info("=== æµ‹è¯•AIé¢„æµ‹æœåŠ¡GPUé›†æˆ ===")
        test_name = "AIé¢„æµ‹æœåŠ¡GPUé›†æˆ"
        start_time = time.time()
        
        try:
            # å¯¼å…¥AIé¢„æµ‹æœåŠ¡
            try:
                from core.services.ai_prediction_service import AIPredictionService
                logger.info("  âœ… AIé¢„æµ‹æœåŠ¡æ¨¡å—å¯¼å…¥æˆåŠŸ")
            except ImportError as e:
                self.log_test_result(test_name, 'FAIL', f'å¯¼å…¥å¤±è´¥: {e}', time.time() - start_time)
                return False
            
            # åˆ›å»ºAIé¢„æµ‹æœåŠ¡å®ä¾‹
            ai_service = AIPredictionService()
            self.log_test_result(test_name + "_åˆ›å»º", 'PASS', 'AIé¢„æµ‹æœåŠ¡å®ä¾‹åˆ›å»ºæˆåŠŸ', time.time() - start_time)
            
            # æµ‹è¯•GPUçŠ¶æ€è·å–
            start_time = time.time()
            gpu_status = ai_service.get_gpu_status()
            duration = time.time() - start_time
            
            gpu_enabled = gpu_status.get('enabled', False)
            device_strategy = gpu_status.get('device_strategy', '/CPU:0')
            self.log_test_result(test_name + "_GPUçŠ¶æ€", 'PASS', f'GPUå¯ç”¨: {gpu_enabled}, è®¾å¤‡: {device_strategy}', duration)
            
            # æµ‹è¯•é¢„æµ‹è®¾å¤‡è·å–
            start_time = time.time()
            prediction_device = ai_service.get_device_for_prediction()
            duration = time.time() - start_time
            
            self.log_test_result(test_name + "_é¢„æµ‹è®¾å¤‡", 'PASS', f'é¢„æµ‹è®¾å¤‡: {prediction_device}', duration)
            
            # åˆ›å»ºæµ‹è¯•æ•°æ®
            import pandas as pd
            import numpy as np
            
            start_time = time.time()
            test_data = {
                'open': np.random.uniform(100, 110, 100),
                'high': np.random.uniform(110, 120, 100),
                'low': np.random.uniform(90, 100, 100),
                'close': np.random.uniform(95, 115, 100),
                'volume': np.random.uniform(1000000, 10000000, 100)
            }
            kdata = pd.DataFrame(test_data)
            duration = time.time() - start_time
            
            self.log_test_result(test_name + "_æµ‹è¯•æ•°æ®", 'PASS', f'æµ‹è¯•æ•°æ®åˆ›å»ºå®Œæˆ: {kdata.shape}', duration)
            
            # æµ‹è¯•é¢„æµ‹åŠŸèƒ½ï¼ˆå¦‚æœGPUç®¡ç†å™¨å¯ç”¨ï¼‰
            if hasattr(ai_service, '_gpu_manager') and ai_service._gpu_manager:
                start_time = time.time()
                try:
                    prediction_result = ai_service._predict_with_deep_learning(kdata)
                    duration = time.time() - start_time
                    
                    if prediction_result:
                        device_used = prediction_result.get('device_used', 'unknown')
                        gpu_enabled = prediction_result.get('gpu_enabled', False)
                        self.log_test_result(test_name + "_GPUé¢„æµ‹", 'PASS', 
                                           f'è®¾å¤‡: {device_used}, GPU: {gpu_enabled}', duration)
                    else:
                        self.log_test_result(test_name + "_GPUé¢„æµ‹", 'WARN', 'é¢„æµ‹ç»“æœä¸ºç©º', duration)
                        
                except Exception as e:
                    duration = time.time() - start_time
                    self.log_test_result(test_name + "_GPUé¢„æµ‹", 'WARN', f'é¢„æµ‹å¼‚å¸¸: {str(e)}', duration)
            else:
                self.log_test_result(test_name + "_GPUé¢„æµ‹", 'WARN', 'GPUç®¡ç†å™¨ä¸å¯ç”¨ï¼Œè·³è¿‡é¢„æµ‹æµ‹è¯•', 0.1)
            
            return True
            
        except Exception as e:
            error_msg = f'å¼‚å¸¸: {str(e)}'
            logger.error(f"AIé¢„æµ‹æœåŠ¡é›†æˆæµ‹è¯•å¤±è´¥: {error_msg}")
            logger.error(traceback.format_exc())
            self.log_test_result(test_name, 'FAIL', error_msg, time.time() - start_time)
            return False
    
    def test_performance_comparison(self) -> bool:
        """æµ‹è¯•GPU vs CPUæ€§èƒ½å¯¹æ¯”"""
        logger.info("=== æµ‹è¯•GPU vs CPUæ€§èƒ½å¯¹æ¯” ===")
        test_name = "æ€§èƒ½å¯¹æ¯”æµ‹è¯•"
        start_time = time.time()
        
        try:
            # æ£€æŸ¥TensorFlowæ˜¯å¦å¯ç”¨
            try:
                import tensorflow as tf
                TENSORFLOW_AVAILABLE = True
            except ImportError:
                self.log_test_result(test_name, 'WARN', 'TensorFlowä¸å¯ç”¨ï¼Œè·³è¿‡æ€§èƒ½æµ‹è¯•', time.time() - start_time)
                return False
            
            # æ£€æŸ¥GPUå¯ç”¨æ€§
            gpus = tf.config.list_physical_devices('GPU')
            if len(gpus) == 0:
                self.log_test_result(test_name, 'WARN', 'æœªæ£€æµ‹åˆ°GPUï¼Œè·³è¿‡æ€§èƒ½å¯¹æ¯”', time.time() - start_time)
                return False
            
            # å‡†å¤‡æµ‹è¯•æ•°æ®
            size = 1000
            a = tf.random.normal([size, size])
            b = tf.random.normal([size, size])
            
            # CPUæ€§èƒ½æµ‹è¯•
            start_time = time.time()
            with tf.device('/CPU:0'):
                cpu_result = tf.matmul(a, b)
            cpu_time = time.time() - start_time
            
            # GPUæ€§èƒ½æµ‹è¯•
            start_time = time.time()
            with tf.device('/GPU:0'):
                gpu_result = tf.matmul(a, b)
            gpu_time = time.time() - start_time
            
            # è®¡ç®—åŠ é€Ÿæ¯”
            speedup = cpu_time / gpu_time if gpu_time > 0 else 0.0
            
            self.log_test_result(test_name, 'PASS', 
                               f'CPU: {cpu_time:.4f}s, GPU: {gpu_time:.4f}s, åŠ é€Ÿæ¯”: {speedup:.2f}x', 
                               cpu_time + gpu_time)
            
            return True
            
        except Exception as e:
            error_msg = f'å¼‚å¸¸: {str(e)}'
            logger.error(f"æ€§èƒ½å¯¹æ¯”æµ‹è¯•å¤±è´¥: {error_msg}")
            self.log_test_result(test_name, 'FAIL', error_msg, time.time() - start_time)
            return False
    
    def generate_test_report(self) -> str:
        """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
        total_duration = time.time() - self.test_start_time
        
        report = []
        report.append("=" * 80)
        report.append("GPUé›†æˆæµ‹è¯•æŠ¥å‘Š")
        report.append("=" * 80)
        report.append("")
        
        # æµ‹è¯•ç»Ÿè®¡
        report.append("æµ‹è¯•ç»Ÿè®¡:")
        report.append(f"  æ€»æµ‹è¯•æ•°: {self.stats['total_tests']}")
        report.append(f"  é€šè¿‡æµ‹è¯•: {self.stats['passed_tests']}")
        report.append(f"  å¤±è´¥æµ‹è¯•: {self.stats['failed_tests']}")
        report.append(f"  è­¦å‘Šæµ‹è¯•: {self.stats['warning_tests']}")
        report.append(f"  æˆåŠŸç‡: {self.stats['passed_tests']/self.stats['total_tests']*100:.1f}%" if self.stats['total_tests'] > 0 else "  æˆåŠŸç‡: 0%")
        report.append(f"  æ€»è€—æ—¶: {total_duration:.2f}s")
        report.append("")
        
        # è¯¦ç»†æµ‹è¯•ç»“æœ
        report.append("è¯¦ç»†æµ‹è¯•ç»“æœ:")
        for test_name, result in self.test_results.items():
            status_icon = {'PASS': 'âœ…', 'FAIL': 'âŒ', 'WARN': 'âš ï¸'}[result['status']]
            report.append(f"  {status_icon} {test_name}: {result['message']} ({result['duration']:.2f}s)")
        report.append("")
        
        # å»ºè®®å’Œæ€»ç»“
        if self.stats['failed_tests'] == 0:
            if self.stats['warning_tests'] == 0:
                report.append("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼GPUé›†æˆç³»ç»Ÿå·¥ä½œæ­£å¸¸ã€‚")
            else:
                report.append("âš ï¸ æµ‹è¯•åŸºæœ¬é€šè¿‡ï¼Œä½†æœ‰ä¸€äº›è­¦å‘Šï¼Œå»ºè®®æ£€æŸ¥ç›¸å…³é…ç½®ã€‚")
        else:
            report.append("âŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œéœ€è¦æ£€æŸ¥GPUé…ç½®å’Œç¯å¢ƒè®¾ç½®ã€‚")
        
        report.append("")
        report.append("å»ºè®®:")
        if self.stats['failed_tests'] > 0:
            report.append("  1. æ£€æŸ¥CUDAå’ŒcuDNNå®‰è£…")
            report.append("  2. éªŒè¯NVIDIA GPUé©±åŠ¨")
            report.append("  3. ç¡®è®¤TensorFlow GPUç‰ˆæœ¬å®‰è£…")
        elif self.stats['warning_tests'] > 0:
            report.append("  1. æ£€æŸ¥GPUè®¾å¤‡æ˜¯å¦æ­£ç¡®è¯†åˆ«")
            report.append("  2. éªŒè¯CUDAç‰ˆæœ¬å…¼å®¹æ€§")
        else:
            report.append("  1. ç³»ç»Ÿé…ç½®è‰¯å¥½ï¼Œå¯ä»¥æ­£å¸¸ä½¿ç”¨GPUåŠ é€Ÿ")
        
        report.append("=" * 80)
        
        return "\n".join(report)
    
    def run_all_tests(self, verbose: bool = False, full_test: bool = False) -> bool:
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        self.verbose = verbose
        
        logger.info("å¼€å§‹GPUé›†æˆæµ‹è¯•...")
        logger.info(f"è¯¦ç»†æ¨¡å¼: {verbose}, å®Œæ•´æµ‹è¯•: {full_test}")
        
        tests = [
            ("TensorFlow GPUç®¡ç†å™¨", self.test_tensorflow_gpu_manager),
            ("CUDAç¯å¢ƒéªŒè¯å™¨", self.test_cuda_environment_validator),
            ("AIé¢„æµ‹æœåŠ¡é›†æˆ", self.test_ai_prediction_service_integration)
        ]
        
        if full_test:
            tests.append(("æ€§èƒ½å¯¹æ¯”æµ‹è¯•", self.test_performance_comparison))
        
        all_passed = True
        
        for test_name, test_func in tests:
            try:
                logger.info(f"è¿è¡Œæµ‹è¯•: {test_name}")
                test_passed = test_func()
                if not test_passed:
                    all_passed = False
                    logger.warning(f"æµ‹è¯•å¤±è´¥: {test_name}")
            except Exception as e:
                logger.error(f"æµ‹è¯•å¼‚å¸¸: {test_name} - {e}")
                all_passed = False
        
        # ç”ŸæˆæŠ¥å‘Š
        report = self.generate_test_report()
        print("\n" + report)
        
        # ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶
        report_file = Path("gpu_integration_test_report.txt")
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report)
        logger.info(f"æµ‹è¯•æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")
        
        return all_passed

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description="GPUé›†æˆæµ‹è¯•å·¥å…·")
    parser.add_argument("--verbose", "-v", action="store_true", help="è¯¦ç»†è¾“å‡º")
    parser.add_argument("--full-test", "-f", action="store_true", help="è¿è¡Œå®Œæ•´æµ‹è¯•")
    parser.add_argument("--save-json", action="store_true", help="ä¿å­˜JSONæ ¼å¼ç»“æœ")
    
    args = parser.parse_args()
    
    # åˆ›å»ºæµ‹è¯•å™¨å¹¶è¿è¡Œ
    tester = GPUIntegrationTest()
    success = tester.run_all_tests(verbose=args.verbose, full_test=args.full_test)
    
    # ä¿å­˜JSONç»“æœ
    if args.save_json:
        json_file = Path("gpu_integration_test_results.json")
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump({
                'test_results': tester.test_results,
                'stats': tester.stats,
                'timestamp': time.time(),
                'success': success
            }, f, indent=2, ensure_ascii=False)
        logger.info(f"JSONç»“æœå·²ä¿å­˜åˆ°: {json_file}")
    
    # è¿”å›çŠ¶æ€ç 
    sys.exit(0 if success else 1)

if __name__ == "__main__":
    main()