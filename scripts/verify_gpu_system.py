#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
GPUç®¡ç†ç³»ç»Ÿç‹¬ç«‹éªŒè¯è„šæœ¬
ç‹¬ç«‹è¿è¡Œï¼ŒéªŒè¯GPUç®¡ç†ç³»ç»Ÿçš„æ ¸å¿ƒåŠŸèƒ½
"""

import sys
import os
import json
import time
from pathlib import Path
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

def test_gpu_detection():
    """æµ‹è¯•GPUç¡¬ä»¶æ£€æµ‹"""
    print("\n=== æµ‹è¯•GPUç¡¬ä»¶æ£€æµ‹ ===")
    
    try:
        # æµ‹è¯•nvidia-ml-py3
        try:
            import pynvml
            pynvml.nvmlInit()
            device_count = pynvml.nvmlDeviceGetCount()
            print(f"âœ… NVIDIA GPUæ£€æµ‹æˆåŠŸ: å‘ç° {device_count} ä¸ªGPUè®¾å¤‡")
            
            for i in range(device_count):
                handle = pynvml.nvmlDeviceGetHandleByIndex(i)
                name_result = pynvml.nvmlDeviceGetName(handle)
                # å…¼å®¹ä¸åŒç‰ˆæœ¬çš„pynvmlè¿”å›ç±»å‹
                name = name_result.decode('utf-8') if isinstance(name_result, bytes) else str(name_result)
                memory_info = pynvml.nvmlDeviceGetMemoryInfo(handle)
                print(f"  GPU {i}: {name}")
                print(f"    æ˜¾å­˜: {memory_info.total // 1024 // 1024} MB")
                print(f"    å¯ç”¨: {memory_info.free // 1024 // 1024} MB")
                print(f"    å·²ç”¨: {memory_info.used // 1024 // 1024} MB")
            
            pynvml.nvmlShutdown()
            return True
            
        except ImportError:
            print("âŒ pynvmlåº“æœªå®‰è£…ï¼Œæ— æ³•è¿›è¡ŒGPUæ£€æµ‹")
        except Exception as e:
            print(f"âŒ GPUæ£€æµ‹å¤±è´¥: {e}")
            
        return False
        
    except Exception as e:
        print(f"âŒ GPUæ£€æµ‹å¼‚å¸¸: {e}")
        return False

def test_tensorflow_gpu():
    """æµ‹è¯•TensorFlow GPUæ”¯æŒ"""
    print("\n=== æµ‹è¯•TensorFlow GPUæ”¯æŒ ===")
    
    try:
        import tensorflow as tf
        print(f"âœ… TensorFlowç‰ˆæœ¬: {tf.__version__}")
        
        # æ£€æµ‹GPUå¯ç”¨æ€§
        gpus = tf.config.list_physical_devices('GPU')
        if gpus:
            print(f"âœ… TensorFlowæ£€æµ‹åˆ° {len(gpus)} ä¸ªGPUè®¾å¤‡")
            
            # æ˜¾ç¤ºGPUè¯¦ç»†ä¿¡æ¯
            for i, gpu in enumerate(gpus):
                print(f"  GPU {i}: {gpu.name}")
                try:
                    # è®¾ç½®æ˜¾å­˜å¢é•¿
                    tf.config.experimental.set_memory_growth(gpu, True)
                    print(f"    æ˜¾å­˜å¢é•¿: å·²å¯ç”¨")
                except Exception as e:
                    print(f"    æ˜¾å­˜å¢é•¿: å¤±è´¥ ({e})")
            
            # ç®€å•GPUè®¡ç®—æµ‹è¯•
            with tf.device('/GPU:0'):
                a = tf.constant([[1.0, 2.0], [3.0, 4.0]])
                b = tf.constant([[1.0, 1.0], [0.0, 1.0]])
                c = tf.matmul(a, b)
                print(f"    GPUè®¡ç®—æµ‹è¯•: æˆåŠŸ (ç»“æœå½¢çŠ¶: {c.shape})")
            
            return True
        else:
            print("âŒ TensorFlowæœªæ£€æµ‹åˆ°GPUè®¾å¤‡")
            return False
            
    except ImportError:
        print("âŒ TensorFlowæœªå®‰è£…")
        return False
    except Exception as e:
        print(f"âŒ TensorFlow GPUæµ‹è¯•å¤±è´¥: {e}")
        return False

def test_cuda_environment():
    """æµ‹è¯•CUDAç¯å¢ƒ"""
    print("\n=== æµ‹è¯•CUDAç¯å¢ƒ ===")
    
    try:
        # æ£€æŸ¥CUDAåº“
        try:
            import ctypes
            cuda_lib = ctypes.CDLL('nvcuda.dll' if sys.platform == 'win32' else 'libcuda.so.1')
            print("âœ… CUDAè¿è¡Œæ—¶åº“åŠ è½½æˆåŠŸ")
        except Exception as e:
            print(f"âŒ CUDAè¿è¡Œæ—¶åº“åŠ è½½å¤±è´¥: {e}")
            return False
        
        # æ£€æŸ¥cuDNN
        try:
            cudnn_lib = ctypes.CDLL('cudnn64_8.dll' if sys.platform == 'win32' else 'libcudnn.so.8')
            print("âœ… cuDNNåº“åŠ è½½æˆåŠŸ")
        except Exception as e:
            print(f"âŒ cuDNNåº“åŠ è½½å¤±è´¥: {e}")
            return False
        
        print("âœ… CUDAç¯å¢ƒåŸºæœ¬éªŒè¯é€šè¿‡")
        return True
        
    except Exception as e:
        print(f"âŒ CUDAç¯å¢ƒæµ‹è¯•å¤±è´¥: {e}")
        return False

def test_gpu_manager_module():
    """æµ‹è¯•GPUç®¡ç†å™¨æ¨¡å—"""
    print("\n=== æµ‹è¯•GPUç®¡ç†å™¨æ¨¡å— ===")
    
    try:
        # å°è¯•å¯¼å…¥GPUç®¡ç†å™¨æ¨¡å—
        gpu_manager_path = Path(__file__).parent.parent / 'core' / 'services' / 'tensorflow_gpu_manager.py'
        
        if not gpu_manager_path.exists():
            print("âŒ GPUç®¡ç†å™¨æ¨¡å—æ–‡ä»¶ä¸å­˜åœ¨")
            return False
        
        print("âœ… GPUç®¡ç†å™¨æ¨¡å—æ–‡ä»¶å­˜åœ¨")
        
        # éªŒè¯æ–‡ä»¶å†…å®¹
        with open(gpu_manager_path, 'r', encoding='utf-8') as f:
            content = f.read()
            
        # æ£€æŸ¥å…³é”®ç±»å’Œæ–¹æ³•
        required_elements = [
            'class TensorFlowGPUManager',
            'def auto_detect_and_configure',
            'def detect_gpu_hardware',
            'def configure_tensorflow_gpu',
            'GPUStatus'
        ]
        
        for element in required_elements:
            if element in content:
                print(f"  âœ… æ‰¾åˆ°å…³é”®å…ƒç´ : {element}")
            else:
                print(f"  âŒ ç¼ºå°‘å…³é”®å…ƒç´ : {element}")
                return False
        
        print("âœ… GPUç®¡ç†å™¨æ¨¡å—ç»“æ„éªŒè¯é€šè¿‡")
        return True
        
    except Exception as e:
        print(f"âŒ GPUç®¡ç†å™¨æ¨¡å—æµ‹è¯•å¤±è´¥: {e}")
        return False

def generate_verification_report(results):
    """ç”ŸæˆéªŒè¯æŠ¥å‘Š"""
    print("\n" + "="*60)
    print("GPUç®¡ç†ç³»ç»ŸéªŒè¯æŠ¥å‘Š")
    print("="*60)
    
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    print(f"éªŒè¯æ—¶é—´: {timestamp}")
    print(f"è¿è¡Œç¯å¢ƒ: {sys.platform} - Python {sys.version}")
    
    print("\néªŒè¯ç»“æœ:")
    test_names = {
        'gpu_detection': 'GPUç¡¬ä»¶æ£€æµ‹',
        'tensorflow_gpu': 'TensorFlow GPUæ”¯æŒ',
        'cuda_environment': 'CUDAç¯å¢ƒ',
        'gpu_manager': 'GPUç®¡ç†å™¨æ¨¡å—'
    }
    
    passed = 0
    total = len(results)
    
    for test_key, result in results.items():
        test_name = test_names.get(test_key, test_key)
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"  {test_name}: {status}")
        if result:
            passed += 1
    
    print(f"\næ€»ä½“ç»“æœ: {passed}/{total} é¡¹æµ‹è¯•é€šè¿‡")
    
    if passed == total:
        print("ğŸ‰ GPUç®¡ç†ç³»ç»ŸéªŒè¯å®Œå…¨é€šè¿‡ï¼")
        print("ğŸ’¡ å»ºè®®: ç³»ç»Ÿå·²å‡†å¤‡å¥½ä½¿ç”¨GPUåŠ é€ŸåŠŸèƒ½")
    elif passed >= total * 0.5:
        print("âš ï¸ GPUç®¡ç†ç³»ç»Ÿéƒ¨åˆ†å¯ç”¨")
        print("ğŸ’¡ å»ºè®®: éƒ¨åˆ†åŠŸèƒ½æ­£å¸¸ï¼Œå¯å°è¯•ä½¿ç”¨ï¼Œä½†å»ºè®®å®Œå–„ç¼ºå¤±çš„ç»„ä»¶")
    else:
        print("âŒ GPUç®¡ç†ç³»ç»Ÿå­˜åœ¨é‡å¤§é—®é¢˜")
        print("ğŸ’¡ å»ºè®®: éœ€è¦å®‰è£…ä¾èµ–åº“æˆ–é…ç½®CUDAç¯å¢ƒ")
    
    return passed, total

def main():
    """ä¸»å‡½æ•°"""
    print("GPUç®¡ç†ç³»ç»Ÿç‹¬ç«‹éªŒè¯è„šæœ¬")
    print("="*60)
    print("æ­¤è„šæœ¬å°†ç‹¬ç«‹éªŒè¯GPUç®¡ç†ç³»ç»Ÿçš„å„ä¸ªç»„ä»¶")
    
    results = {}
    
    # æ‰§è¡Œå„é¡¹æµ‹è¯•
    tests = [
        ('gpu_detection', test_gpu_detection),
        ('tensorflow_gpu', test_tensorflow_gpu),
        ('cuda_environment', test_cuda_environment),
        ('gpu_manager', test_gpu_manager_module)
    ]
    
    for test_name, test_func in tests:
        try:
            print(f"\nå¼€å§‹æ‰§è¡Œ: {test_name}")
            results[test_name] = test_func()
        except Exception as e:
            print(f"âŒ æµ‹è¯•å¼‚å¸¸: {test_name} - {e}")
            results[test_name] = False
    
    # ç”ŸæˆæŠ¥å‘Š
    passed, total = generate_verification_report(results)
    
    # ä¿å­˜è¯¦ç»†æŠ¥å‘Šåˆ°æ–‡ä»¶
    report_data = {
        'timestamp': datetime.now().isoformat(),
        'platform': sys.platform,
        'python_version': sys.version,
        'results': results,
        'summary': {
            'passed': passed,
            'total': total,
            'success_rate': passed / total if total > 0 else 0
        }
    }
    
    report_file = Path("gpu_verification_report.json")
    with open(report_file, 'w', encoding='utf-8') as f:
        json.dump(report_data, f, indent=2, ensure_ascii=False)
    
    print(f"\nè¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")
    
    return passed == total

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)