#!/usr/bin/env python3
"""
AIæ¨¡åž‹ç”Ÿæˆè„šæœ¬

åŠŸèƒ½ï¼š
1. ç”Ÿæˆè®­ç»ƒæ•°æ®
2. è®­ç»ƒ4ä¸ªAIé¢„æµ‹æ¨¡åž‹ï¼špattern_model, trend_model, sentiment_model, price_model
3. ä¿å­˜æ¨¡åž‹åˆ° models/trained/ ç›®å½•

ä½¿ç”¨æ–¹æ³•ï¼š
python scripts/generate_ai_models.py [--quick] [--model pattern|trend|sentiment|price|all]
"""

import sys
import logging
import argparse
import numpy as np
import pandas as pd
from pathlib import Path
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# æ£€æŸ¥TensorFlowå¯ç”¨æ€§
try:
    import tensorflow as tf
    from tensorflow.keras.models import Sequential
    from tensorflow.keras.layers import Dense, Dropout, LSTM
    from tensorflow.keras.utils import to_categorical
    from models.deep_learning import build_deep_learning_model, TENSORFLOW_AVAILABLE
    TF_AVAILABLE = True
    print("âœ… TensorFlow å¯ç”¨")
except ImportError as e:
    TF_AVAILABLE = False
    print(f"âŒ TensorFlow ä¸å¯ç”¨: {e}")
    print("è¯·å®‰è£…TensorFlow: pip install tensorflow")

logger = logging.getLogger(__name__)


class AIModelGenerator:
    """AIæ¨¡åž‹ç”Ÿæˆå™¨"""

    def __init__(self, quick_mode=False):
        """
        åˆå§‹åŒ–æ¨¡åž‹ç”Ÿæˆå™¨

        Args:
            quick_mode: å¿«é€Ÿæ¨¡å¼ï¼Œä½¿ç”¨è¾ƒå°‘çš„è®­ç»ƒæ•°æ®å’Œè½®æ¬¡
        """
        self.quick_mode = quick_mode
        self.models_dir = project_root / "models" / "trained"
        self.models_dir.mkdir(parents=True, exist_ok=True)

        # è®­ç»ƒå‚æ•°
        if quick_mode:
            self.epochs = 10
            self.sample_size = 1000
            self.sequence_length = 10
        else:
            self.epochs = 50
            self.sample_size = 5000
            self.sequence_length = 20

        print(f"æ¨¡å¼: {'å¿«é€Ÿ' if quick_mode else 'æ ‡å‡†'}")
        print(f"è®­ç»ƒè½®æ¬¡: {self.epochs}")
        print(f"æ ·æœ¬æ•°é‡: {self.sample_size}")

    def generate_sample_data(self, data_type="pattern", size=None):
        """
        ç”Ÿæˆç¤ºä¾‹è®­ç»ƒæ•°æ®

        Args:
            data_type: æ•°æ®ç±»åž‹ (pattern, trend, sentiment, price)
            size: æ•°æ®å¤§å°

        Returns:
            X: ç‰¹å¾æ•°æ®
            y: æ ‡ç­¾æ•°æ®
        """
        if size is None:
            size = self.sample_size

        print(f"ç”Ÿæˆ {data_type} è®­ç»ƒæ•°æ®ï¼Œæ ·æœ¬æ•°: {size}")

        if data_type == "pattern":
            # å½¢æ€è¯†åˆ«æ•°æ®ï¼šæŠ€æœ¯æŒ‡æ ‡ -> å½¢æ€ç±»åž‹
            n_features = 15  # 15ä¸ªæŠ€æœ¯æŒ‡æ ‡
            X = np.random.randn(size, n_features)

            # æ·»åŠ ä¸€äº›ç›¸å…³æ€§ï¼Œæ¨¡æ‹ŸçœŸå®žçš„æŠ€æœ¯æŒ‡æ ‡å…³ç³»
            X[:, 1] = X[:, 0] * 0.8 + np.random.randn(size) * 0.3  # RSIä¸Žä»·æ ¼ç›¸å…³
            X[:, 2] = X[:, 0] * 0.6 + np.random.randn(size) * 0.5  # MACDä¸Žä»·æ ¼ç›¸å…³

            # 3ç±»å½¢æ€ï¼šä¸Šå‡ã€ä¸‹é™ã€éœ‡è¡
            y = np.random.randint(0, 3, size)

        elif data_type == "trend":
            # è¶‹åŠ¿é¢„æµ‹æ•°æ®ï¼šåŽ†å²ä»·æ ¼+æŒ‡æ ‡ -> æœªæ¥è¶‹åŠ¿
            n_features = 20  # 20ä¸ªç‰¹å¾
            X = np.random.randn(size, n_features)

            # æ¨¡æ‹Ÿè¶‹åŠ¿ç‰¹å¾
            trend_signal = np.cumsum(np.random.randn(size) * 0.1)
            X[:, 0] = trend_signal  # ä¸»è¶‹åŠ¿ç‰¹å¾
            X[:, 1] = np.roll(trend_signal, 1)  # æ»žåŽ1æœŸ
            X[:, 2] = np.roll(trend_signal, 2)  # æ»žåŽ2æœŸ

            # 3ç±»è¶‹åŠ¿ï¼šä¸Šæ¶¨ã€ä¸‹è·Œã€æ¨ªç›˜
            y = np.where(trend_signal > 0.5, 2, np.where(trend_signal < -0.5, 0, 1))

        elif data_type == "sentiment":
            # æƒ…ç»ªåˆ†æžæ•°æ®ï¼šå¸‚åœºæŒ‡æ ‡ -> æƒ…ç»ªçŠ¶æ€
            n_features = 12  # 12ä¸ªå¸‚åœºæƒ…ç»ªæŒ‡æ ‡
            X = np.random.randn(size, n_features)

            # æ¨¡æ‹Ÿæƒ…ç»ªæŒ‡æ ‡
            fear_greed = np.random.beta(2, 2, size) * 100  # ææƒ§è´ªå©ªæŒ‡æ•°
            volume_ratio = np.random.lognormal(0, 0.5, size)  # æˆäº¤é‡æ¯”çŽ‡
            X[:, 0] = (fear_greed - 50) / 25  # æ ‡å‡†åŒ–
            X[:, 1] = np.log(volume_ratio)

            # 3ç±»æƒ…ç»ªï¼šä¹è§‚ã€æ‚²è§‚ã€ä¸­æ€§
            y = np.where(fear_greed > 70, 2, np.where(fear_greed < 30, 0, 1))

        elif data_type == "price":
            # ä»·æ ¼é¢„æµ‹æ•°æ®ï¼šæŠ€æœ¯åˆ†æžç‰¹å¾ -> ä»·æ ¼å˜åŒ–
            n_features = 25  # 25ä¸ªæŠ€æœ¯åˆ†æžç‰¹å¾
            X = np.random.randn(size, n_features)

            # æ¨¡æ‹Ÿä»·æ ¼ç›¸å…³ç‰¹å¾
            price_momentum = np.random.randn(size)
            volatility = np.random.exponential(1, size)
            X[:, 0] = price_momentum
            X[:, 1] = volatility
            X[:, 2] = price_momentum * volatility  # åŠ¨é‡*æ³¢åŠ¨çŽ‡

            # 3ç±»ä»·æ ¼å˜åŒ–ï¼šä¸Šæ¶¨ã€ä¸‹è·Œã€å¹³ç¨³
            price_change = price_momentum + np.random.randn(size) * 0.5
            y = np.where(price_change > 0.3, 2, np.where(price_change < -0.3, 0, 1))

        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ•°æ®ç±»åž‹: {data_type}")

        # ç¡®ä¿æ ‡ç­¾åˆ†å¸ƒç›¸å¯¹å‡è¡¡
        unique, counts = np.unique(y, return_counts=True)
        print(f"æ ‡ç­¾åˆ†å¸ƒ: {dict(zip(unique, counts))}")

        return X.astype(np.float32), y.astype(np.int32)

    def create_simple_model(self, input_dim, model_name):
        """
        åˆ›å»ºç®€å•çš„æ·±åº¦å­¦ä¹ æ¨¡åž‹

        Args:
            input_dim: è¾“å…¥ç»´åº¦
            model_name: æ¨¡åž‹åç§°

        Returns:
            model: Kerasæ¨¡åž‹
        """
        if not TF_AVAILABLE:
            raise ImportError("TensorFlowä¸å¯ç”¨ï¼Œæ— æ³•åˆ›å»ºæ·±åº¦å­¦ä¹ æ¨¡åž‹")

        model = Sequential([
            Dense(128, activation='relu', input_dim=input_dim),
            Dropout(0.3),
            Dense(64, activation='relu'),
            Dropout(0.2),
            Dense(32, activation='relu'),
            Dense(3, activation='softmax')  # 3åˆ†ç±»è¾“å‡º
        ])

        model.compile(
            optimizer='adam',
            loss='categorical_crossentropy',
            metrics=['accuracy']
        )

        print(f"{model_name} æ¨¡åž‹ç»“æž„:")
        model.summary()

        return model

    def train_and_save_model(self, model_type):
        """
        è®­ç»ƒå¹¶ä¿å­˜æŒ‡å®šç±»åž‹çš„æ¨¡åž‹

        Args:
            model_type: æ¨¡åž‹ç±»åž‹ (pattern, trend, sentiment, price)
        """
        print(f"\n{'='*60}")
        print(f"å¼€å§‹è®­ç»ƒ {model_type} æ¨¡åž‹")
        print(f"{'='*60}")

        try:
            # ç”Ÿæˆè®­ç»ƒæ•°æ®
            X, y = self.generate_sample_data(model_type)

            # åˆ’åˆ†è®­ç»ƒæµ‹è¯•é›†
            split_idx = int(0.8 * len(X))
            X_train, X_test = X[:split_idx], X[split_idx:]
            y_train, y_test = y[:split_idx], y[split_idx:]

            # è½¬æ¢ä¸ºåˆ†ç±»æ ‡ç­¾
            y_train_cat = to_categorical(y_train, 3)
            y_test_cat = to_categorical(y_test, 3)

            print(f"è®­ç»ƒé›†å¤§å°: {X_train.shape[0]}")
            print(f"æµ‹è¯•é›†å¤§å°: {X_test.shape[0]}")
            print(f"ç‰¹å¾ç»´åº¦: {X_train.shape[1]}")

            # åˆ›å»ºæ¨¡åž‹
            model = self.create_simple_model(X_train.shape[1], model_type)

            # è®­ç»ƒæ¨¡åž‹
            print("å¼€å§‹è®­ç»ƒ...")
            history = model.fit(
                X_train, y_train_cat,
                validation_data=(X_test, y_test_cat),
                epochs=self.epochs,
                batch_size=32,
                verbose=1 if not self.quick_mode else 0
            )

            # è¯„ä¼°æ¨¡åž‹
            test_loss, test_acc = model.evaluate(X_test, y_test_cat, verbose=0)
            print(f"æµ‹è¯•å‡†ç¡®çŽ‡: {test_acc:.4f}")

            # ä¿å­˜æ¨¡åž‹
            model_path = self.models_dir / f"{model_type}_model.h5"
            model.save(str(model_path))
            print(f"âœ… æ¨¡åž‹å·²ä¿å­˜: {model_path}")

            # ä¿å­˜è®­ç»ƒä¿¡æ¯
            info = {
                'model_type': model_type,
                'training_date': datetime.now().isoformat(),
                'test_accuracy': float(test_acc),
                'test_loss': float(test_loss),
                'epochs': self.epochs,
                'sample_size': self.sample_size,
                'input_features': int(X_train.shape[1]),
                'quick_mode': self.quick_mode
            }

            info_path = self.models_dir / f"{model_type}_model_info.json"
            import json
            with open(info_path, 'w', encoding='utf-8') as f:
                json.dump(info, f, indent=2, ensure_ascii=False)

            print(f"âœ… æ¨¡åž‹ä¿¡æ¯å·²ä¿å­˜: {info_path}")

        except Exception as e:
            print(f"âŒ {model_type} æ¨¡åž‹è®­ç»ƒå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()

    def generate_all_models(self):
        """ç”Ÿæˆæ‰€æœ‰AIæ¨¡åž‹"""
        model_types = ['pattern', 'trend', 'sentiment', 'price']

        print(f"\nðŸš€ å¼€å§‹ç”ŸæˆAIé¢„æµ‹æ¨¡åž‹")
        print(f"ç›®æ ‡ç›®å½•: {self.models_dir}")
        print(f"æ¨¡åž‹ç±»åž‹: {model_types}")

        if not TF_AVAILABLE:
            print("âŒ TensorFlowä¸å¯ç”¨ï¼Œæ— æ³•ç”Ÿæˆæ·±åº¦å­¦ä¹ æ¨¡åž‹")
            print("è¯·å®‰è£…TensorFlow: pip install tensorflow")
            return False

        success_count = 0
        for model_type in model_types:
            try:
                self.train_and_save_model(model_type)
                success_count += 1
            except Exception as e:
                print(f"âŒ {model_type} æ¨¡åž‹ç”Ÿæˆå¤±è´¥: {e}")

        print(f"\n{'='*60}")
        print(f"æ¨¡åž‹ç”Ÿæˆå®Œæˆ")
        print(f"æˆåŠŸ: {success_count}/{len(model_types)}")
        print(f"æ¨¡åž‹ä¿å­˜ç›®å½•: {self.models_dir}")
        print(f"{'='*60}")

        if success_count == len(model_types):
            print("ðŸŽ‰ æ‰€æœ‰æ¨¡åž‹ç”ŸæˆæˆåŠŸï¼çŽ°åœ¨å¯ä»¥é‡æ–°å¯åŠ¨FactorWeave-Quant åº”ç”¨ç¨‹åºã€‚")
            return True
        else:
            print("âš ï¸ éƒ¨åˆ†æ¨¡åž‹ç”Ÿæˆå¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯ã€‚")
            return False


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='ç”Ÿæˆ FactorWeave-Quant  AIé¢„æµ‹æ¨¡åž‹')
    parser.add_argument('--quick', action='store_true',
                        help='å¿«é€Ÿæ¨¡å¼ï¼ˆè¾ƒå°‘è®­ç»ƒè½®æ¬¡å’Œæ•°æ®ï¼‰')
    parser.add_argument('--model', choices=['pattern', 'trend', 'sentiment', 'price', 'all'],
                        default='all', help='è¦ç”Ÿæˆçš„æ¨¡åž‹ç±»åž‹')

    args = parser.parse_args()

    # é…ç½®æ—¥å¿—
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s'
    )

    print("FactorWeave-Quant  AIæ¨¡åž‹ç”Ÿæˆå™¨")
    print("=" * 60)

    # åˆ›å»ºæ¨¡åž‹ç”Ÿæˆå™¨
    generator = AIModelGenerator(quick_mode=args.quick)

    # ç”Ÿæˆæ¨¡åž‹
    if args.model == 'all':
        success = generator.generate_all_models()
    else:
        try:
            generator.train_and_save_model(args.model)
            success = True
        except Exception as e:
            print(f"æ¨¡åž‹ç”Ÿæˆå¤±è´¥: {e}")
            success = False

    if success:
        print("\nðŸŽ¯ ä¸‹ä¸€æ­¥æ“ä½œ:")
        print("1. é‡æ–°å¯åŠ¨FactorWeave-Quant åº”ç”¨ç¨‹åº")
        print("2. æ£€æŸ¥æ—¥å¿—ç¡®è®¤æ¨¡åž‹åŠ è½½æˆåŠŸ")
        print("3. æµ‹è¯•AIé¢„æµ‹åŠŸèƒ½")

    sys.exit(0 if success else 1)


if __name__ == "__main__":
    main()
