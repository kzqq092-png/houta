# TET框架下板块资金流系统融合实施方案

## 📋 方案概述

本方案基于FactorWeave-Quant系统现有的TET（Transform-Extract-Transform）框架和数据库存储架构，设计板块资金流业务的完整融合实施路径，确保新功能与现有系统的深度集成和最优性能。

## 🏗️ 系统架构融合设计

### 1. TET框架集成策略

#### 1.1 数据类型扩展
**现有DataType枚举扩展：**
- `DataType.SECTOR_FUND_FLOW_REALTIME` - 实时板块资金流
- `DataType.SECTOR_FUND_FLOW_HISTORICAL` - 历史板块资金流  
- `DataType.SECTOR_FUND_FLOW_INTRADAY` - 日内分时资金流
- `DataType.SECTOR_FUND_FLOW_SUMMARY` - 资金流汇总统计

#### 1.2 StandardQuery标准化查询扩展
**查询参数规范：**
```
StandardQuery结构：
- asset_type: AssetType.SECTOR
- data_type: DataType.SECTOR_FUND_FLOW_REALTIME
- symbol: 板块代码或"ALL"（全部板块）
- provider: 自动路由或指定数据源
- extra_params:
  - time_window: "1d"/"3d"/"5d"/"10d"/"20d"
  - fund_type: "main"/"large"/"medium"/"small"/"all"
  - sort_by: "amount"/"ratio"/"rank"
  - limit: 返回记录数限制
  - real_time: True/False（实时或历史）
```

#### 1.3 TET管道处理流程优化
**三层处理架构：**

**Transform（转换层）：**
- 原始成交数据格式标准化
- 资金性质识别和分类（主力/散户）
- 买卖方向判断逻辑
- 异常数据清洗和修正

**Extract（提取层）：**
- 多数据源智能路由选择
- 实时数据流获取和缓存
- 历史数据批量提取
- 数据质量验证和监控

**Transform（聚合层）：**
- 个股数据按板块聚合
- 多时间维度计算（1日/3日/5日等）
- 排名和分位数计算
- 趋势指标生成

### 2. 数据库存储架构设计

#### 2.1 数据存储分层策略

**热数据层（Redis/内存缓存）：**
- **用途**：实时数据缓存，高频访问
- **数据范围**：当日实时资金流数据
- **缓存策略**：LRU淘汰，5分钟过期
- **存储结构**：
  - `sector_flow:realtime:{date}` - 实时排行榜
  - `sector_flow:intraday:{sector_id}:{date}` - 分时数据
  - `sector_flow:summary:{date}` - 日度汇总

**温数据层（DuckDB分析库）：**
- **用途**：近期历史数据，分析查询
- **数据范围**：近1年的日度数据
- **表结构设计**：
  - `sector_fund_flow_daily` - 日度板块资金流
  - `sector_fund_flow_intraday` - 分时资金流明细
  - `sector_fund_flow_stats` - 统计指标汇总
- **分区策略**：按月分区，提高查询性能

**冷数据层（SQLite配置库 + 文件存储）：**
- **用途**：长期历史数据归档
- **数据范围**：1年以上的历史数据
- **存储方式**：压缩文件 + 元数据索引
- **访问模式**：按需加载，异步处理

#### 2.2 数据表设计规范

**sector_fund_flow_daily表结构：**
```
字段设计：
- trade_date: 交易日期（分区键）
- sector_id: 板块ID
- sector_name: 板块名称
- main_net_inflow_1d: 主力1日净流入金额
- main_net_inflow_3d: 主力3日净流入金额
- main_net_inflow_5d: 主力5日净流入金额
- main_net_inflow_ratio: 主力净流入占比
- total_turnover: 板块总成交金额
- stock_count: 板块内股票数量
- rise_count: 上涨股票数量
- avg_change_pct: 平均涨跌幅
- rank_by_amount: 按金额排名
- rank_by_ratio: 按占比排名
- update_time: 数据更新时间
- data_source: 数据来源标识
```

**sector_fund_flow_intraday表结构：**
```
字段设计：
- trade_date: 交易日期
- trade_time: 交易时间（分钟级）
- sector_id: 板块ID
- cumulative_inflow: 累计净流入
- interval_inflow: 区间净流入
- inflow_speed: 流入速度
- large_order_inflow: 大单净流入
- medium_order_inflow: 中单净流入
- small_order_inflow: 小单净流入
- active_degree: 活跃度指标
```

### 3. 数据源集成与路由策略

#### 3.1 数据源分层管理

**一级数据源（实时优先）：**
- **东方财富API**：实时资金流数据，更新频率1-3分钟
- **同花顺API**：准实时数据，数据质量高
- **权重配置**：东方财富(0.9) + 同花顺(0.8)

**二级数据源（历史补充）：**
- **AkShare接口**：免费历史数据，覆盖面广
- **本地数据库**：已缓存的历史数据
- **权重配置**：本地库(1.0) + AkShare(0.7)

**三级数据源（备用降级）：**
- **网页爬虫**：应急数据源
- **模拟数据**：测试和展示用途
- **权重配置**：爬虫(0.3) + 模拟(0.1)

#### 3.2 智能路由规则设计

**实时数据路由策略：**
1. **交易时段（9:30-15:00）**：
   - 优先级：东方财富API > 同花顺API > AkShare
   - 健康检查：响应时间<3秒，成功率>95%
   - 故障切换：主源失败后30秒内切换备源

2. **非交易时段**：
   - 优先级：本地缓存 > AkShare历史接口
   - 更新策略：日终批量更新 + 按需查询

**历史数据路由策略：**
1. **近期数据（30天内）**：DuckDB分析库
2. **中期数据（30天-1年）**：DuckDB + SQLite混合
3. **长期数据（1年以上）**：文件归档 + 按需加载

### 4. 实时数据处理流水线

#### 4.1 数据获取层
**实时数据源监控：**
- **健康检查**：每30秒检查数据源状态
- **数据质量监控**：检查数据完整性和时效性
- **异常处理**：自动重试机制，3次失败后切换数据源

**数据获取调度：**
- **高频获取**：交易时段每1分钟获取实时数据
- **增量更新**：只获取变化的数据，减少网络开销
- **批量处理**：非交易时段批量更新历史数据

#### 4.2 数据处理层
**实时计算引擎：**
- **流式处理**：使用内存队列处理实时数据流
- **增量计算**：基于前值进行增量计算，提高效率
- **并行处理**：多线程处理不同板块的数据

**数据标准化：**
- **格式统一**：不同数据源的数据格式标准化
- **单位换算**：金额单位统一为万元或亿元
- **时间同步**：统一时间格式和时区

#### 4.3 数据存储层
**分层存储策略：**
- **内存缓存**：最新1小时的实时数据
- **Redis缓存**：当日完整数据 + 近3日热点数据
- **DuckDB存储**：近1年的历史数据 + 统计指标
- **文件归档**：长期历史数据压缩存储

### 5. 用户界面集成方案

#### 5.1 现有UI系统集成
**数据管理中心集成：**
- 在现有数据管理UI中新增"板块资金流"标签页
- 复用现有的数据源状态监控界面
- 集成到现有的数据质量检查系统

**主窗口集成：**
- 在主界面添加板块资金流快速入口
- 支持实时数据推送和通知
- 集成到现有的主题和样式系统

#### 5.2 功能模块设计
**实时监控面板：**
- **排行榜显示**：实时板块资金流排名
- **趋势图表**：资金流入流出趋势可视化
- **异动提醒**：异常资金流动的自动预警
- **自定义筛选**：按行业、市值、涨跌幅筛选

**历史分析工具：**
- **多维度查询**：时间、板块、资金类型多维筛选
- **对比分析**：不同板块的历史表现对比
- **统计分析**：相关性分析、回归分析等
- **数据导出**：支持Excel、CSV等格式导出

### 6. 性能优化策略

#### 6.1 缓存优化
**多级缓存架构：**
- **L1缓存（内存）**：最热数据，命中率>90%
- **L2缓存（Redis）**：中等热度数据，命中率>80%
- **L3缓存（DuckDB）**：冷数据，按需加载

**缓存策略：**
- **预热策略**：系统启动时预加载热点数据
- **失效策略**：基于时间和访问频率的智能失效
- **一致性保证**：实时数据更新时的缓存同步

#### 6.2 查询优化
**数据库优化：**
- **索引策略**：在trade_date、sector_id等关键字段建立索引
- **分区优化**：按时间分区，提高查询性能
- **查询优化**：预计算常用统计指标，减少实时计算

**API优化：**
- **批量查询**：支持一次查询多个板块的数据
- **分页查询**：大数据量查询时的分页处理
- **异步处理**：耗时查询使用异步处理模式

### 7. 监控与运维方案

#### 7.1 系统监控
**数据质量监控：**
- **数据完整性**：检查数据缺失和异常值
- **数据一致性**：多数据源数据的一致性验证
- **数据时效性**：监控数据更新延迟

**性能监控：**
- **响应时间**：API响应时间监控
- **吞吐量**：数据处理能力监控
- **资源使用**：CPU、内存、磁盘使用率监控

#### 7.2 告警机制
**业务告警：**
- **数据源故障**：数据源连接失败或数据异常
- **数据延迟**：实时数据更新延迟超过阈值
- **异常波动**：资金流数据出现异常波动

**技术告警：**
- **系统故障**：服务进程异常退出
- **性能告警**：响应时间或资源使用超过阈值
- **存储告警**：磁盘空间不足或数据库连接异常

### 8. 实施路线图

#### 8.1 第一阶段（1-2周）：基础设施准备
- **数据库表结构设计和创建**
- **TET框架DataType和StandardQuery扩展**
- **基础数据源适配器开发**
- **核心缓存和存储组件集成**

#### 8.2 第二阶段（2-3周）：核心功能实现
- **实时数据获取和处理流水线**
- **历史数据批量导入和处理**
- **智能数据源路由系统**
- **数据质量监控和异常处理**

#### 8.3 第三阶段（1-2周）：用户界面集成
- **数据管理UI扩展**
- **实时监控面板开发**
- **历史分析工具集成**
- **数据导出和报表功能**

#### 8.4 第四阶段（1周）：测试和优化
- **功能测试和性能测试**
- **数据准确性验证**
- **用户界面优化**
- **文档完善和部署准备**

### 9. 风险控制与应对策略

#### 9.1 技术风险
**数据源依赖风险：**
- **风险描述**：外部数据源API变更或服务中断
- **应对策略**：多数据源备份 + 本地数据缓存 + 自动故障切换

**性能风险：**
- **风险描述**：高并发访问导致系统性能下降
- **应对策略**：负载均衡 + 缓存优化 + 异步处理

#### 9.2 业务风险
**数据质量风险：**
- **风险描述**：数据不准确影响用户决策
- **应对策略**：多源数据校验 + 数据质量监控 + 异常数据标记

**合规风险：**
- **风险描述**：数据使用不符合相关法规要求
- **应对策略**：遵循数据使用协议 + 用户免责声明 + 数据来源标注

### 10. 成功评估标准

#### 10.1 技术指标
- **数据准确性**：与权威数据源对比，准确率>95%
- **系统可用性**：服务可用率>99.5%
- **响应性能**：API响应时间<2秒，页面加载<3秒
- **数据实时性**：实时数据延迟<5分钟

#### 10.2 业务指标
- **用户满意度**：用户反馈评分>4.5/5.0
- **功能使用率**：板块资金流功能日活跃用户>70%
- **数据覆盖度**：支持主要板块覆盖率>95%
- **稳定性**：连续运行30天无重大故障

## 📊 总结

本实施方案充分利用FactorWeave-Quant系统现有的TET框架和数据库架构优势，通过标准化的接口设计、智能化的数据路由、分层化的存储策略和优化的性能方案，实现板块资金流功能与现有系统的深度融合。

**核心优势：**
- **架构统一**：完全融入现有TET框架，保持系统一致性
- **性能优越**：多级缓存和智能路由确保高性能表现
- **扩展性强**：标准化设计支持未来功能扩展
- **可维护性好**：清晰的分层架构便于维护和升级

该方案既满足了板块资金流业务的专业需求，又充分发挥了现有技术架构的优势，为FactorWeave-Quant系统的持续发展奠定了坚实基础。
