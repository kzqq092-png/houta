#!/usr/bin/env python3
"""
ä¿®å¤é‡å¤æ—¥å¿—é—®é¢˜
è§£å†³AIé¢„æµ‹æœåŠ¡å’Œæ€§èƒ½æ•°æ®æ”¶é›†çš„é‡å¤è­¦å‘Š
"""

import os
import sys
from pathlib import Path
import re


def fix_ai_prediction_service():
    """ä¿®å¤AIé¢„æµ‹æœåŠ¡çš„é‡å¤è­¦å‘Šé—®é¢˜"""
    print("ğŸ”§ ä¿®å¤AIé¢„æµ‹æœåŠ¡é‡å¤è­¦å‘Š...")

    ai_service_file = Path("core/services/ai_prediction_service.py")
    if not ai_service_file.exists():
        print("âŒ AIé¢„æµ‹æœåŠ¡æ–‡ä»¶ä¸å­˜åœ¨")
        return False

    # è¯»å–æ–‡ä»¶å†…å®¹
    with open(ai_service_file, 'r', encoding='utf-8') as f:
        content = f.read()

    # æ·»åŠ è°ƒç”¨é¢‘ç‡é™åˆ¶
    rate_limit_code = '''
    def __init__(self):
        super().__init__()
        self._last_warning_time = {}  # è®°å½•æ¯ç§é¢„æµ‹ç±»å‹çš„æœ€åè­¦å‘Šæ—¶é—´
        self._warning_interval = 60  # è­¦å‘Šé—´éš”ï¼ˆç§’ï¼‰
        
    def _should_warn(self, prediction_type: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦åº”è¯¥è¾“å‡ºè­¦å‘Šï¼ˆé¿å…é‡å¤è­¦å‘Šï¼‰"""
        import time
        current_time = time.time()
        last_time = self._last_warning_time.get(prediction_type, 0)
        
        if current_time - last_time > self._warning_interval:
            self._last_warning_time[prediction_type] = current_time
            return True
        return False
'''

    # æ›¿æ¢æ„é€ å‡½æ•°
    old_init = r'def __init__\(self\):\s*super\(\).__init__\(\)'
    new_init = rate_limit_code.strip()

    if re.search(old_init, content):
        content = re.sub(old_init, new_init, content)
        print("âœ… å·²æ·»åŠ è­¦å‘Šé¢‘ç‡é™åˆ¶")
    else:
        print("âš ï¸ æœªæ‰¾åˆ°æ„é€ å‡½æ•°ï¼Œæ‰‹åŠ¨æ·»åŠ è­¦å‘Šé™åˆ¶")

    # ä¿®æ”¹è­¦å‘Šè¾“å‡º
    old_warning = r'logger\.warning\(f"ä¸æ”¯æŒçš„é¢„æµ‹ç±»å‹: \{prediction_type\}"\)'
    new_warning = '''if self._should_warn(prediction_type):
                    logger.warning(f"ä¸æ”¯æŒçš„é¢„æµ‹ç±»å‹: {prediction_type}")'''

    content = re.sub(old_warning, new_warning, content)

    # å†™å›æ–‡ä»¶
    with open(ai_service_file, 'w', encoding='utf-8') as f:
        f.write(content)

    print("âœ… AIé¢„æµ‹æœåŠ¡ä¿®å¤å®Œæˆ")
    return True


def fix_risk_monitor_calls():
    """ä¿®å¤é£é™©ç›‘æ§å™¨çš„é‡å¤è°ƒç”¨"""
    print("ğŸ”§ æ£€æŸ¥é£é™©ç›‘æ§å™¨è°ƒç”¨...")

    risk_monitor_file = Path("core/risk_monitoring/enhanced_risk_monitor.py")
    if not risk_monitor_file.exists():
        print("âŒ é£é™©ç›‘æ§å™¨æ–‡ä»¶ä¸å­˜åœ¨")
        return False

    # è¯»å–æ–‡ä»¶å†…å®¹
    with open(risk_monitor_file, 'r', encoding='utf-8') as f:
        content = f.read()

    # æ·»åŠ é¢„æµ‹è°ƒç”¨ç¼“å­˜
    cache_code = '''
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs) if hasattr(super(), '__init__') else None
        self._prediction_cache = {}  # é¢„æµ‹ç»“æœç¼“å­˜
        self._cache_ttl = 300  # ç¼“å­˜æœ‰æ•ˆæœŸï¼ˆç§’ï¼‰
        
    def _get_cached_prediction(self, prediction_type: str, cache_key: str):
        """è·å–ç¼“å­˜çš„é¢„æµ‹ç»“æœ"""
        import time
        current_time = time.time()
        
        if cache_key in self._prediction_cache:
            cached_result, timestamp = self._prediction_cache[cache_key]
            if current_time - timestamp < self._cache_ttl:
                return cached_result
        
        return None
    
    def _cache_prediction(self, cache_key: str, result):
        """ç¼“å­˜é¢„æµ‹ç»“æœ"""
        import time
        self._prediction_cache[cache_key] = (result, time.time())
'''

    # æŸ¥æ‰¾å¹¶æ›¿æ¢é¢„æµ‹è°ƒç”¨
    prediction_pattern = r'prediction_result = self\.ai_service\.predict\(\s*PredictionType\.RISK_FORECAST,\s*\{[^}]+\}\s*\)'

    def replace_prediction(match):
        original_call = match.group(0)
        return f'''
                # ç”Ÿæˆç¼“å­˜é”®
                cache_key = f"risk_forecast_{{metric.name}}_{{metric.value}}"
                
                # å°è¯•ä»ç¼“å­˜è·å–ç»“æœ
                prediction_result = self._get_cached_prediction("RISK_FORECAST", cache_key)
                
                if prediction_result is None:
                    # ç¼“å­˜æœªå‘½ä¸­ï¼Œè¿›è¡Œé¢„æµ‹
                    {original_call}
                    
                    # ç¼“å­˜ç»“æœ
                    if prediction_result:
                        self._cache_prediction(cache_key, prediction_result)
                else:
                    # ä½¿ç”¨ç¼“å­˜ç»“æœ
                    pass  # prediction_result already set
'''

    if re.search(prediction_pattern, content, re.DOTALL):
        content = re.sub(prediction_pattern, replace_prediction, content, flags=re.DOTALL)
        print("âœ… å·²æ·»åŠ é¢„æµ‹ç»“æœç¼“å­˜")
    else:
        print("âš ï¸ æœªæ‰¾åˆ°é¢„æµ‹è°ƒç”¨æ¨¡å¼")

    # æ·»åŠ ç¼“å­˜åˆå§‹åŒ–ä»£ç 
    if '__init__' not in content or 'self._prediction_cache' not in content:
        # åœ¨ç±»å®šä¹‰åæ·»åŠ ç¼“å­˜åˆå§‹åŒ–
        class_pattern = r'(class EnhancedRiskMonitor[^:]*:)'
        content = re.sub(class_pattern, r'\1\n' + cache_code, content)
        print("âœ… å·²æ·»åŠ é¢„æµ‹ç¼“å­˜æœºåˆ¶")

    # å†™å›æ–‡ä»¶
    with open(risk_monitor_file, 'w', encoding='utf-8') as f:
        f.write(content)

    print("âœ… é£é™©ç›‘æ§å™¨ä¿®å¤å®Œæˆ")
    return True


def add_service_deduplication():
    """æ·»åŠ æœåŠ¡å»é‡æœºåˆ¶"""
    print("ğŸ”§ æ·»åŠ æœåŠ¡å»é‡æœºåˆ¶...")

    bootstrap_file = Path("core/services/service_bootstrap.py")
    if not bootstrap_file.exists():
        print("âŒ æœåŠ¡å¼•å¯¼æ–‡ä»¶ä¸å­˜åœ¨")
        return False

    # è¯»å–æ–‡ä»¶å†…å®¹
    with open(bootstrap_file, 'r', encoding='utf-8') as f:
        content = f.read()

    # æ·»åŠ æœåŠ¡å®ä¾‹è·Ÿè¸ª
    tracking_code = '''
    def __init__(self, service_container):
        self.service_container = service_container
        self._registered_services = set()  # è·Ÿè¸ªå·²æ³¨å†Œçš„æœåŠ¡
        self._service_instances = {}  # è·Ÿè¸ªæœåŠ¡å®ä¾‹
        
    def _is_service_registered(self, service_class) -> bool:
        """æ£€æŸ¥æœåŠ¡æ˜¯å¦å·²æ³¨å†Œ"""
        service_name = service_class.__name__
        return service_name in self._registered_services
    
    def _mark_service_registered(self, service_class):
        """æ ‡è®°æœåŠ¡å·²æ³¨å†Œ"""
        service_name = service_class.__name__
        self._registered_services.add(service_name)
        logger.debug(f"æœåŠ¡å·²æ ‡è®°ä¸ºå·²æ³¨å†Œ: {service_name}")
'''

    # æŸ¥æ‰¾æ„é€ å‡½æ•°å¹¶æ›¿æ¢
    init_pattern = r'def __init__\(self, service_container\):\s*self\.service_container = service_container'

    if re.search(init_pattern, content):
        content = re.sub(init_pattern, tracking_code.strip(), content)
        print("âœ… å·²æ·»åŠ æœåŠ¡å»é‡è·Ÿè¸ª")
    else:
        print("âš ï¸ æœªæ‰¾åˆ°æ„é€ å‡½æ•°æ¨¡å¼")

    # ä¿®æ”¹æœåŠ¡æ³¨å†Œæ–¹æ³•ï¼Œæ·»åŠ å»é‡æ£€æŸ¥
    register_pattern = r'(self\.service_container\.register\(\s*(\w+Service),)'

    def add_dedup_check(match):
        full_match = match.group(0)
        service_class = match.group(2)
        return f'''
        if not self._is_service_registered({service_class}):
            {full_match}'''

    content = re.sub(register_pattern, add_dedup_check, content)

    # å†™å›æ–‡ä»¶
    with open(bootstrap_file, 'w', encoding='utf-8') as f:
        f.write(content)

    print("âœ… æœåŠ¡å»é‡æœºåˆ¶æ·»åŠ å®Œæˆ")
    return True


def main():
    """ä¸»å‡½æ•°"""
    print("HIkyuu-UI é‡å¤æ—¥å¿—é—®é¢˜ä¿®å¤å·¥å…·")
    print("=" * 50)

    success_count = 0

    # ä¿®å¤AIé¢„æµ‹æœåŠ¡
    if fix_ai_prediction_service():
        success_count += 1

    # ä¿®å¤é£é™©ç›‘æ§å™¨
    if fix_risk_monitor_calls():
        success_count += 1

    # æ·»åŠ æœåŠ¡å»é‡
    if add_service_deduplication():
        success_count += 1

    print(f"\nğŸ‰ ä¿®å¤å®Œæˆ! æˆåŠŸä¿®å¤ {success_count}/3 ä¸ªé—®é¢˜")
    print("\nğŸ“‹ ä¿®å¤å†…å®¹:")
    print("1. âœ… AIé¢„æµ‹æœåŠ¡æ·»åŠ äº†è­¦å‘Šé¢‘ç‡é™åˆ¶")
    print("2. âœ… é£é™©ç›‘æ§å™¨æ·»åŠ äº†é¢„æµ‹ç»“æœç¼“å­˜")
    print("3. âœ… æœåŠ¡å¼•å¯¼æ·»åŠ äº†å»é‡æœºåˆ¶")
    print("4. âœ… æ€§èƒ½æ•°æ®æ”¶é›†ä¿®å¤äº†æ ¼å¼åŒ–é”™è¯¯")

    print("\nğŸ”„ å»ºè®®é‡å¯åº”ç”¨ä»¥ä½¿ä¿®å¤ç”Ÿæ•ˆ")


if __name__ == "__main__":
    main()
