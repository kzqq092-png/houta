#!/usr/bin/env python3
"""
é˜¶æ®µ1 æ€§èƒ½åŸºå‡†æµ‹è¯•è„šæœ¬

å¯¹æ¯” _standardize_kline_data_fields() å’Œ TETDataPipeline.transform_data() çš„æ€§èƒ½
æµ‹è¯•æ•°æ®: 10000 æ¡ K çº¿è®°å½•
"""

import sys
import os
import pandas as pd
import numpy as np
import time
import psutil
import tracemalloc
from typing import Dict, Tuple, List
from datetime import datetime, timedelta
import json
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

# å¯¼å…¥ç›¸å…³ç»„ä»¶
from core.importdata.import_execution_engine import ImportExecutionEngine
from core.tet_data_pipeline import TETDataPipeline, StandardQuery, DataType
from core.plugin_types import AssetType


class PerformanceBenchmark:
    """æ€§èƒ½åŸºå‡†æµ‹è¯•ç±»"""
    
    def __init__(self):
        """åˆå§‹åŒ–æµ‹è¯•ç¯å¢ƒ"""
        self.import_engine = ImportExecutionEngine()
        self.tet_pipeline = TETDataPipeline()
        self.results = {
            'quick_standardization': [],
            'tet_pipeline': [],
            'summary': {}
        }
        self.test_data = None
        
    def generate_test_data(self, num_records: int = 10000) -> pd.DataFrame:
        """ç”Ÿæˆæµ‹è¯•æ•°æ® - æ¨¡æ‹Ÿé€šè¾¾ä¿¡æ ¼å¼çš„Kçº¿æ•°æ®"""
        print(f"ç”Ÿæˆ {num_records} æ¡æµ‹è¯•æ•°æ®...")
        
        dates = pd.date_range('2023-01-01', periods=num_records, freq='D')
        base_price = 100.0
        
        data = pd.DataFrame({
            'Datetime': dates,
            'Open': base_price + np.random.randn(num_records) * 2,
            'High': base_price + np.random.randn(num_records) * 3,
            'Low': base_price + np.random.randn(num_records) * 2.5,
            'Close': base_price + np.random.randn(num_records) * 2,
            'Volume': np.random.randint(1000000, 10000000, num_records),
            'Amount': np.random.randint(500000000, 5000000000, num_records)
        })
        
        # ç¡®ä¿ High >= max(Open, Close) å’Œ Low <= min(Open, Close)
        data['High'] = data[['Open', 'High', 'Close']].max(axis=1) * 1.01
        data['Low'] = data[['Open', 'Low', 'Close']].min(axis=1) * 0.99
        
        self.test_data = data
        print(f"âœ“ æµ‹è¯•æ•°æ®ç”Ÿæˆå®Œæˆï¼Œå½¢çŠ¶: {data.shape}")
        return data
    
    def measure_execution_time_and_memory(self, func, *args, **kwargs) -> Tuple[float, float, float, float]:
        """æµ‹é‡å‡½æ•°æ‰§è¡Œæ—¶é—´å’Œå†…å­˜å ç”¨
        
        è¿”å›: (æ‰§è¡Œæ—¶é—´, å³°å€¼å†…å­˜, å¹³å‡å†…å­˜, CPUå ç”¨ç™¾åˆ†æ¯”)
        """
        # å¯åŠ¨å†…å­˜è¿½è¸ª
        tracemalloc.start()
        process = psutil.Process()
        
        # è®°å½•å¼€å§‹çŠ¶æ€
        start_time = time.time()
        start_memory = process.memory_info().rss / 1024 / 1024  # MB
        start_cpu = process.cpu_percent()
        
        # æ‰§è¡Œå‡½æ•°
        try:
            result = func(*args, **kwargs)
        except Exception as e:
            print(f"  âŒ æ‰§è¡Œå‡ºé”™: {e}")
            tracemalloc.stop()
            return None
        
        # è®°å½•ç»“æŸçŠ¶æ€
        end_time = time.time()
        end_memory = process.memory_info().rss / 1024 / 1024  # MB
        end_cpu = process.cpu_percent()
        
        # è·å–å†…å­˜å³°å€¼
        current, peak = tracemalloc.get_traced_memory()
        peak_memory = peak / 1024 / 1024  # MB
        tracemalloc.stop()
        
        elapsed_time = end_time - start_time
        memory_used = end_memory - start_memory
        avg_cpu = (start_cpu + end_cpu) / 2
        
        return elapsed_time, peak_memory, memory_used, avg_cpu, result
    
    def test_quick_standardization(self, iterations: int = 10):
        """æµ‹è¯•å¿«é€Ÿæ ‡å‡†åŒ–æ–¹æ³•"""
        print(f"\nã€æµ‹è¯•å¿«é€Ÿæ ‡å‡†åŒ–ã€‘è¿è¡Œ {iterations} æ¬¡...")
        
        data = self.test_data.copy()
        times = []
        peak_mems = []
        memory_used_list = []
        cpu_list = []
        
        for i in range(iterations):
            print(f"  è¿è¡Œ {i+1}/{iterations}...", end='')
            
            elapsed, peak_mem, mem_used, cpu_usage, _ = self.measure_execution_time_and_memory(
                self.import_engine._standardize_kline_data_fields,
                data.copy(),
                data_source='tongdaxin'
            )
            
            if elapsed is not None:
                times.append(elapsed)
                peak_mems.append(peak_mem)
                memory_used_list.append(mem_used)
                cpu_list.append(cpu_usage)
                print(f" âœ“ {elapsed*1000:.2f}ms, å†…å­˜: {mem_used:.2f}MB")
            else:
                print(f" âœ— æ‰§è¡Œå¤±è´¥")
        
        # è®¡ç®—ç»Ÿè®¡
        stats = {
            'iterations': len(times),
            'avg_time_ms': np.mean(times) * 1000 if times else 0,
            'min_time_ms': np.min(times) * 1000 if times else 0,
            'max_time_ms': np.max(times) * 1000 if times else 0,
            'std_time_ms': np.std(times) * 1000 if times else 0,
            'avg_peak_memory_mb': np.mean(peak_mems) if peak_mems else 0,
            'avg_memory_used_mb': np.mean(memory_used_list) if memory_used_list else 0,
            'avg_cpu_percent': np.mean(cpu_list) if cpu_list else 0
        }
        
        self.results['quick_standardization'] = stats
        print(f"âœ“ å¿«é€Ÿæ ‡å‡†åŒ–å®Œæˆ")
        print(f"  - å¹³å‡è€—æ—¶: {stats['avg_time_ms']:.2f}ms")
        print(f"  - æœ€å°è€—æ—¶: {stats['min_time_ms']:.2f}ms")
        print(f"  - æœ€å¤§è€—æ—¶: {stats['max_time_ms']:.2f}ms")
        print(f"  - å¹³å‡å†…å­˜å³°å€¼: {stats['avg_peak_memory_mb']:.2f}MB")
        print(f"  - å¹³å‡ CPU: {stats['avg_cpu_percent']:.2f}%")
        
        return stats
    
    def test_tet_pipeline(self, iterations: int = 10):
        """æµ‹è¯• TET ç®¡é“"""
        print(f"\nã€æµ‹è¯• TET ç®¡é“ã€‘è¿è¡Œ {iterations} æ¬¡...")
        
        data = self.test_data.copy()
        times = []
        peak_mems = []
        memory_used_list = []
        cpu_list = []
        
        for i in range(iterations):
            print(f"  è¿è¡Œ {i+1}/{iterations}...", end='')
            
            query = StandardQuery(
                data_type=DataType.HISTORICAL_KLINE,
                asset_type=AssetType.STOCK_A,
                provider='tongdazhin',
                period='D'
            )
            
            elapsed, peak_mem, mem_used, cpu_usage, result = self.measure_execution_time_and_memory(
                self.tet_pipeline.transform_data,
                data.copy(),
                query
            )
            
            if elapsed is not None:
                times.append(elapsed)
                peak_mems.append(peak_mem)
                memory_used_list.append(mem_used)
                cpu_list.append(cpu_usage)
                print(f" âœ“ {elapsed*1000:.2f}ms, å†…å­˜: {mem_used:.2f}MB")
            else:
                print(f" âœ— æ‰§è¡Œå¤±è´¥")
        
        # è®¡ç®—ç»Ÿè®¡
        stats = {
            'iterations': len(times),
            'avg_time_ms': np.mean(times) * 1000 if times else 0,
            'min_time_ms': np.min(times) * 1000 if times else 0,
            'max_time_ms': np.max(times) * 1000 if times else 0,
            'std_time_ms': np.std(times) * 1000 if times else 0,
            'avg_peak_memory_mb': np.mean(peak_mems) if peak_mems else 0,
            'avg_memory_used_mb': np.mean(memory_used_list) if memory_used_list else 0,
            'avg_cpu_percent': np.mean(cpu_list) if cpu_list else 0
        }
        
        self.results['tet_pipeline'] = stats
        print(f"âœ“ TET ç®¡é“æµ‹è¯•å®Œæˆ")
        print(f"  - å¹³å‡è€—æ—¶: {stats['avg_time_ms']:.2f}ms")
        print(f"  - æœ€å°è€—æ—¶: {stats['min_time_ms']:.2f}ms")
        print(f"  - æœ€å¤§è€—æ—¶: {stats['max_time_ms']:.2f}ms")
        print(f"  - å¹³å‡å†…å­˜å³°å€¼: {stats['avg_peak_memory_mb']:.2f}MB")
        print(f"  - å¹³å‡ CPU: {stats['avg_cpu_percent']:.2f}%")
        
        return stats
    
    def compare_results(self):
        """å¯¹æ¯”æµ‹è¯•ç»“æœ"""
        print("\nã€æ€§èƒ½å¯¹æ¯”ã€‘")
        
        quick = self.results['quick_standardization']
        tet = self.results['tet_pipeline']
        
        if not quick or not tet:
            print("âŒ æ²¡æœ‰å®Œæ•´çš„æµ‹è¯•ç»“æœ")
            return
        
        # è®¡ç®—æ€§èƒ½å·®å¼‚
        time_diff_percent = ((tet['avg_time_ms'] - quick['avg_time_ms']) / quick['avg_time_ms'] * 100) if quick['avg_time_ms'] > 0 else 0
        memory_diff_percent = ((tet['avg_peak_memory_mb'] - quick['avg_peak_memory_mb']) / quick['avg_peak_memory_mb'] * 100) if quick['avg_peak_memory_mb'] > 0 else 0
        
        print(f"\nã€è€—æ—¶å¯¹æ¯”ã€‘")
        print(f"å¿«é€Ÿæ ‡å‡†åŒ–: {quick['avg_time_ms']:.2f}ms (Â±{quick['std_time_ms']:.2f}ms)")
        print(f"TET ç®¡é“:   {tet['avg_time_ms']:.2f}ms (Â±{tet['std_time_ms']:.2f}ms)")
        print(f"å·®å¼‚:      {time_diff_percent:+.2f}% {'ğŸ“ˆ å˜æ…¢' if time_diff_percent > 0 else 'ğŸ“‰ å˜å¿«'}")
        
        print(f"\nã€å†…å­˜å¯¹æ¯”ã€‘")
        print(f"å¿«é€Ÿæ ‡å‡†åŒ–: {quick['avg_peak_memory_mb']:.2f}MB")
        print(f"TET ç®¡é“:   {tet['avg_peak_memory_mb']:.2f}MB")
        print(f"å·®å¼‚:      {memory_diff_percent:+.2f}%")
        
        print(f"\nã€CPU å ç”¨å¯¹æ¯”ã€‘")
        print(f"å¿«é€Ÿæ ‡å‡†åŒ–: {quick['avg_cpu_percent']:.2f}%")
        print(f"TET ç®¡é“:   {tet['avg_cpu_percent']:.2f}%")
        
        # æ¨è¿›å»ºè®®
        print(f"\nã€æ¨è¿›å»ºè®®ã€‘")
        if abs(time_diff_percent) < 10:
            print("âœ… æ€§èƒ½å·®å¼‚ < 10%ï¼Œå»ºè®®æ¨è¿›åˆ°é˜¶æ®µ2")
            self.results['summary']['recommendation'] = 'PROCEED'
        elif abs(time_diff_percent) < 15:
            print("âš ï¸  æ€§èƒ½å·®å¼‚ 10-15%ï¼Œå»ºè®®è¿›è¡Œä¼˜åŒ–åæ¨è¿›")
            self.results['summary']['recommendation'] = 'OPTIMIZE_THEN_PROCEED'
        else:
            print("âŒ æ€§èƒ½å·®å¼‚ > 15%ï¼Œå»ºè®®è¿›è¡Œæ·±å…¥ä¼˜åŒ–")
            self.results['summary']['recommendation'] = 'REQUIRES_OPTIMIZATION'
        
        self.results['summary']['time_diff_percent'] = time_diff_percent
        self.results['summary']['memory_diff_percent'] = memory_diff_percent
    
    def save_results(self, output_file: str = 'phase1_performance_benchmark_results.json'):
        """ä¿å­˜æµ‹è¯•ç»“æœ"""
        output_path = Path(__file__).parent / output_file
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(self.results, f, indent=2, ensure_ascii=False)
        
        print(f"\nâœ“ æµ‹è¯•ç»“æœå·²ä¿å­˜åˆ°: {output_path}")
    
    def run_all_tests(self):
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        print("=" * 60)
        print("Kçº¿æ•°æ®å¯¼å…¥æ€§èƒ½åŸºå‡†æµ‹è¯•")
        print("=" * 60)
        
        # ç”Ÿæˆæµ‹è¯•æ•°æ®
        self.generate_test_data(num_records=10000)
        
        # è¿è¡Œæµ‹è¯•
        self.test_quick_standardization(iterations=5)  # å…ˆåš5æ¬¡æµ‹è¯•
        self.test_tet_pipeline(iterations=5)           # å†åš5æ¬¡æµ‹è¯•
        
        # å¯¹æ¯”ç»“æœ
        self.compare_results()
        
        # ä¿å­˜ç»“æœ
        self.save_results()
        
        print("\n" + "=" * 60)
        print("æµ‹è¯•å®Œæˆï¼")
        print("=" * 60)


def main():
    """ä¸»å‡½æ•°"""
    try:
        benchmark = PerformanceBenchmark()
        benchmark.run_all_tests()
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()


if __name__ == '__main__':
    main()
