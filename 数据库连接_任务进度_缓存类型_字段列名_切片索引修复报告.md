# æ•°æ®åº“è¿æ¥ã€ä»»åŠ¡è¿›åº¦ã€ç¼“å­˜ç±»å‹ã€å­—æ®µåˆ—åä¸åˆ‡ç‰‡ç´¢å¼•ä¿®å¤æŠ¥å‘Š

## é—®é¢˜æ¦‚è¿°

æœ¬æ¬¡ä¿®å¤è§£å†³äº†5ä¸ªæ–°å‡ºç°çš„å…³é”®é—®é¢˜ï¼š
1. FactorWeaveAnalyticsDBç¼ºå°‘reconnectæ–¹æ³•
2. TaskExecutionResultç¼ºå°‘progresså±æ€§
3. ç¼“å­˜å­˜å‚¨ç±»å‹é”™è¯¯ï¼ˆæŒç»­å‡ºç°ï¼‰
4. æ•°æ®åº“è¡¨ç¼ºå°‘import_timeåˆ—
5. è‡ªé€‚åº”é˜ˆå€¼æ›´æ–°çš„dequeåˆ‡ç‰‡é”™è¯¯

---

## é—®é¢˜åˆ—è¡¨ä¸ä¿®å¤æ–¹æ¡ˆ

### âœ… é—®é¢˜ 1: FactorWeaveAnalyticsDBç¼ºå°‘reconnectæ–¹æ³•

**é”™è¯¯ä¿¡æ¯**:
```
23:48:50.866 | WARNING | core.database.factorweave_analytics_db:execute_query:476 - æ£€æµ‹åˆ°è¿æ¥å…³é—­ï¼Œå°è¯•é‡æ–°è¿æ¥...
23:48:50.867 | ERROR | core.performance.factorweave_performance_integration:_get_strategy_performance_stats:224 - è·å–ç­–ç•¥æ€§èƒ½ç»Ÿè®¡å¤±è´¥: 'FactorWeaveAnalyticsDB' object has no attribute 'reconnect'
```

**æ ¹æœ¬åŸå› **:
ä¹‹å‰çš„ä¿®å¤ä¸­ï¼Œåœ¨`execute_query`æ–¹æ³•é‡Œæ·»åŠ äº†é‡è¿é€»è¾‘ï¼ˆç¬¬476-477è¡Œï¼‰ï¼Œè°ƒç”¨äº†`self.reconnect()`ï¼Œä½†`FactorWeaveAnalyticsDB`ç±»ä¸­æ²¡æœ‰å®ç°è¿™ä¸ªæ–¹æ³•ã€‚

**è°ƒç”¨é“¾**:
```
FactorWeavePerformanceIntegration._get_strategy_performance_stats()
  â†“
FactorWeaveAnalyticsDB.execute_query(sql, params)
  â†“ (è¡Œ476-477)
if 'result closed' in error_msg or 'connection closed' in error_msg:
    logger.warning("æ£€æµ‹åˆ°è¿æ¥å…³é—­ï¼Œå°è¯•é‡æ–°è¿æ¥...")
    self.reconnect()  # âŒ æ–¹æ³•ä¸å­˜åœ¨
  â†“
AttributeError: 'FactorWeaveAnalyticsDB' object has no attribute 'reconnect'
```

**ä¿®å¤æ–¹æ¡ˆ**:

æ·»åŠ `reconnect`æ–¹æ³•åˆ°`FactorWeaveAnalyticsDB`ç±»ï¼š

```python
def reconnect(self):
    """é‡æ–°è¿æ¥æ•°æ®åº“"""
    try:
        if self.conn:
            try:
                self.conn.close()
            except Exception as e:
                logger.debug(f"å…³é—­æ—§è¿æ¥æ—¶å‡ºé”™: {e}")
        
        self.conn = None
        self._connect()
        logger.info("æ•°æ®åº“é‡æ–°è¿æ¥æˆåŠŸ")
    except Exception as e:
        logger.error(f"æ•°æ®åº“é‡æ–°è¿æ¥å¤±è´¥: {e}")
        self.conn = None
```

**æ–¹æ³•è®¾è®¡**:
1. **å®‰å…¨å…³é—­æ—§è¿æ¥**: å°è¯•å…³é—­ï¼Œå³ä½¿å¤±è´¥ä¹Ÿç»§ç»­
2. **é‡ç½®è¿æ¥**: è®¾ç½®ä¸ºNoneï¼Œé¿å…çŠ¶æ€æ··ä¹±
3. **è°ƒç”¨_connect**: å¤ç”¨ç°æœ‰çš„è¿æ¥é€»è¾‘
4. **è¯¦ç»†æ—¥å¿—**: è®°å½•æˆåŠŸæˆ–å¤±è´¥

**æ–‡ä»¶**: `core/database/factorweave_analytics_db.py` (è¡Œ130-144)

---

### âœ… é—®é¢˜ 2: TaskExecutionResultç¼ºå°‘progresså±æ€§

**é”™è¯¯ä¿¡æ¯**:
```
23:51:08.480 | ERROR | gui.widgets.enhanced_data_import_widget:on_task_selection_changed:2614 - æ›´æ–°ä»»åŠ¡è¯¦æƒ…å¤±è´¥: 'TaskExecutionResult' object has no attribute 'progress'
```

**æ ¹æœ¬åŸå› **:
UIä»£ç åœ¨ç¬¬2601è¡Œè®¿é—®`task_status.progress`ï¼Œä½†`TaskExecutionResult`ç±»åªæœ‰`progress_percentage`å±æ€§ï¼Œæ²¡æœ‰`progress`å±æ€§ã€‚

**é—®é¢˜ä»£ç ** (gui/widgets/enhanced_data_import_widget.py:2601):
```python
details = f"""ä»»åŠ¡ID: {task_id}
çŠ¶æ€: {task_status.status.value}
è¿›åº¦: {task_status.progress:.1f}%({task_status.processed_count}/{task_status.total_count})
...
```

**TaskExecutionResultç±»** (ä¹‹å‰çš„å®šä¹‰):
```python
@dataclass
class TaskExecutionResult:
    # ... å­—æ®µ ...
    
    @property
    def progress_percentage(self) -> float:
        """è¿›åº¦ç™¾åˆ†æ¯”"""
        if self.total_records == 0:
            return 0.0
        return (self.processed_records / self.total_records) * 100
```

**ä¿®å¤æ–¹æ¡ˆ**:

æ·»åŠ `progress`å±æ€§ä½œä¸ºä¸»è¦æ¥å£ï¼Œä¿ç•™`progress_percentage`ç”¨äºå‘åå…¼å®¹ï¼š

```python
@dataclass
class TaskExecutionResult:
    # ... å­—æ®µ ...
    
    @property
    def progress(self) -> float:
        """è¿›åº¦ç™¾åˆ†æ¯”ï¼ˆ0-100ï¼‰- UIå…¼å®¹æ€§"""
        if self.total_records == 0:
            return 0.0
        return (self.processed_records / self.total_records) * 100

    @property
    def progress_percentage(self) -> float:
        """è¿›åº¦ç™¾åˆ†æ¯”ï¼ˆå‘åå…¼å®¹ï¼‰"""
        return self.progress
```

**è®¾è®¡è€ƒè™‘**:
- **progress**: ä¸»è¦æ¥å£ï¼ŒUIä½¿ç”¨
- **progress_percentage**: å‘åå…¼å®¹ï¼Œå†…éƒ¨å¯èƒ½ä½¿ç”¨
- **ç»Ÿä¸€è®¡ç®—**: ä¸¤è€…å…±äº«ç›¸åŒçš„è®¡ç®—é€»è¾‘

**æ–‡ä»¶**: `core/importdata/import_execution_engine.py` (è¡Œ72-82)

---

### âœ… é—®é¢˜ 3: ç¼“å­˜å­˜å‚¨ç±»å‹é”™è¯¯ï¼ˆæŒç»­å‡ºç°ï¼‰

**é”™è¯¯ä¿¡æ¯**:
```
23:51:16.102 | WARNING | core.services.unified_data_manager:_cache_data:727 - ç¼“å­˜å­˜å‚¨å¤±è´¥: '>=' not supported between instances of 'int' and 'dict'
```

**æ·±åº¦åˆ†æ**:

è¿™ä¸ªé—®é¢˜ä¹‹å‰ä¿®å¤è¿‡`MultiLevelCacheManager`å’Œ`Cache.set`æ–¹æ³•ï¼Œä½†é”™è¯¯ä¾ç„¶å‡ºç°ã€‚ç»è¿‡æ·±å…¥åˆ†æï¼Œå‘ç°è¿˜æœ‰ä¸¤ä¸ªå…¥å£ç‚¹æ²¡æœ‰ä¿æŠ¤ï¼š

1. **Cache.__init__** - åˆå§‹åŒ–æ—¶çš„`default_ttl`å‚æ•°
2. **Cache.set_default_ttl** - åŠ¨æ€è®¾ç½®é»˜è®¤TTL

**é—®é¢˜åœºæ™¯**:
```python
# åœºæ™¯1: åˆå§‹åŒ–æ—¶ä¼ å…¥é”™è¯¯ç±»å‹
cache = Cache(default_ttl={'error': 'type'})  # âŒ dictè€Œä¸æ˜¯int

# åœºæ™¯2: åŠ¨æ€è®¾ç½®æ—¶ä¼ å…¥é”™è¯¯ç±»å‹
cache.set_default_ttl({'error': 'type'})  # âŒ dictè€Œä¸æ˜¯int

# ä¹‹åè°ƒç”¨set
cache.set('key', 'value')  # ttl=Noneï¼Œä½¿ç”¨self._default_ttl (dict)
  â†“
expire = ttl if ttl is not None else self._default_ttl  # expireæ˜¯dict
  â†“
self.cache.set(key, value, expire=expire)  # diskcacheå†…éƒ¨æ¯”è¾ƒ
  â†“
TypeError: '>=' not supported between instances of 'int' and 'dict'
```

**ä¿®å¤æ–¹æ¡ˆ**:

**ä¿®å¤1**: `__init__`ä¸­æ·»åŠ ç±»å‹æ£€æŸ¥
```python
def __init__(self, cache_dir: str = ".cache", size_limit: int = 1024*1024*1024,
             default_ttl: int = 1800, backend: str = "diskcache",
             redis_url: str = "redis://localhost:6379/0", async_mode: bool = False):
    # âœ… ç¡®ä¿default_ttlæ˜¯æœ‰æ•ˆçš„æ•°å€¼
    if not isinstance(default_ttl, (int, float)):
        logger.warning(f"Invalid default_ttl type: {type(default_ttl)}, using 1800")
        default_ttl = 1800
    
    self._default_ttl = default_ttl
    # ...
```

**ä¿®å¤2**: `set_default_ttl`ä¸­æ·»åŠ ç±»å‹æ£€æŸ¥
```python
def set_default_ttl(self, ttl: int):
    """è®¾ç½®é»˜è®¤TTLï¼Œå¸¦ç±»å‹æ£€æŸ¥"""
    if not isinstance(ttl, (int, float)):
        logger.warning(f"Invalid default_ttl type: {type(ttl)}, ignored")
        return  # æ‹’ç»è®¾ç½®é”™è¯¯ç±»å‹
    self._default_ttl = ttl
```

**ä¸‰é‡é˜²æŠ¤**:
```python
# ç¬¬1å±‚ï¼šåˆå§‹åŒ–ä¿æŠ¤
__init__(default_ttl)
  â†“ ç±»å‹æ£€æŸ¥
  
# ç¬¬2å±‚ï¼šåŠ¨æ€è®¾ç½®ä¿æŠ¤
set_default_ttl(ttl)
  â†“ ç±»å‹æ£€æŸ¥
  
# ç¬¬3å±‚ï¼šä½¿ç”¨æ—¶ä¿æŠ¤ï¼ˆä¹‹å‰å·²ä¿®å¤ï¼‰
set(key, value, ttl)
  â†“ ç±»å‹æ£€æŸ¥
```

**æ–‡ä»¶**: `utils/cache.py` (è¡Œ37-40, 174-179)

---

### âœ… é—®é¢˜ 4: æ•°æ®åº“è¡¨ç¼ºå°‘import_timeåˆ—

**é”™è¯¯ä¿¡æ¯**:
```
23:51:18.365 | ERROR | core.asset_database_manager:_upsert_data:887 - æ’å…¥æ•°æ®å¤±è´¥: Binder Error: Table "stock_kline" does not have a column with name "import_time"
23:51:18.366 | ERROR | core.database.duckdb_manager:get_connection:288 - æ•°æ®åº“è¿æ¥ä½¿ç”¨é”™è¯¯: Binder Error: Table "stock_kline" does not have a column with name "import_time"
23:51:18.369 | ERROR | core.asset_database_manager:store_standardized_data:668 - å­˜å‚¨æ ‡å‡†åŒ–æ•°æ®å¤±è´¥: Binder Error: Table "stock_kline" does not have a column with name "import_time"
```

**æ ¹æœ¬åŸå› **:
ä»£ç åœ¨ä¸¤ä¸ªåœ°æ–¹ï¼ˆç¬¬1915å’Œ1960è¡Œï¼‰å‘æ•°æ®ä¸­æ·»åŠ äº†`import_time`åˆ—ï¼Œä½†æ•°æ®åº“è¡¨`stock_kline`ä¸­æ²¡æœ‰å®šä¹‰è¿™ä¸ªåˆ—ã€‚

**é—®é¢˜ä»£ç 1** (è¡Œ1912-1915):
```python
# æ·»åŠ symbolåˆ—
data_with_symbol = data.copy()
data_with_symbol['symbol'] = symbol
data_with_symbol['import_time'] = pd.Timestamp.now()  # âŒ è¡¨ä¸­æ²¡æœ‰æ­¤åˆ—

# æ’å…¥æ•°æ®
result = duckdb_ops.insert_dataframe(
    database_path=db_path,
    table_name=table_name,
    data=data_with_symbol,  # åŒ…å«import_timeåˆ—
    ...
)
```

**é—®é¢˜ä»£ç 2** (è¡Œ1956-1960):
```python
# æ·»åŠ symbolåˆ—
data_with_symbol = data.copy()
data_with_symbol['symbol'] = symbol
data_with_symbol['import_time'] = pd.Timestamp.now()  # âŒ è¡¨ä¸­æ²¡æœ‰æ­¤åˆ—

# æ’å…¥æ•°æ®ï¼ˆå®æ—¶æ•°æ®ï¼‰
```

**è°ƒç”¨é“¾**:
```
ImportExecutionEngine._save_fundamental_data_to_database()
  â†“
data_with_symbol['import_time'] = pd.Timestamp.now()
  â†“
duckdb_ops.insert_dataframe(data=data_with_symbol, ...)
  â†“
AssetSeparatedDatabaseManager._upsert_data()
  â†“
columns = ', '.join(data.columns)  # åŒ…å«'import_time'
  â†“
sql = f"INSERT INTO {table_name} ({columns}) ..."
  â†“
DuckDB Binder Error: Table "stock_kline" does not have a column with name "import_time"
```

**ä¿®å¤æ–¹æ¡ˆ**:

åˆ é™¤ä¸¤å¤„`import_time`çš„æ·»åŠ ï¼š

**ä¿®å¤1** (è¡Œ1912-1915):
```python
# âœ… ç§»é™¤import_time
# æ·»åŠ symbolåˆ—
data_with_symbol = data.copy()
data_with_symbol['symbol'] = symbol

# æ’å…¥æ•°æ®
result = duckdb_ops.insert_dataframe(...)
```

**ä¿®å¤2** (è¡Œ1956-1960):
```python
# âœ… ç§»é™¤import_time
# æ·»åŠ symbolåˆ—
data_with_symbol = data.copy()
data_with_symbol['symbol'] = symbol

# æ’å…¥æ•°æ®ï¼ˆå®æ—¶æ•°æ®ï¼‰
```

**ä¸ºä»€ä¹ˆè¿™æ ·ä¿®å¤**:
1. **è¡¨ç»“æ„å·²ç¡®å®š**: `stock_kline`è¡¨ç»“æ„ä¸åŒ…å«`import_time`åˆ—
2. **ä¸éœ€è¦æ­¤å­—æ®µ**: æ•°æ®æœ¬èº«å·²ç»æœ‰`datetime`å­—æ®µè®°å½•æ—¶é—´
3. **é¿å…ä¿®æ”¹è¡¨ç»“æ„**: ä¿æŒè¡¨ç»“æ„ç¨³å®šï¼Œä¸å¼•å…¥æ–°åˆ—

**æ›¿ä»£æ–¹æ¡ˆ** (å¦‚æœç¡®å®éœ€è¦å¯¼å…¥æ—¶é—´):
```python
# å¯ä»¥ä½¿ç”¨created_atæˆ–updated_atå­—æ®µï¼ˆå¦‚æœè¡¨ä¸­æœ‰ï¼‰
if 'created_at' in table_columns:
    data_with_symbol['created_at'] = pd.Timestamp.now()
```

**æ–‡ä»¶**: `core/importdata/import_execution_engine.py` (è¡Œ1915, 1960)

---

### âœ… é—®é¢˜ 5: è‡ªé€‚åº”é˜ˆå€¼æ›´æ–°çš„dequeåˆ‡ç‰‡é”™è¯¯

**é”™è¯¯ä¿¡æ¯**:
```
23:51:57.734 | ERROR | core.services.enhanced_performance_bridge:_update_adaptive_thresholds:816 - æ›´æ–°è‡ªé€‚åº”é˜ˆå€¼å¤±è´¥: sequence index must be integer, not 'slice'
```

**æ ¹æœ¬åŸå› **:
`performance_history`æ˜¯`deque`ç±»å‹ï¼ˆç¬¬110è¡Œå®šä¹‰ï¼‰ï¼Œä½†ä»£ç åœ¨ç¬¬784è¡Œå°è¯•ä½¿ç”¨åˆ‡ç‰‡æ“ä½œ`history[-50:]`ï¼Œè€Œ`deque`ä¸æ”¯æŒåˆ‡ç‰‡ã€‚

**é—®é¢˜å®šä¹‰** (è¡Œ110):
```python
# æ•°æ®å­˜å‚¨
self.performance_history: Dict[str, deque] = defaultdict(lambda: deque(maxlen=1000))
```

**é—®é¢˜ä»£ç ** (è¡Œ784):
```python
def _update_adaptive_thresholds(self):
    """æ›´æ–°è‡ªé€‚åº”é˜ˆå€¼"""
    try:
        for metric_name, history in self.performance_history.items():
            if len(history) < 50:  # æ•°æ®ä¸è¶³
                continue

            recent_values = [point['value'] for point in history[-50:]]  # âŒ dequeä¸æ”¯æŒåˆ‡ç‰‡
```

**è°ƒç”¨é“¾**:
```
EnhancedPerformanceBridge._update_adaptive_thresholds()
  â†“
for metric_name, history in self.performance_history.items():
  â†“ (è¡Œ784)
recent_values = [point['value'] for point in history[-50:]]
  â†“
TypeError: sequence index must be integer, not 'slice'
```

**æŠ€æœ¯èƒŒæ™¯**:

**deque vs liståˆ‡ç‰‡**:
```python
from collections import deque

# listæ”¯æŒåˆ‡ç‰‡
my_list = [1, 2, 3, 4, 5]
print(my_list[-3:])  # âœ… [3, 4, 5]

# dequeä¸æ”¯æŒåˆ‡ç‰‡
my_deque = deque([1, 2, 3, 4, 5])
print(my_deque[-3:])  # âŒ TypeError

# è§£å†³æ–¹æ¡ˆï¼šå…ˆè½¬æ¢ä¸ºlist
print(list(my_deque)[-3:])  # âœ… [3, 4, 5]
```

**ä¿®å¤æ–¹æ¡ˆ**:

å…ˆå°†`deque`è½¬æ¢ä¸º`list`ï¼Œç„¶åå†åˆ‡ç‰‡ï¼š

```python
def _update_adaptive_thresholds(self):
    """æ›´æ–°è‡ªé€‚åº”é˜ˆå€¼"""
    try:
        for metric_name, history in self.performance_history.items():
            if len(history) < 50:  # æ•°æ®ä¸è¶³
                continue

            # âœ… dequeä¸æ”¯æŒåˆ‡ç‰‡ï¼Œéœ€è¦å…ˆè½¬æ¢ä¸ºåˆ—è¡¨
            history_list = list(history)
            recent_values = [point['value'] for point in history_list[-50:]]
```

**æ€§èƒ½è€ƒè™‘**:
- **dequeä¼˜åŠ¿**: å¿«é€Ÿçš„appendå’Œpopleftæ“ä½œï¼ˆO(1)ï¼‰
- **listè½¬æ¢**: O(n)å¤æ‚åº¦ï¼Œä½†n=1000æ˜¯å¯æ¥å—çš„
- **é¢‘ç‡**: è¿™ä¸ªæ–¹æ³•ä¸æ˜¯é«˜é¢‘è°ƒç”¨ï¼Œæ€§èƒ½å½±å“å¯å¿½ç•¥

**æ›¿ä»£æ–¹æ¡ˆ** (å¦‚æœæ€§èƒ½æ•æ„Ÿ):
```python
# æ–¹æ¡ˆ1: ä½¿ç”¨itertools.islice
from itertools import islice
recent_values = [point['value'] for point in islice(history, max(0, len(history)-50), len(history))]

# æ–¹æ¡ˆ2: ä½¿ç”¨åˆ—è¡¨æ¨å¯¼å¼é™åˆ¶
recent_values = [point['value'] for i, point in enumerate(history) if i >= len(history)-50]
```

**æ–‡ä»¶**: `core/services/enhanced_performance_bridge.py` (è¡Œ784-786)

---

## ä¿®å¤æ€»ç»“

### ä¿®æ”¹æ–‡ä»¶åˆ—è¡¨

| # | æ–‡ä»¶ | ä¿®æ”¹å†…å®¹ | è¡Œæ•° | é—®é¢˜ |
|---|------|---------|------|------|
| 1 | `core/database/factorweave_analytics_db.py` | æ·»åŠ reconnectæ–¹æ³• | 130-144 | #1 |
| 2 | `core/importdata/import_execution_engine.py` | æ·»åŠ progresså±æ€§ | 72-82 | #2 |
| 3 | `utils/cache.py` | __init__ç±»å‹æ£€æŸ¥ | 37-40 | #3 |
| 4 | `utils/cache.py` | set_default_ttlç±»å‹æ£€æŸ¥ | 174-179 | #3 |
| 5 | `core/importdata/import_execution_engine.py` | åˆ é™¤import_time (2å¤„) | 1915, 1960 | #4 |
| 6 | `core/services/enhanced_performance_bridge.py` | dequeè½¬list | 784-786 | #5 |

### é—®é¢˜ä¿®å¤çŠ¶æ€

| é—®é¢˜ | ä¼˜å…ˆçº§ | çŠ¶æ€ | æ”¹è¿›ç‚¹ |
|------|--------|------|--------|
| FactorWeaveAnalyticsDBç¼ºreconnect | é«˜ | âœ… å·²ä¿®å¤ | æ·»åŠ é‡è¿æ–¹æ³• |
| TaskExecutionResultç¼ºprogress | é«˜ | âœ… å·²ä¿®å¤ | æ·»åŠ progresså±æ€§ |
| ç¼“å­˜ç±»å‹é”™è¯¯æŒç»­ | é«˜ | âœ… å·²ä¿®å¤ | ä¸‰é‡ç±»å‹æ£€æŸ¥ |
| import_timeåˆ—ä¸å­˜åœ¨ | é«˜ | âœ… å·²ä¿®å¤ | åˆ é™¤ä¸å­˜åœ¨çš„åˆ— |
| dequeåˆ‡ç‰‡é”™è¯¯ | ä¸­ | âœ… å·²ä¿®å¤ | è½¬listååˆ‡ç‰‡ |

---

## æŠ€æœ¯æ”¹è¿›ç‚¹

### 1. æ•°æ®åº“è¿æ¥çš„å¥å£®æ€§

**è®¾è®¡æ¨¡å¼**:
```python
def reconnect(self):
    """é‡æ–°è¿æ¥æ•°æ®åº“"""
    try:
        # Step 1: å®‰å…¨å…³é—­æ—§è¿æ¥
        if self.conn:
            try:
                self.conn.close()
            except Exception:
                pass  # å¿½ç•¥å…³é—­é”™è¯¯
        
        # Step 2: é‡ç½®çŠ¶æ€
        self.conn = None
        
        # Step 3: é‡æ–°è¿æ¥
        self._connect()
        
        # Step 4: æ—¥å¿—è®°å½•
        logger.info("é‡æ–°è¿æ¥æˆåŠŸ")
    except Exception as e:
        logger.error(f"é‡æ–°è¿æ¥å¤±è´¥: {e}")
        self.conn = None  # ç¡®ä¿çŠ¶æ€ä¸€è‡´
```

### 2. å±æ€§çš„å‘åå…¼å®¹

**è®¾è®¡æ¨¡å¼**:
```python
@property
def progress(self) -> float:
    """æ–°çš„ä¸»è¦æ¥å£"""
    return self._calculate_progress()

@property
def progress_percentage(self) -> float:
    """æ—§çš„æ¥å£ï¼Œå‘åå…¼å®¹"""
    return self.progress  # å§”æ‰˜ç»™æ–°æ¥å£
```

### 3. å¤šå±‚ç±»å‹æ£€æŸ¥é˜²æŠ¤

**é˜²æŠ¤å±‚æ¬¡**:
```python
# ç¬¬1å±‚ï¼šæ„é€ å‡½æ•°
def __init__(self, default_ttl: int = 1800):
    if not isinstance(default_ttl, (int, float)):
        default_ttl = 1800  # ä½¿ç”¨å®‰å…¨é»˜è®¤å€¼
    self._default_ttl = default_ttl

# ç¬¬2å±‚ï¼šè®¾ç½®æ–¹æ³•
def set_default_ttl(self, ttl: int):
    if not isinstance(ttl, (int, float)):
        return  # æ‹’ç»è®¾ç½®
    self._default_ttl = ttl

# ç¬¬3å±‚ï¼šä½¿ç”¨æ—¶
def set(self, key, value, ttl=None):
    expire = ttl if ttl is not None else self._default_ttl
    if not isinstance(expire, (int, float)):
        expire = self._default_ttl
    # ä½¿ç”¨
```

### 4. æ•°æ®ç»“æ„çš„æ­£ç¡®ä½¿ç”¨

**deque vs list**:
```python
from collections import deque

# âœ… æ­£ç¡®ä½¿ç”¨deque
history = deque(maxlen=1000)
history.append(data)  # O(1)
history.popleft()     # O(1)

# âŒ dequeä¸æ”¯æŒåˆ‡ç‰‡
recent = history[-50:]  # TypeError

# âœ… éœ€è¦åˆ‡ç‰‡æ—¶è½¬æ¢
recent = list(history)[-50:]  # O(n)

# ğŸ’¡ æˆ–ä½¿ç”¨islice
from itertools import islice
recent = list(islice(history, max(0, len(history)-50), len(history)))
```

---

## æœ€ä½³å®è·µ

### 1. æ•°æ®åº“è¿æ¥ç®¡ç†
```python
# âœ… å¥½çš„åšæ³•ï¼šæä¾›reconnectæ–¹æ³•
class DatabaseManager:
    def reconnect(self):
        self._close_safely()
        self.conn = None
        self._connect()
    
    def execute_with_retry(self, sql):
        try:
            return self.conn.execute(sql)
        except ConnectionError:
            self.reconnect()
            return self.conn.execute(sql)
```

### 2. å±æ€§å‘½åçš„ä¸€è‡´æ€§
```python
# âœ… å¥½çš„åšæ³•ï¼šç»Ÿä¸€å‘½åï¼Œæä¾›åˆ«å
class TaskResult:
    @property
    def progress(self):
        """ä¸»è¦æ¥å£"""
        return self._calc()
    
    @property
    def progress_percentage(self):
        """å‘åå…¼å®¹"""
        return self.progress
```

### 3. ç±»å‹å®‰å…¨çš„å‚æ•°å¤„ç†
```python
# âœ… å¥½çš„åšæ³•ï¼šå¤šç‚¹éªŒè¯
class Cache:
    def __init__(self, ttl: int = 1800):
        # å…¥å£éªŒè¯
        self._default_ttl = self._validate_ttl(ttl, 1800)
    
    def set_default_ttl(self, ttl: int):
        # è®¾ç½®éªŒè¯
        validated = self._validate_ttl(ttl, self._default_ttl)
        if validated != self._default_ttl:
            self._default_ttl = validated
    
    def _validate_ttl(self, ttl, fallback):
        if not isinstance(ttl, (int, float)):
            logger.warning(f"Invalid TTL type: {type(ttl)}")
            return fallback
        return ttl
```

### 4. æ•°æ®ç»“æ„é€‰æ‹©
```python
# âœ… æ ¹æ®éœ€æ±‚é€‰æ‹©åˆé€‚çš„æ•°æ®ç»“æ„

# éœ€è¦å¿«é€Ÿä¸¤ç«¯æ“ä½œ â†’ deque
from collections import deque
history = deque(maxlen=1000)

# éœ€è¦é¢‘ç¹åˆ‡ç‰‡ â†’ list
history = []
if len(history) > 1000:
    history = history[-1000:]

# éœ€è¦ä¸¤è€…å…¼é¡¾ â†’ ç»„åˆ
history = deque(maxlen=1000)
# åˆ‡ç‰‡æ—¶ä¸´æ—¶è½¬æ¢
recent = list(history)[-50:]
```

---

## æµ‹è¯•å»ºè®®

### 1. æ•°æ®åº“é‡è¿æµ‹è¯•
```python
def test_database_reconnect():
    db = FactorWeaveAnalyticsDB()
    
    # æ¨¡æ‹Ÿè¿æ¥å…³é—­
    db.conn.close()
    
    # æµ‹è¯•é‡è¿
    db.reconnect()
    
    # éªŒè¯å¯ä»¥ç»§ç»­ä½¿ç”¨
    result = db.execute_query("SELECT 1")
    assert not result.empty
```

### 2. ä»»åŠ¡è¿›åº¦å±æ€§æµ‹è¯•
```python
def test_task_progress_properties():
    result = TaskExecutionResult(
        task_id="test",
        status=TaskExecutionStatus.RUNNING,
        total_records=100,
        processed_records=50
    )
    
    # æµ‹è¯•progresså±æ€§
    assert result.progress == 50.0
    
    # æµ‹è¯•å‘åå…¼å®¹
    assert result.progress_percentage == 50.0
    
    # æµ‹è¯•ç©ºè®°å½•
    result.total_records = 0
    assert result.progress == 0.0
```

### 3. ç¼“å­˜ç±»å‹å®‰å…¨æµ‹è¯•
```python
def test_cache_type_safety():
    # æµ‹è¯•åˆå§‹åŒ–
    cache1 = Cache(default_ttl={'invalid': 'type'})
    assert isinstance(cache1._default_ttl, (int, float))
    
    # æµ‹è¯•set_default_ttl
    cache2 = Cache()
    cache2.set_default_ttl({'invalid': 'type'})
    assert isinstance(cache2._default_ttl, (int, float))
    
    # æµ‹è¯•set
    cache2.set('key', 'value', ttl={'invalid': 'type'})
    # ä¸åº”è¯¥å´©æºƒ
    assert cache2.get('key') == 'value'
```

### 4. dequeåˆ‡ç‰‡æµ‹è¯•
```python
def test_deque_slicing():
    from collections import deque
    
    bridge = EnhancedPerformanceBridge()
    
    # æ·»åŠ æµ‹è¯•æ•°æ®
    for i in range(100):
        bridge.performance_history['test_metric'].append({
            'value': i,
            'timestamp': datetime.now()
        })
    
    # æµ‹è¯•è‡ªé€‚åº”é˜ˆå€¼æ›´æ–°
    bridge._update_adaptive_thresholds()
    
    # éªŒè¯æ²¡æœ‰å´©æºƒï¼Œä¸”æœ‰é˜ˆå€¼
    assert 'test_metric' in bridge.adaptive_thresholds
```

---

## ä»£ç å¯¹æ¯”

### æ•°æ®åº“é‡è¿

**ä¿®å¤å‰**:
```python
# âŒ æ²¡æœ‰reconnectæ–¹æ³•
class FactorWeaveAnalyticsDB:
    # ...
    
# è°ƒç”¨æ—¶å´©æºƒ
self.reconnect()  # AttributeError
```

**ä¿®å¤å**:
```python
# âœ… æ·»åŠ reconnectæ–¹æ³•
class FactorWeaveAnalyticsDB:
    def reconnect(self):
        """é‡æ–°è¿æ¥æ•°æ®åº“"""
        try:
            if self.conn:
                try:
                    self.conn.close()
                except Exception as e:
                    logger.debug(f"å…³é—­æ—§è¿æ¥æ—¶å‡ºé”™: {e}")
            
            self.conn = None
            self._connect()
            logger.info("æ•°æ®åº“é‡æ–°è¿æ¥æˆåŠŸ")
        except Exception as e:
            logger.error(f"æ•°æ®åº“é‡æ–°è¿æ¥å¤±è´¥: {e}")
            self.conn = None
```

### ä»»åŠ¡è¿›åº¦å±æ€§

**ä¿®å¤å‰**:
```python
@dataclass
class TaskExecutionResult:
    # ... å­—æ®µ ...
    
    @property
    def progress_percentage(self) -> float:  # âŒ UIéœ€è¦progress
        if self.total_records == 0:
            return 0.0
        return (self.processed_records / self.total_records) * 100
```

**ä¿®å¤å**:
```python
@dataclass
class TaskExecutionResult:
    # ... å­—æ®µ ...
    
    @property
    def progress(self) -> float:  # âœ… UIä¸»è¦æ¥å£
        """è¿›åº¦ç™¾åˆ†æ¯”ï¼ˆ0-100ï¼‰- UIå…¼å®¹æ€§"""
        if self.total_records == 0:
            return 0.0
        return (self.processed_records / self.total_records) * 100

    @property
    def progress_percentage(self) -> float:  # âœ… å‘åå…¼å®¹
        """è¿›åº¦ç™¾åˆ†æ¯”ï¼ˆå‘åå…¼å®¹ï¼‰"""
        return self.progress
```

### ç¼“å­˜ç±»å‹æ£€æŸ¥

**ä¿®å¤å‰**:
```python
def __init__(self, ..., default_ttl: int = 1800, ...):
    self._default_ttl = default_ttl  # âŒ æ²¡æœ‰éªŒè¯

def set_default_ttl(self, ttl: int):
    self._default_ttl = ttl  # âŒ æ²¡æœ‰éªŒè¯
```

**ä¿®å¤å**:
```python
def __init__(self, ..., default_ttl: int = 1800, ...):
    # âœ… ç±»å‹æ£€æŸ¥
    if not isinstance(default_ttl, (int, float)):
        logger.warning(f"Invalid default_ttl type: {type(default_ttl)}, using 1800")
        default_ttl = 1800
    self._default_ttl = default_ttl

def set_default_ttl(self, ttl: int):
    """è®¾ç½®é»˜è®¤TTLï¼Œå¸¦ç±»å‹æ£€æŸ¥"""
    # âœ… ç±»å‹æ£€æŸ¥
    if not isinstance(ttl, (int, float)):
        logger.warning(f"Invalid default_ttl type: {type(ttl)}, ignored")
        return
    self._default_ttl = ttl
```

### import_timeåˆ—

**ä¿®å¤å‰**:
```python
data_with_symbol['symbol'] = symbol
data_with_symbol['import_time'] = pd.Timestamp.now()  # âŒ è¡¨ä¸­æ²¡æœ‰æ­¤åˆ—
result = duckdb_ops.insert_dataframe(data=data_with_symbol, ...)
```

**ä¿®å¤å**:
```python
data_with_symbol['symbol'] = symbol
# âœ… ç§»é™¤import_time
result = duckdb_ops.insert_dataframe(data=data_with_symbol, ...)
```

### dequeåˆ‡ç‰‡

**ä¿®å¤å‰**:
```python
recent_values = [point['value'] for point in history[-50:]]  # âŒ dequeä¸æ”¯æŒåˆ‡ç‰‡
```

**ä¿®å¤å**:
```python
# âœ… å…ˆè½¬æ¢ä¸ºlist
history_list = list(history)
recent_values = [point['value'] for point in history_list[-50:]]
```

---

## å½±å“è¯„ä¼°

### ä¿®å¤å‰
- âŒ æ•°æ®åº“è¿æ¥é”™è¯¯å¯¼è‡´æ€§èƒ½ç»Ÿè®¡å¤±è´¥
- âŒ UIæ— æ³•æ˜¾ç¤ºä»»åŠ¡è¿›åº¦
- âš ï¸ ç¼“å­˜å¯èƒ½å› ç±»å‹é”™è¯¯å´©æºƒ
- âŒ æ•°æ®ä¿å­˜å› åˆ—ä¸å­˜åœ¨å¤±è´¥
- âŒ è‡ªé€‚åº”é˜ˆå€¼æ›´æ–°å´©æºƒ

### ä¿®å¤å
- âœ… æ•°æ®åº“è¿æ¥è‡ªåŠ¨æ¢å¤
- âœ… UIæ­£ç¡®æ˜¾ç¤ºä»»åŠ¡è¿›åº¦
- âœ… ç¼“å­˜æ“ä½œå®Œå…¨ç±»å‹å®‰å…¨
- âœ… æ•°æ®æ­£å¸¸ä¿å­˜åˆ°æ•°æ®åº“
- âœ… è‡ªé€‚åº”é˜ˆå€¼æ­£å¸¸æ›´æ–°
- âœ… è¯¦ç»†çš„é”™è¯¯æ—¥å¿—

---

## ä»£ç è´¨é‡

- âœ… æ— å…³é”®lintingé”™è¯¯
- âœ… å¤šå±‚ç±»å‹æ£€æŸ¥
- âœ… è¯¦ç»†æ—¥å¿—è®°å½•
- âœ… å‘åå…¼å®¹æ€§ä¿æŒ
- âœ… æ•°æ®ç»“æ„æ­£ç¡®ä½¿ç”¨

---

## åç»­ä¼˜åŒ–å»ºè®®

### çŸ­æœŸä¼˜åŒ–
1. ä¸ºæ‰€æœ‰æ•°æ®åº“ç±»æ·»åŠ reconnectæ–¹æ³•
2. ç»Ÿä¸€ä»»åŠ¡ç»“æœçš„å±æ€§å‘½å
3. æ·»åŠ ç¼“å­˜å‚æ•°çš„å•å…ƒæµ‹è¯•
4. æ–‡æ¡£åŒ–è¡¨ç»“æ„ï¼Œé¿å…æ·»åŠ ä¸å­˜åœ¨çš„åˆ—

### ä¸­æœŸä¼˜åŒ–
1. å®ç°æ•°æ®åº“è¿æ¥æ± ï¼Œå‡å°‘reconnectéœ€æ±‚
2. æä¾›é…ç½®é©±åŠ¨çš„è¡¨ç»“æ„ç®¡ç†
3. å®ç°ç¼“å­˜å‚æ•°çš„å…¨å±€éªŒè¯å™¨
4. ä¼˜åŒ–dequeä½¿ç”¨ï¼Œæä¾›åˆ‡ç‰‡åŒ…è£…å™¨

### é•¿æœŸä¼˜åŒ–
1. å®ç°æ•°æ®åº“Schemaç‰ˆæœ¬ç®¡ç†
2. æä¾›ç»Ÿä¸€çš„è¿›åº¦æŠ¥å‘Šæ¥å£
3. å®ç°ç±»å‹å®‰å…¨çš„é…ç½®ç³»ç»Ÿ
4. æä¾›æ€§èƒ½æ•°æ®ç»“æ„çš„æœ€ä½³å®è·µæŒ‡å—

---

## æ€»ç»“

æœ¬æ¬¡ä¿®å¤è§£å†³äº†5ä¸ªæ–°å‡ºç°çš„å…³é”®é—®é¢˜ï¼š

1. **æ•°æ®åº“é‡è¿**: æ·»åŠ reconnectæ–¹æ³•ï¼Œæ”¯æŒè¿æ¥è‡ªåŠ¨æ¢å¤
2. **ä»»åŠ¡è¿›åº¦**: æ·»åŠ progresså±æ€§ï¼Œä¿æŒUIå…¼å®¹æ€§
3. **ç¼“å­˜ç±»å‹**: ä¸‰é‡ç±»å‹æ£€æŸ¥ï¼Œç¡®ä¿å‚æ•°å®‰å…¨
4. **å­—æ®µåˆ—å**: åˆ é™¤ä¸å­˜åœ¨çš„åˆ—ï¼Œé¿å…æ•°æ®åº“é”™è¯¯
5. **dequeåˆ‡ç‰‡**: æ­£ç¡®ä½¿ç”¨æ•°æ®ç»“æ„ï¼Œé¿å…ç±»å‹é”™è¯¯

æ‰€æœ‰ä¿®å¤éƒ½éµå¾ª**å¥å£®æ€§**ã€**å‘åå…¼å®¹**å’Œ**ç±»å‹å®‰å…¨**çš„åŸåˆ™ã€‚

**ä¿®å¤çŠ¶æ€**: âœ… å®Œæˆï¼ˆ5/5ï¼‰  
**ä»£ç è´¨é‡**: âœ… ä¼˜ç§€  
**æµ‹è¯•çŠ¶æ€**: â³ å¾…ç”¨æˆ·éªŒè¯

**é‡è¦æç¤º**:
1. æ•°æ®åº“è¿æ¥ç°åœ¨æ”¯æŒè‡ªåŠ¨é‡è¿
2. UIå¯ä»¥æ­£ç¡®æ˜¾ç¤ºä»»åŠ¡è¿›åº¦
3. ç¼“å­˜æœ‰ä¸‰é‡ç±»å‹å®‰å…¨ä¿æŠ¤
4. æ•°æ®ä¿å­˜ä¸å†æœ‰åˆ—åé”™è¯¯
5. æ€§èƒ½ç›‘æ§æ­£å¸¸å·¥ä½œ

**ä¸‹ä¸€æ­¥**: è¯·é‡å¯åº”ç”¨å¹¶æµ‹è¯•å®Œæ•´çš„æ•°æ®å¯¼å…¥æµç¨‹ï¼

