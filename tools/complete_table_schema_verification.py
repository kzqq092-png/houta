#!/usr/bin/env python3
"""
å®Œæ•´è¡¨ç»“æ„éªŒè¯æµ‹è¯•è„šæœ¬

éªŒè¯æ‰€æœ‰11ç§è¡¨ç±»å‹çš„å®Œæ•´Schemaå®šä¹‰å’Œè‡ªåŠ¨åˆ›å»ºåŠŸèƒ½
æµ‹è¯•TETæ¡†æ¶ä¸è¡¨ç®¡ç†ç³»ç»Ÿçš„å®Œæ•´æ•´åˆ

ä½œè€…: FactorWeave-Quantå›¢é˜Ÿ
æ—¥æœŸ: 2024-01-XX
"""

import sys
import os
import pandas as pd
from datetime import datetime, timedelta
from pathlib import Path
import json

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from loguru import logger
from core.database.table_manager import (
    TableType, TableSchemaRegistry, DynamicTableManager
)
from core.database.data_source_separated_storage import DataSourceSeparatedStorageManager
from core.plugin_types import AssetType


class CompleteTableSchemaVerifier:
    """å®Œæ•´è¡¨ç»“æ„éªŒè¯å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–éªŒè¯å™¨"""
        self.schema_registry = TableSchemaRegistry()
        self.table_manager = DynamicTableManager()
        self.storage_manager = DataSourceSeparatedStorageManager()
        self.test_results = {}
        
        logger.info("ğŸš€ å®Œæ•´è¡¨ç»“æ„éªŒè¯å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def verify_all_table_schemas(self):
        """éªŒè¯æ‰€æœ‰è¡¨ç»“æ„å®šä¹‰"""
        logger.info("ğŸ“‹ å¼€å§‹éªŒè¯æ‰€æœ‰è¡¨ç»“æ„å®šä¹‰...")
        
        all_table_types = [
            TableType.STOCK_BASIC_INFO,
            TableType.KLINE_DATA,
            TableType.FINANCIAL_STATEMENT,
            TableType.MACRO_ECONOMIC,
            TableType.REAL_TIME_QUOTE,
            TableType.MARKET_DEPTH,
            TableType.TRADE_TICK,
            TableType.NEWS,
            TableType.ANNOUNCEMENT,
            TableType.FUND_FLOW,
            TableType.TECHNICAL_INDICATOR
        ]
        
        schema_results = {}
        
        for table_type in all_table_types:
            logger.info(f"éªŒè¯è¡¨ç±»å‹: {table_type.value}")
            
            # éªŒè¯Schemaæ˜¯å¦å­˜åœ¨
            schema = self.schema_registry.get_schema(table_type)
            if schema is None:
                schema_results[table_type.value] = {
                    'status': 'FAILED',
                    'error': 'Schemaå®šä¹‰ä¸å­˜åœ¨'
                }
                logger.error(f"âŒ {table_type.value}: Schemaå®šä¹‰ç¼ºå¤±")
                continue
            
            # éªŒè¯SchemaåŸºæœ¬å±æ€§
            validation_result = self._validate_schema_structure(schema, table_type)
            schema_results[table_type.value] = validation_result
            
            if validation_result['status'] == 'SUCCESS':
                logger.success(f"âœ… {table_type.value}: SchemaéªŒè¯é€šè¿‡")
            else:
                logger.error(f"âŒ {table_type.value}: {validation_result['error']}")
        
        self.test_results['schema_validation'] = schema_results
        return schema_results
    
    def _validate_schema_structure(self, schema, table_type):
        """éªŒè¯Schemaç»“æ„çš„å®Œæ•´æ€§"""
        try:
            # æ£€æŸ¥å¿…è¦å­—æ®µ
            required_fields = ['data_source', 'created_at', 'data_quality_score']
            missing_fields = []
            
            for field in required_fields:
                if field not in schema.columns:
                    missing_fields.append(field)
            
            if missing_fields:
                return {
                    'status': 'FAILED',
                    'error': f'ç¼ºå°‘å¿…è¦å­—æ®µ: {missing_fields}'
                }
            
            # æ£€æŸ¥ä¸»é”®å®šä¹‰
            if not schema.primary_key:
                return {
                    'status': 'FAILED',
                    'error': 'ç¼ºå°‘ä¸»é”®å®šä¹‰'
                }
            
            # æ£€æŸ¥ç´¢å¼•å®šä¹‰
            if not schema.indexes:
                return {
                    'status': 'FAILED',
                    'error': 'ç¼ºå°‘ç´¢å¼•å®šä¹‰'
                }
            
            return {
                'status': 'SUCCESS',
                'columns_count': len(schema.columns),
                'primary_key': schema.primary_key,
                'indexes_count': len(schema.indexes),
                'has_partitions': schema.partitions is not None
            }
            
        except Exception as e:
            return {
                'status': 'FAILED',
                'error': f'éªŒè¯è¿‡ç¨‹å¼‚å¸¸: {str(e)}'
            }
    
    def test_table_name_generation(self):
        """æµ‹è¯•è¡¨åç”ŸæˆåŠŸèƒ½"""
        logger.info("ğŸ·ï¸ å¼€å§‹æµ‹è¯•è¡¨åç”ŸæˆåŠŸèƒ½...")
        
        test_plugin = "examples.test_plugin"
        name_generation_results = {}
        
        all_table_types = [
            TableType.STOCK_BASIC_INFO,
            TableType.KLINE_DATA,
            TableType.FINANCIAL_STATEMENT,
            TableType.MACRO_ECONOMIC,
            TableType.REAL_TIME_QUOTE,
            TableType.MARKET_DEPTH,
            TableType.TRADE_TICK,
            TableType.NEWS,
            TableType.ANNOUNCEMENT,
            TableType.FUND_FLOW,
            TableType.TECHNICAL_INDICATOR
        ]
        
        for table_type in all_table_types:
            try:
                # æµ‹è¯•åŸºæœ¬è¡¨åç”Ÿæˆ
                table_name = self.table_manager.generate_table_name(
                    table_type=table_type,
                    plugin_name=test_plugin
                )
                
                # æµ‹è¯•å¸¦å‘¨æœŸçš„è¡¨åç”Ÿæˆ
                table_name_with_period = self.table_manager.generate_table_name(
                    table_type=table_type,
                    plugin_name=test_plugin,
                    period="daily"
                )
                
                name_generation_results[table_type.value] = {
                    'status': 'SUCCESS',
                    'basic_name': table_name,
                    'period_name': table_name_with_period
                }
                
                logger.success(f"âœ… {table_type.value}: è¡¨åç”ŸæˆæˆåŠŸ")
                logger.info(f"   åŸºæœ¬è¡¨å: {table_name}")
                logger.info(f"   å‘¨æœŸè¡¨å: {table_name_with_period}")
                
            except Exception as e:
                name_generation_results[table_type.value] = {
                    'status': 'FAILED',
                    'error': str(e)
                }
                logger.error(f"âŒ {table_type.value}: è¡¨åç”Ÿæˆå¤±è´¥ - {e}")
        
        self.test_results['name_generation'] = name_generation_results
        return name_generation_results
    
    def test_auto_table_creation(self):
        """æµ‹è¯•è‡ªåŠ¨è¡¨åˆ›å»ºåŠŸèƒ½"""
        logger.info("ğŸ”¨ å¼€å§‹æµ‹è¯•è‡ªåŠ¨è¡¨åˆ›å»ºåŠŸèƒ½...")
        
        test_plugin = "examples.complete_test_plugin"
        creation_results = {}
        
        # æµ‹è¯•å…³é”®è¡¨ç±»å‹çš„è‡ªåŠ¨åˆ›å»º
        key_table_types = [
            (TableType.KLINE_DATA, "daily"),
            (TableType.REAL_TIME_QUOTE, None),
            (TableType.MARKET_DEPTH, None),
            (TableType.TRADE_TICK, "minute"),
            (TableType.NEWS, None),
            (TableType.ANNOUNCEMENT, None),
            (TableType.FUND_FLOW, "daily"),
            (TableType.TECHNICAL_INDICATOR, "daily")
        ]
        
        for table_type, period in key_table_types:
            try:
                logger.info(f"æµ‹è¯•åˆ›å»ºè¡¨: {table_type.value}")
                
                # æµ‹è¯•è‡ªåŠ¨åˆ›å»ºè¡¨å’Œç´¢å¼•
                table_name = self.storage_manager._auto_create_table_and_indexes(
                    plugin_id=test_plugin,
                    table_type=table_type,
                    period=period,
                    config=self.storage_manager._get_storage_config(test_plugin)
                )
                
                if table_name:
                    creation_results[f"{table_type.value}_{period or 'default'}"] = {
                        'status': 'SUCCESS',
                        'table_name': table_name
                    }
                    logger.success(f"âœ… {table_type.value}: è¡¨åˆ›å»ºæˆåŠŸ - {table_name}")
                else:
                    creation_results[f"{table_type.value}_{period or 'default'}"] = {
                        'status': 'FAILED',
                        'error': 'è¡¨åˆ›å»ºè¿”å›None'
                    }
                    logger.error(f"âŒ {table_type.value}: è¡¨åˆ›å»ºå¤±è´¥")
                    
            except Exception as e:
                creation_results[f"{table_type.value}_{period or 'default'}"] = {
                    'status': 'FAILED',
                    'error': str(e)
                }
                logger.error(f"âŒ {table_type.value}: è¡¨åˆ›å»ºå¼‚å¸¸ - {e}")
        
        self.test_results['table_creation'] = creation_results
        return creation_results
    
    def test_data_insertion(self):
        """æµ‹è¯•æ•°æ®æ’å…¥åŠŸèƒ½"""
        logger.info("ğŸ’¾ å¼€å§‹æµ‹è¯•æ•°æ®æ’å…¥åŠŸèƒ½...")
        
        test_plugin = "examples.complete_test_plugin"
        insertion_results = {}
        
        # æµ‹è¯•ä¸åŒç±»å‹çš„æ•°æ®æ’å…¥
        test_cases = [
            {
                'table_type': TableType.KLINE_DATA,
                'data': self._generate_kline_test_data(),
                'period': 'daily'
            },
            {
                'table_type': TableType.REAL_TIME_QUOTE,
                'data': self._generate_realtime_quote_test_data(),
                'period': None
            },
            {
                'table_type': TableType.FUND_FLOW,
                'data': self._generate_fund_flow_test_data(),
                'period': 'daily'
            }
        ]
        
        for test_case in test_cases:
            table_type = test_case['table_type']
            data = test_case['data']
            period = test_case['period']
            
            try:
                logger.info(f"æµ‹è¯•æ’å…¥æ•°æ®: {table_type.value}")
                
                # ä¿å­˜æ•°æ®
                success = self.storage_manager.save_data_to_source(
                    plugin_id=test_plugin,
                    table_type=table_type,
                    data=data,
                    period=period
                )
                
                if success:
                    insertion_results[f"{table_type.value}_{period or 'default'}"] = {
                        'status': 'SUCCESS',
                        'rows_inserted': len(data)
                    }
                    logger.success(f"âœ… {table_type.value}: æ•°æ®æ’å…¥æˆåŠŸ - {len(data)}è¡Œ")
                else:
                    insertion_results[f"{table_type.value}_{period or 'default'}"] = {
                        'status': 'FAILED',
                        'error': 'æ•°æ®æ’å…¥è¿”å›False'
                    }
                    logger.error(f"âŒ {table_type.value}: æ•°æ®æ’å…¥å¤±è´¥")
                    
            except Exception as e:
                insertion_results[f"{table_type.value}_{period or 'default'}"] = {
                    'status': 'FAILED',
                    'error': str(e)
                }
                logger.error(f"âŒ {table_type.value}: æ•°æ®æ’å…¥å¼‚å¸¸ - {e}")
        
        self.test_results['data_insertion'] = insertion_results
        return insertion_results
    
    def _generate_kline_test_data(self):
        """ç”ŸæˆKçº¿æµ‹è¯•æ•°æ®"""
        base_time = datetime.now() - timedelta(days=5)
        data = []
        
        for i in range(5):
            data.append({
                'symbol': 'TEST001',
                'datetime': base_time + timedelta(days=i),
                'open': 10.0 + i * 0.1,
                'high': 10.5 + i * 0.1,
                'low': 9.5 + i * 0.1,
                'close': 10.2 + i * 0.1,
                'volume': 1000000 + i * 10000,
                'amount': 10000000 + i * 100000
            })
        
        return pd.DataFrame(data)
    
    def _generate_realtime_quote_test_data(self):
        """ç”Ÿæˆå®æ—¶è¡Œæƒ…æµ‹è¯•æ•°æ®"""
        base_time = datetime.now()
        data = []
        
        for i in range(3):
            data.append({
                'symbol': 'TEST001',
                'datetime': base_time + timedelta(minutes=i),
                'price': 10.5 + i * 0.01,
                'volume': 100000 + i * 1000,
                'amount': 1000000 + i * 10000,
                'change': i * 0.01,
                'change_percent': i * 0.1,
                'market_status': 'trading'
            })
        
        return pd.DataFrame(data)
    
    def _generate_fund_flow_test_data(self):
        """ç”Ÿæˆèµ„é‡‘æµæµ‹è¯•æ•°æ®"""
        base_time = datetime.now() - timedelta(days=3)
        data = []
        
        for i in range(3):
            data.append({
                'symbol': 'TEST001',
                'datetime': base_time + timedelta(days=i),
                'period': 'daily',
                'main_inflow': 1000000 + i * 100000,
                'main_outflow': 800000 + i * 50000,
                'main_net_inflow': 200000 + i * 50000,
                'net_inflow': 150000 + i * 30000
            })
        
        return pd.DataFrame(data)
    
    def run_complete_verification(self):
        """è¿è¡Œå®Œæ•´éªŒè¯æµç¨‹"""
        logger.info("ğŸ¯ å¼€å§‹è¿è¡Œå®Œæ•´è¡¨ç»“æ„éªŒè¯æµç¨‹...")
        
        # 1. éªŒè¯Schemaå®šä¹‰
        schema_results = self.verify_all_table_schemas()
        
        # 2. æµ‹è¯•è¡¨åç”Ÿæˆ
        name_results = self.test_table_name_generation()
        
        # 3. æµ‹è¯•è‡ªåŠ¨è¡¨åˆ›å»º
        creation_results = self.test_auto_table_creation()
        
        # 4. æµ‹è¯•æ•°æ®æ’å…¥
        insertion_results = self.test_data_insertion()
        
        # 5. ç”Ÿæˆç»¼åˆæŠ¥å‘Š
        self._generate_final_report()
        
        return self.test_results
    
    def _generate_final_report(self):
        """ç”Ÿæˆæœ€ç»ˆéªŒè¯æŠ¥å‘Š"""
        logger.info("ğŸ“Š ç”ŸæˆéªŒè¯æŠ¥å‘Š...")
        
        # ç»Ÿè®¡æˆåŠŸç‡
        schema_success = sum(1 for r in self.test_results['schema_validation'].values() if r['status'] == 'SUCCESS')
        schema_total = len(self.test_results['schema_validation'])
        
        name_success = sum(1 for r in self.test_results['name_generation'].values() if r['status'] == 'SUCCESS')
        name_total = len(self.test_results['name_generation'])
        
        creation_success = sum(1 for r in self.test_results['table_creation'].values() if r['status'] == 'SUCCESS')
        creation_total = len(self.test_results['table_creation'])
        
        insertion_success = sum(1 for r in self.test_results['data_insertion'].values() if r['status'] == 'SUCCESS')
        insertion_total = len(self.test_results['data_insertion'])
        
        # è¾“å‡ºæŠ¥å‘Š
        logger.info("="*60)
        logger.info("ğŸ‰ å®Œæ•´è¡¨ç»“æ„éªŒè¯æŠ¥å‘Š")
        logger.info("="*60)
        logger.info(f"ğŸ“‹ SchemaéªŒè¯: {schema_success}/{schema_total} æˆåŠŸ ({schema_success/schema_total*100:.1f}%)")
        logger.info(f"ğŸ·ï¸ è¡¨åç”Ÿæˆ: {name_success}/{name_total} æˆåŠŸ ({name_success/name_total*100:.1f}%)")
        logger.info(f"ğŸ”¨ è¡¨åˆ›å»º: {creation_success}/{creation_total} æˆåŠŸ ({creation_success/creation_total*100:.1f}%)")
        logger.info(f"ğŸ’¾ æ•°æ®æ’å…¥: {insertion_success}/{insertion_total} æˆåŠŸ ({insertion_success/insertion_total*100:.1f}%)")
        
        total_success = schema_success + name_success + creation_success + insertion_success
        total_tests = schema_total + name_total + creation_total + insertion_total
        overall_success_rate = total_success / total_tests * 100
        
        logger.info("="*60)
        logger.info(f"ğŸ¯ æ€»ä½“æˆåŠŸç‡: {total_success}/{total_tests} ({overall_success_rate:.1f}%)")
        
        if overall_success_rate >= 90:
            logger.success("ğŸ‰ éªŒè¯é€šè¿‡ï¼TETæ¡†æ¶è¡¨ç®¡ç†ç³»ç»Ÿè¿è¡Œæ­£å¸¸")
        elif overall_success_rate >= 70:
            logger.warning("âš ï¸ éªŒè¯éƒ¨åˆ†é€šè¿‡ï¼Œå­˜åœ¨ä¸€äº›é—®é¢˜éœ€è¦å…³æ³¨")
        else:
            logger.error("âŒ éªŒè¯å¤±è´¥ï¼Œå­˜åœ¨ä¸¥é‡é—®é¢˜éœ€è¦ä¿®å¤")
        
        # ä¿å­˜è¯¦ç»†æŠ¥å‘Š
        self._save_detailed_report()
    
    def _save_detailed_report(self):
        """ä¿å­˜è¯¦ç»†æŠ¥å‘Šåˆ°æ–‡ä»¶"""
        report_data = {
            'timestamp': datetime.now().isoformat(),
            'test_results': self.test_results,
            'summary': {
                'total_table_types': 11,
                'schema_definitions_complete': True,
                'auto_creation_supported': True,
                'data_insertion_supported': True
            }
        }
        
        report_path = project_root / f"complete_table_verification_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(report_data, f, ensure_ascii=False, indent=2, default=str)
        
        logger.info(f"ğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_path}")


def main():
    """ä¸»å‡½æ•°"""
    try:
        logger.info("å¯åŠ¨å®Œæ•´è¡¨ç»“æ„éªŒè¯æµ‹è¯•...")
        
        # åˆ›å»ºéªŒè¯å™¨å¹¶è¿è¡Œæµ‹è¯•
        verifier = CompleteTableSchemaVerifier()
        results = verifier.run_complete_verification()
        
        logger.info("éªŒè¯æµ‹è¯•å®Œæˆï¼")
        
    except Exception as e:
        logger.error(f"éªŒè¯æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        logger.error(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
        return 1
    
    return 0


if __name__ == "__main__":
    exit(main())
