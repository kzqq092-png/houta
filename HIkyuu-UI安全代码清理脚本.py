#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
HIkyuu-UIå®‰å…¨ä»£ç æ¸…ç†è„šæœ¬

åœ¨ç»Ÿä¸€æ¶æ„æ”¹é€ å®Œæˆåï¼Œå®‰å…¨æ¸…ç†ä¸å†éœ€è¦çš„é—ç•™ä»£ç å’Œä¸´æ—¶æ–‡ä»¶ã€‚
åŒ…å«å¤‡ä»½æœºåˆ¶ã€ä¾èµ–æ£€æŸ¥å’Œå›æ»šåŠŸèƒ½ã€‚

ä½œè€…: FactorWeave-Quantå›¢é˜Ÿ
ç‰ˆæœ¬: 1.0
æ—¥æœŸ: 2024-09-17
"""

import sys
import os
import shutil
import json
import traceback
from datetime import datetime
from typing import Dict, List, Any, Optional, Set
from pathlib import Path
from loguru import logger

# é…ç½®æ—¥å¿—
logger.remove()
logger.add(sys.stdout, format="<green>{time:YYYY-MM-DD HH:mm:ss}</green> | <level>{level: <8}</level> | <cyan>{name}</cyan>:<cyan>{function}</cyan>:<cyan>{line}</cyan> - <level>{message}</level>")

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°ç³»ç»Ÿè·¯å¾„
project_root = os.path.dirname(os.path.abspath(__file__))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

class SafeCodeCleaner:
    """å®‰å…¨ä»£ç æ¸…ç†å™¨"""
    
    def __init__(self, project_root: str):
        self.project_root = Path(project_root)
        self.backup_dir = self.project_root / "cleanup_backup" / datetime.now().strftime("%Y%m%d_%H%M%S")
        self.cleanup_log = []
        self.dependency_map = {}
        
        # æ¸…ç†é…ç½®
        self.cleanup_config = {
            "safe_to_delete": {
                "description": "å¯ä»¥å®‰å…¨åˆ é™¤çš„æ–‡ä»¶",
                "files": [
                    "comprehensive_architecture_test.py",
                    "comprehensive_ui_system_test.py",
                    "adjusted_architecture_test.py", 
                    "validate_ui_components.py",
                    "verify_data_router.py",
                    "verify_data_standardization_engine.py",
                    "simple_ui_test.py",
                    "simple_test.py",
                    "simple_verification.py",
                    "verify_asset_aware_data_manager.py",
                    "verify_week1_implementation.py",
                    "tools/test_table_creation.py",
                    "tools/complete_table_schema_verification.py"
                ]
            },
            "mark_deprecated": {
                "description": "éœ€è¦æ ‡è®°ä¸ºåºŸå¼ƒçš„æ–‡ä»¶",
                "files": [
                    "core/data_source.py",
                    "core/eastmoney_source.py", 
                    "core/sina_source.py",
                    "core/tonghuashun_source.py",
                    "core/akshare_data_source.py"
                ]
            },
            "backup_only": {
                "description": "ä»…å¤‡ä»½ä½†ä¿ç•™çš„é‡è¦æ–‡ä»¶",
                "files": [
                    "core/services/legacy_datasource_adapter.py",
                    "core/services/unified_data_manager.py"
                ]
            },
            "cleanup_directories": {
                "description": "éœ€è¦æ¸…ç†çš„ç›®å½•",
                "dirs": [
                    "backup",
                    "backups", 
                    "__pycache__",
                    "*.pyc"
                ]
            }
        }
    
    def create_backup(self) -> bool:
        """åˆ›å»ºæ¸…ç†å‰çš„å®Œæ•´å¤‡ä»½"""
        logger.info("ğŸ”„ åˆ›å»ºæ¸…ç†å‰çš„å®Œæ•´å¤‡ä»½...")
        
        try:
            # åˆ›å»ºå¤‡ä»½ç›®å½•
            self.backup_dir.mkdir(parents=True, exist_ok=True)
            
            # å¤‡ä»½æ‰€æœ‰å°†è¦å¤„ç†çš„æ–‡ä»¶
            all_files = (
                self.cleanup_config["safe_to_delete"]["files"] + 
                self.cleanup_config["mark_deprecated"]["files"] +
                self.cleanup_config["backup_only"]["files"]
            )
            
            backed_up_count = 0
            for file_path in all_files:
                source_file = self.project_root / file_path
                if source_file.exists():
                    # åˆ›å»ºå¤‡ä»½æ–‡ä»¶çš„ç›®å½•ç»“æ„
                    backup_file = self.backup_dir / file_path
                    backup_file.parent.mkdir(parents=True, exist_ok=True)
                    
                    # å¤åˆ¶æ–‡ä»¶
                    shutil.copy2(source_file, backup_file)
                    backed_up_count += 1
                    logger.debug(f"å¤‡ä»½æ–‡ä»¶: {file_path}")
            
            # åˆ›å»ºå¤‡ä»½æ¸…å•
            backup_manifest = {
                "backup_time": datetime.now().isoformat(),
                "project_root": str(self.project_root),
                "backup_dir": str(self.backup_dir),
                "files_backed_up": backed_up_count,
                "cleanup_config": self.cleanup_config
            }
            
            with open(self.backup_dir / "backup_manifest.json", "w", encoding="utf-8") as f:
                json.dump(backup_manifest, f, indent=2, ensure_ascii=False)
            
            logger.success(f"âœ… å¤‡ä»½å®Œæˆï¼Œå…±å¤‡ä»½ {backed_up_count} ä¸ªæ–‡ä»¶åˆ°: {self.backup_dir}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ å¤‡ä»½å¤±è´¥: {e}")
            return False
    
    def analyze_dependencies(self) -> Dict[str, Set[str]]:
        """åˆ†ææ–‡ä»¶ä¾èµ–å…³ç³»"""
        logger.info("ğŸ” åˆ†ææ–‡ä»¶ä¾èµ–å…³ç³»...")
        
        dependency_map = {}
        
        # æ‰«ææ‰€æœ‰Pythonæ–‡ä»¶
        for py_file in self.project_root.rglob("*.py"):
            if py_file.is_file():
                try:
                    with open(py_file, "r", encoding="utf-8") as f:
                        content = f.read()
                    
                    # æŸ¥æ‰¾å¯¼å…¥è¯­å¥
                    imports = set()
                    for line in content.split("\n"):
                        line = line.strip()
                        if line.startswith("from ") or line.startswith("import "):
                            imports.add(line)
                    
                    relative_path = str(py_file.relative_to(self.project_root))
                    dependency_map[relative_path] = imports
                    
                except Exception as e:
                    logger.debug(f"åˆ†ææ–‡ä»¶ä¾èµ–å¤±è´¥: {py_file}, {e}")
        
        self.dependency_map = dependency_map
        logger.success(f"âœ… ä¾èµ–åˆ†æå®Œæˆï¼Œåˆ†æäº† {len(dependency_map)} ä¸ªæ–‡ä»¶")
        return dependency_map
    
    def check_file_usage(self, file_path: str) -> List[str]:
        """æ£€æŸ¥æ–‡ä»¶æ˜¯å¦è¢«å…¶ä»–æ–‡ä»¶ä½¿ç”¨"""
        file_stem = Path(file_path).stem
        usage_files = []
        
        for file, imports in self.dependency_map.items():
            for import_line in imports:
                if file_stem in import_line or file_path.replace("/", ".") in import_line:
                    usage_files.append(file)
        
        return usage_files
    
    def safe_delete_files(self) -> bool:
        """å®‰å…¨åˆ é™¤æ–‡ä»¶"""
        logger.info("ğŸ—‘ï¸  å¼€å§‹å®‰å…¨åˆ é™¤æ–‡ä»¶...")
        
        deleted_count = 0
        skipped_count = 0
        
        for file_path in self.cleanup_config["safe_to_delete"]["files"]:
            source_file = self.project_root / file_path
            
            if not source_file.exists():
                logger.debug(f"æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡: {file_path}")
                continue
            
            # æ£€æŸ¥æ–‡ä»¶ä½¿ç”¨æƒ…å†µ
            usage_files = self.check_file_usage(file_path)
            if usage_files:
                logger.warning(f"âš ï¸  æ–‡ä»¶ {file_path} è¢«ä»¥ä¸‹æ–‡ä»¶ä½¿ç”¨ï¼Œè·³è¿‡åˆ é™¤:")
                for usage_file in usage_files[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ª
                    logger.warning(f"    - {usage_file}")
                if len(usage_files) > 3:
                    logger.warning(f"    - ... è¿˜æœ‰ {len(usage_files) - 3} ä¸ªæ–‡ä»¶")
                skipped_count += 1
                continue
            
            try:
                # åˆ é™¤æ–‡ä»¶
                source_file.unlink()
                deleted_count += 1
                logger.info(f"âœ… å·²åˆ é™¤: {file_path}")
                
                self.cleanup_log.append({
                    "action": "deleted",
                    "file": file_path,
                    "timestamp": datetime.now().isoformat()
                })
                
            except Exception as e:
                logger.error(f"âŒ åˆ é™¤å¤±è´¥: {file_path}, {e}")
                skipped_count += 1
        
        logger.success(f"âœ… æ–‡ä»¶åˆ é™¤å®Œæˆï¼Œåˆ é™¤ {deleted_count} ä¸ªï¼Œè·³è¿‡ {skipped_count} ä¸ª")
        return True
    
    def mark_deprecated_files(self) -> bool:
        """æ ‡è®°æ–‡ä»¶ä¸ºåºŸå¼ƒ"""
        logger.info("ğŸ·ï¸  æ ‡è®°åºŸå¼ƒæ–‡ä»¶...")
        
        deprecated_header = '''"""
âš ï¸  DEPRECATED: This file is deprecated and will be removed in future versions.
âš ï¸  åºŸå¼ƒè­¦å‘Š: æ­¤æ–‡ä»¶å·²åºŸå¼ƒï¼Œå°†åœ¨æœªæ¥ç‰ˆæœ¬ä¸­ç§»é™¤ã€‚

Please use the new plugin-based architecture instead:
è¯·ä½¿ç”¨æ–°çš„åŸºäºæ’ä»¶çš„æ¶æ„:
- UniPluginDataManager for unified data access
- IDataSourcePlugin for data source implementations  
- Standard plugin templates in plugins/templates/

Migration date: {migration_date}
Reason: Replaced by unified plugin architecture
"""

'''
        
        marked_count = 0
        
        for file_path in self.cleanup_config["mark_deprecated"]["files"]:
            source_file = self.project_root / file_path
            
            if not source_file.exists():
                logger.debug(f"æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡: {file_path}")
                continue
            
            try:
                # è¯»å–åŸæ–‡ä»¶å†…å®¹
                with open(source_file, "r", encoding="utf-8") as f:
                    content = f.read()
                
                # æ£€æŸ¥æ˜¯å¦å·²ç»æ ‡è®°
                if "DEPRECATED" in content:
                    logger.debug(f"æ–‡ä»¶å·²æ ‡è®°ä¸ºåºŸå¼ƒï¼Œè·³è¿‡: {file_path}")
                    continue
                
                # æ·»åŠ åºŸå¼ƒæ ‡è®°
                deprecated_notice = deprecated_header.format(
                    migration_date=datetime.now().strftime("%Y-%m-%d")
                )
                
                # åœ¨æ–‡ä»¶å¼€å¤´æ·»åŠ åºŸå¼ƒæ ‡è®°
                new_content = deprecated_notice + content
                
                # å†™å›æ–‡ä»¶
                with open(source_file, "w", encoding="utf-8") as f:
                    f.write(new_content)
                
                marked_count += 1
                logger.info(f"âœ… å·²æ ‡è®°ä¸ºåºŸå¼ƒ: {file_path}")
                
                self.cleanup_log.append({
                    "action": "marked_deprecated",
                    "file": file_path,
                    "timestamp": datetime.now().isoformat()
                })
                
            except Exception as e:
                logger.error(f"âŒ æ ‡è®°åºŸå¼ƒå¤±è´¥: {file_path}, {e}")
        
        logger.success(f"âœ… åºŸå¼ƒæ ‡è®°å®Œæˆï¼Œæ ‡è®°äº† {marked_count} ä¸ªæ–‡ä»¶")
        return True
    
    def cleanup_cache_files(self) -> bool:
        """æ¸…ç†ç¼“å­˜æ–‡ä»¶"""
        logger.info("ğŸ§¹ æ¸…ç†ç¼“å­˜æ–‡ä»¶...")
        
        cleaned_count = 0
        
        # æ¸…ç†__pycache__ç›®å½•
        for pycache_dir in self.project_root.rglob("__pycache__"):
            if pycache_dir.is_dir():
                try:
                    shutil.rmtree(pycache_dir)
                    cleaned_count += 1
                    logger.debug(f"åˆ é™¤ç¼“å­˜ç›®å½•: {pycache_dir.relative_to(self.project_root)}")
                except Exception as e:
                    logger.warning(f"åˆ é™¤ç¼“å­˜ç›®å½•å¤±è´¥: {pycache_dir}, {e}")
        
        # æ¸…ç†.pycæ–‡ä»¶
        for pyc_file in self.project_root.rglob("*.pyc"):
            try:
                pyc_file.unlink()
                cleaned_count += 1
                logger.debug(f"åˆ é™¤ç¼“å­˜æ–‡ä»¶: {pyc_file.relative_to(self.project_root)}")
            except Exception as e:
                logger.warning(f"åˆ é™¤ç¼“å­˜æ–‡ä»¶å¤±è´¥: {pyc_file}, {e}")
        
        logger.success(f"âœ… ç¼“å­˜æ¸…ç†å®Œæˆï¼Œæ¸…ç†äº† {cleaned_count} ä¸ªé¡¹ç›®")
        return True
    
    def generate_cleanup_report(self) -> str:
        """ç”Ÿæˆæ¸…ç†æŠ¥å‘Š"""
        report = []
        report.append("=" * 80)
        report.append("HIkyuu-UIä»£ç æ¸…ç†æŠ¥å‘Š")
        report.append("=" * 80)
        report.append(f"æ¸…ç†æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report.append(f"é¡¹ç›®è·¯å¾„: {self.project_root}")
        report.append(f"å¤‡ä»½è·¯å¾„: {self.backup_dir}")
        report.append("")
        
        # ç»Ÿè®¡æ¸…ç†ç»“æœ
        deleted_files = [log for log in self.cleanup_log if log["action"] == "deleted"]
        deprecated_files = [log for log in self.cleanup_log if log["action"] == "marked_deprecated"]
        
        report.append("ğŸ“Š æ¸…ç†ç»Ÿè®¡:")
        report.append(f"  â€¢ åˆ é™¤æ–‡ä»¶æ•°: {len(deleted_files)}")
        report.append(f"  â€¢ æ ‡è®°åºŸå¼ƒæ•°: {len(deprecated_files)}")
        report.append(f"  â€¢ åˆ†ææ–‡ä»¶æ•°: {len(self.dependency_map)}")
        report.append("")
        
        # è¯¦ç»†æ¸…ç†æ—¥å¿—
        if deleted_files:
            report.append("ğŸ—‘ï¸  å·²åˆ é™¤æ–‡ä»¶:")
            for log in deleted_files:
                report.append(f"  âœ… {log['file']}")
            report.append("")
        
        if deprecated_files:
            report.append("ğŸ·ï¸  å·²æ ‡è®°åºŸå¼ƒ:")
            for log in deprecated_files:
                report.append(f"  âš ï¸  {log['file']}")
            report.append("")
        
        # å›æ»šè¯´æ˜
        report.append("ğŸ”„ å›æ»šè¯´æ˜:")
        report.append(f"  å¦‚éœ€å›æ»šï¼Œè¯·æ‰§è¡Œä»¥ä¸‹å‘½ä»¤:")
        report.append(f"  python HIkyuu-UIå®‰å…¨ä»£ç æ¸…ç†è„šæœ¬.py --rollback {self.backup_dir}")
        report.append("")
        
        # å»ºè®®
        report.append("ğŸ’¡ åç»­å»ºè®®:")
        report.append("  1. è¿è¡Œå®Œæ•´æµ‹è¯•å¥—ä»¶éªŒè¯ç³»ç»ŸåŠŸèƒ½")
        report.append("  2. æ£€æŸ¥æ˜¯å¦æœ‰æ–°çš„ç¼–è¯‘æˆ–å¯¼å…¥é”™è¯¯")
        report.append("  3. æ›´æ–°ç›¸å…³æ–‡æ¡£å’Œè¯´æ˜")
        report.append("  4. å¦‚å‘ç°é—®é¢˜ï¼Œå¯ä½¿ç”¨å¤‡ä»½è¿›è¡Œå›æ»š")
        report.append("")
        
        report.append("=" * 80)
        
        return "\n".join(report)
    
    def rollback(self, backup_path: str) -> bool:
        """ä»å¤‡ä»½å›æ»š"""
        logger.info(f"ğŸ”„ å¼€å§‹ä»å¤‡ä»½å›æ»š: {backup_path}")
        
        backup_dir = Path(backup_path)
        if not backup_dir.exists():
            logger.error(f"âŒ å¤‡ä»½ç›®å½•ä¸å­˜åœ¨: {backup_path}")
            return False
        
        # è¯»å–å¤‡ä»½æ¸…å•
        manifest_file = backup_dir / "backup_manifest.json"
        if not manifest_file.exists():
            logger.error("âŒ å¤‡ä»½æ¸…å•æ–‡ä»¶ä¸å­˜åœ¨")
            return False
        
        try:
            with open(manifest_file, "r", encoding="utf-8") as f:
                manifest = json.load(f)
            
            restored_count = 0
            
            # æ¢å¤æ‰€æœ‰å¤‡ä»½æ–‡ä»¶
            for backup_file in backup_dir.rglob("*"):
                if backup_file.is_file() and backup_file.name != "backup_manifest.json":
                    relative_path = backup_file.relative_to(backup_dir)
                    target_file = self.project_root / relative_path
                    
                    # åˆ›å»ºç›®æ ‡ç›®å½•
                    target_file.parent.mkdir(parents=True, exist_ok=True)
                    
                    # æ¢å¤æ–‡ä»¶
                    shutil.copy2(backup_file, target_file)
                    restored_count += 1
                    logger.debug(f"æ¢å¤æ–‡ä»¶: {relative_path}")
            
            logger.success(f"âœ… å›æ»šå®Œæˆï¼Œæ¢å¤äº† {restored_count} ä¸ªæ–‡ä»¶")
            return True
            
        except Exception as e:
            logger.error(f"âŒ å›æ»šå¤±è´¥: {e}")
            return False
    
    def run_cleanup(self, dry_run: bool = False) -> bool:
        """è¿è¡Œå®Œæ•´æ¸…ç†æµç¨‹"""
        logger.info("ğŸš€ å¼€å§‹HIkyuu-UIä»£ç æ¸…ç†...")
        
        if dry_run:
            logger.info("ğŸ” è¿è¡Œæ¨¡å¼: é¢„è§ˆæ¨¡å¼ (ä¸ä¼šå®é™…ä¿®æ”¹æ–‡ä»¶)")
        
        try:
            # 1. åˆ†æä¾èµ–å…³ç³»
            self.analyze_dependencies()
            
            # 2. åˆ›å»ºå¤‡ä»½
            if not dry_run and not self.create_backup():
                return False
            
            # 3. å®‰å…¨åˆ é™¤æ–‡ä»¶
            if not dry_run:
                self.safe_delete_files()
            else:
                logger.info("ğŸ” é¢„è§ˆ: å°†åˆ é™¤ä»¥ä¸‹æ–‡ä»¶:")
                for file_path in self.cleanup_config["safe_to_delete"]["files"]:
                    if (self.project_root / file_path).exists():
                        usage_files = self.check_file_usage(file_path)
                        if usage_files:
                            logger.info(f"  âš ï¸  {file_path} (è¢« {len(usage_files)} ä¸ªæ–‡ä»¶ä½¿ç”¨)")
                        else:
                            logger.info(f"  âœ… {file_path}")
            
            # 4. æ ‡è®°åºŸå¼ƒæ–‡ä»¶
            if not dry_run:
                self.mark_deprecated_files()
            else:
                logger.info("ğŸ” é¢„è§ˆ: å°†æ ‡è®°ä»¥ä¸‹æ–‡ä»¶ä¸ºåºŸå¼ƒ:")
                for file_path in self.cleanup_config["mark_deprecated"]["files"]:
                    if (self.project_root / file_path).exists():
                        logger.info(f"  ğŸ·ï¸  {file_path}")
            
            # 5. æ¸…ç†ç¼“å­˜æ–‡ä»¶
            if not dry_run:
                self.cleanup_cache_files()
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ æ¸…ç†å¤±è´¥: {e}")
            logger.error(traceback.format_exc())
            return False

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description="HIkyuu-UIå®‰å…¨ä»£ç æ¸…ç†è„šæœ¬")
    parser.add_argument("--dry-run", action="store_true", help="é¢„è§ˆæ¨¡å¼ï¼Œä¸å®é™…ä¿®æ”¹æ–‡ä»¶")
    parser.add_argument("--rollback", type=str, help="ä»æŒ‡å®šå¤‡ä»½è·¯å¾„å›æ»š")
    parser.add_argument("--project-root", type=str, default=".", help="é¡¹ç›®æ ¹ç›®å½•")
    
    args = parser.parse_args()
    
    project_root = os.path.abspath(args.project_root)
    logger.info(f"ğŸš€ å¯åŠ¨HIkyuu-UIå®‰å…¨ä»£ç æ¸…ç†è„šæœ¬...")
    logger.info(f"ğŸ“ é¡¹ç›®è·¯å¾„: {project_root}")
    
    cleaner = SafeCodeCleaner(project_root)
    
    try:
        if args.rollback:
            # å›æ»šæ¨¡å¼
            success = cleaner.rollback(args.rollback)
            if success:
                logger.success("ğŸ‰ å›æ»šæˆåŠŸï¼")
                return 0
            else:
                logger.error("âŒ å›æ»šå¤±è´¥ï¼")
                return 1
        else:
            # æ¸…ç†æ¨¡å¼
            success = cleaner.run_cleanup(dry_run=args.dry_run)
            
            if success and not args.dry_run:
                # ç”Ÿæˆå¹¶ä¿å­˜æŠ¥å‘Š
                report = cleaner.generate_cleanup_report()
                logger.info("\n" + report)
                
                report_file = f"HIkyuu-UIä»£ç æ¸…ç†æŠ¥å‘Š_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
                with open(report_file, 'w', encoding='utf-8') as f:
                    f.write(report)
                
                logger.info(f"ğŸ“„ æ¸…ç†æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")
                logger.success("ğŸ‰ ä»£ç æ¸…ç†å®Œæˆï¼")
                return 0
            elif success and args.dry_run:
                logger.success("ğŸ‰ é¢„è§ˆå®Œæˆï¼ä½¿ç”¨ --dry-run=false æ‰§è¡Œå®é™…æ¸…ç†")
                return 0
            else:
                logger.error("âŒ æ¸…ç†å¤±è´¥ï¼")
                return 1
    
    except Exception as e:
        logger.error(f"âŒ è„šæœ¬æ‰§è¡Œå¤±è´¥: {e}")
        logger.error(traceback.format_exc())
        return 1

if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)
