# 板块资金流历史数据库存储方案

## 📋 方案概述

基于FactorWeave-Quant系统现有的DuckDB、SQLite数据库架构，设计板块资金流历史数据的完整存储、维护和查询解决方案，实现高效的数据管理和快速查询能力。

## 🏗️ 数据库架构设计

### 1. 分层存储策略

#### 1.1 热数据层（Redis + 内存）
**存储范围：** 当日实时数据 + 近3日热点数据
**存储目的：** 高频查询，秒级响应
**数据结构：**
```
Key格式：
- sector_flow_rank:{date} → 当日板块排行榜
- sector_flow_detail:{sector_id}:{date} → 单板块详细数据
- sector_flow_intraday:{sector_id}:{date} → 分时数据

TTL策略：
- 实时数据：5分钟
- 当日数据：24小时
- 近期数据：72小时
```

#### 1.2 温数据层（DuckDB分析库）
**存储范围：** 近2年的完整历史数据
**存储目的：** 分析查询，OLAP操作
**表结构设计：**

**主表：sector_fund_flow_daily**
```sql
CREATE TABLE sector_fund_flow_daily (
    trade_date DATE NOT NULL,                    -- 交易日期（分区键）
    sector_id VARCHAR(20) NOT NULL,              -- 板块ID
    sector_name VARCHAR(100) NOT NULL,           -- 板块名称
    sector_code VARCHAR(20),                     -- 板块代码
    
    -- 主力资金流向数据
    main_net_inflow_1d DECIMAL(18,2),            -- 1日主力净流入（万元）
    main_net_inflow_3d DECIMAL(18,2),            -- 3日主力净流入（万元）
    main_net_inflow_5d DECIMAL(18,2),            -- 5日主力净流入（万元）
    main_net_inflow_10d DECIMAL(18,2),           -- 10日主力净流入（万元）
    main_net_inflow_20d DECIMAL(18,2),           -- 20日主力净流入（万元）
    
    -- 资金流入占比
    main_net_inflow_ratio DECIMAL(8,4),          -- 主力净流入占比（%）
    retail_net_inflow DECIMAL(18,2),             -- 散户净流入（万元）
    retail_net_inflow_ratio DECIMAL(8,4),        -- 散户净流入占比（%）
    
    -- 成交数据
    total_turnover DECIMAL(18,2),                -- 板块总成交金额（万元）
    total_volume BIGINT,                         -- 板块总成交量（手）
    avg_price DECIMAL(10,3),                     -- 平均成交价格
    
    -- 股票统计
    stock_count INTEGER,                         -- 板块内股票数量
    rise_count INTEGER,                          -- 上涨股票数量
    fall_count INTEGER,                          -- 下跌股票数量
    flat_count INTEGER,                          -- 平盘股票数量
    
    -- 价格变动
    avg_change_pct DECIMAL(8,4),                 -- 平均涨跌幅（%）
    max_change_pct DECIMAL(8,4),                 -- 最大涨跌幅（%）
    min_change_pct DECIMAL(8,4),                 -- 最小涨跌幅（%）
    
    -- 排名数据
    rank_by_amount INTEGER,                      -- 按金额排名
    rank_by_ratio INTEGER,                       -- 按占比排名
    rank_by_change INTEGER,                      -- 按涨跌幅排名
    
    -- 技术指标
    momentum_score DECIMAL(8,4),                 -- 动量评分
    strength_index DECIMAL(8,4),                 -- 强度指数
    activity_level DECIMAL(8,4),                 -- 活跃度指标
    
    -- 元数据
    data_source VARCHAR(50),                     -- 数据来源
    data_quality_score DECIMAL(4,3),             -- 数据质量评分
    update_time TIMESTAMP,                       -- 更新时间
    create_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    
    PRIMARY KEY (trade_date, sector_id)
);

-- 分区策略：按月分区
CREATE TABLE sector_fund_flow_daily PARTITION BY RANGE (trade_date);
```

**分时数据表：sector_fund_flow_intraday**
```sql
CREATE TABLE sector_fund_flow_intraday (
    trade_date DATE NOT NULL,                    -- 交易日期
    trade_time TIME NOT NULL,                    -- 交易时间（分钟级）
    sector_id VARCHAR(20) NOT NULL,              -- 板块ID
    
    -- 累计数据
    cumulative_main_inflow DECIMAL(18,2),        -- 累计主力净流入
    cumulative_retail_inflow DECIMAL(18,2),      -- 累计散户净流入
    cumulative_turnover DECIMAL(18,2),           -- 累计成交金额
    
    -- 区间数据（相对于前一时间点）
    interval_main_inflow DECIMAL(18,2),          -- 区间主力净流入
    interval_retail_inflow DECIMAL(18,2),        -- 区间散户净流入
    interval_turnover DECIMAL(18,2),             -- 区间成交金额
    
    -- 流速指标
    main_inflow_speed DECIMAL(12,4),             -- 主力流入速度（万元/分钟）
    retail_inflow_speed DECIMAL(12,4),           -- 散户流入速度（万元/分钟）
    
    -- 活跃度指标
    active_degree DECIMAL(8,4),                  -- 活跃度指标
    volatility INDEX DECIMAL(8,4),               -- 波动率指数
    
    -- 元数据
    data_source VARCHAR(50),
    update_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    
    PRIMARY KEY (trade_date, trade_time, sector_id)
);

-- 索引优化
CREATE INDEX idx_intraday_sector_date ON sector_fund_flow_intraday(sector_id, trade_date);
CREATE INDEX idx_intraday_time ON sector_fund_flow_intraday(trade_time);
```

**汇总统计表：sector_fund_flow_stats**
```sql
CREATE TABLE sector_fund_flow_stats (
    stat_date DATE NOT NULL,                     -- 统计日期
    stat_type VARCHAR(20) NOT NULL,              -- 统计类型（daily/weekly/monthly）
    
    -- 市场整体统计
    total_sectors INTEGER,                       -- 总板块数量
    rising_sectors INTEGER,                      -- 上涨板块数量
    falling_sectors INTEGER,                     -- 下跌板块数量
    
    -- 资金流统计
    total_main_inflow DECIMAL(20,2),             -- 总主力净流入
    total_retail_inflow DECIMAL(20,2),           -- 总散户净流入
    net_inflow_ratio DECIMAL(8,4),               -- 净流入比例
    
    -- TOP统计
    top_inflow_sector_id VARCHAR(20),            -- 最大流入板块
    top_inflow_amount DECIMAL(18,2),             -- 最大流入金额
    top_outflow_sector_id VARCHAR(20),           -- 最大流出板块
    top_outflow_amount DECIMAL(18,2),            -- 最大流出金额
    
    -- 分布统计
    large_inflow_count INTEGER,                  -- 大额流入板块数（>1亿）
    medium_inflow_count INTEGER,                 -- 中等流入板块数（1000万-1亿）
    small_inflow_count INTEGER,                  -- 小额流入板块数（<1000万）
    
    create_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    
    PRIMARY KEY (stat_date, stat_type)
);
```

#### 1.3 冷数据层（SQLite + 文件存储）
**存储范围：** 2年以上的历史数据
**存储目的：** 长期归档，按需查询
**存储策略：**
- 按年度压缩存储
- 元数据索引
- 异步加载机制

### 2. 数据写入流水线

#### 2.1 实时数据写入流程
```
数据流水线：
原始数据获取 → 数据清洗标准化 → 实时计算聚合 → 多层写入
    ↓
1. 写入Redis缓存（实时查询）
2. 写入DuckDB温数据（当日汇总）
3. 异步写入SQLite（历史归档）
```

#### 2.2 批量历史数据导入
```
批量导入流程：
1. 数据源历史数据拉取
2. 数据质量检查和清洗
3. 重复数据检测和去重
4. 分批写入DuckDB（避免锁表）
5. 索引重建和统计信息更新
```

### 3. 查询优化策略

#### 3.1 索引设计
```sql
-- 主要查询索引
CREATE INDEX idx_daily_date_sector ON sector_fund_flow_daily(trade_date, sector_id);
CREATE INDEX idx_daily_sector_date ON sector_fund_flow_daily(sector_id, trade_date);
CREATE INDEX idx_daily_date_rank_amount ON sector_fund_flow_daily(trade_date, rank_by_amount);
CREATE INDEX idx_daily_date_inflow ON sector_fund_flow_daily(trade_date, main_net_inflow_1d DESC);

-- 复合索引优化
CREATE INDEX idx_daily_complex ON sector_fund_flow_daily(
    trade_date, 
    main_net_inflow_1d DESC, 
    rank_by_amount
) WHERE main_net_inflow_1d IS NOT NULL;

-- 分时数据索引
CREATE INDEX idx_intraday_lookup ON sector_fund_flow_intraday(
    sector_id, 
    trade_date, 
    trade_time
);
```

#### 3.2 查询模式优化
**常用查询模式：**

**1. 按日期范围查询排行榜**
```sql
-- 优化前：全表扫描
SELECT * FROM sector_fund_flow_daily 
WHERE trade_date BETWEEN '2023-01-01' AND '2023-12-31'
ORDER BY main_net_inflow_1d DESC;

-- 优化后：利用分区和索引
SELECT * FROM sector_fund_flow_daily 
WHERE trade_date >= '2023-01-01' AND trade_date <= '2023-12-31'
  AND main_net_inflow_1d IS NOT NULL
ORDER BY main_net_inflow_1d DESC
LIMIT 50;
```

**2. 单板块历史趋势查询**
```sql
-- 时间序列查询优化
SELECT trade_date, main_net_inflow_1d, rank_by_amount
FROM sector_fund_flow_daily 
WHERE sector_id = 'BK0001' 
  AND trade_date >= CURRENT_DATE - INTERVAL '90 days'
ORDER BY trade_date;
```

**3. 统计聚合查询**
```sql
-- 预计算统计结果
SELECT 
    DATE_TRUNC('week', trade_date) as week_start,
    AVG(main_net_inflow_1d) as avg_inflow,
    SUM(total_turnover) as total_turnover
FROM sector_fund_flow_daily 
WHERE sector_id = 'BK0001'
  AND trade_date >= CURRENT_DATE - INTERVAL '1 year'
GROUP BY DATE_TRUNC('week', trade_date)
ORDER BY week_start;
```

### 4. 数据维护策略

#### 4.1 数据生命周期管理
**自动化维护流程：**

**每日维护任务：**
- 数据质量检查和修复
- 增量数据同步和验证
- 实时数据到历史数据的ETL
- 缓存预热和索引优化

**每周维护任务：**
- 统计信息更新
- 分区维护和优化
- 数据压缩和清理
- 性能指标分析

**每月维护任务：**
- 历史数据归档
- 冷数据迁移
- 索引重建
- 备份和恢复测试

#### 4.2 数据质量保障
**多层数据验证：**

**实时验证：**
- 数据格式检查
- 数值范围验证
- 逻辑一致性检查
- 重复数据检测

**批量验证：**
- 跨源数据一致性验证
- 历史数据完整性检查
- 统计指标合理性验证
- 异常数据标记和处理

### 5. TET框架集成方案

#### 5.1 StandardQuery扩展
**历史数据查询标准化：**
```python
# 历史数据查询示例
historical_query = StandardQuery(
    asset_type=AssetType.SECTOR,
    data_type=DataType.SECTOR_FUND_FLOW_HISTORICAL,
    symbol="",  # 空表示所有板块
    extra_params={
        "start_date": "2023-01-01",
        "end_date": "2023-12-31",
        "time_period": "1d",  # 1d/3d/5d/10d/20d
        "sort_by": "main_net_inflow_1d",
        "sort_order": "desc",
        "limit": 100,
        "include_stats": True,
        "data_source": "database_first"  # 优先使用数据库
    }
)
```

#### 5.2 数据库路由策略
**智能数据源选择：**
```python
数据库路由决策逻辑：
if 查询时间范围 <= 3天:
    路由到 → Redis缓存 → DuckDB热数据
elif 查询时间范围 <= 2年:
    路由到 → DuckDB温数据 → 网络数据源补充
else:
    路由到 → SQLite冷数据 → 外部历史数据源
```

### 6. API接口设计

#### 6.1 历史数据查询API
**RESTful接口规范：**

**获取板块历史排行**
```http
GET /api/sector/fund-flow/ranking
Parameters:
- start_date: 开始日期
- end_date: 结束日期  
- time_period: 时间周期(1d/3d/5d/10d/20d)
- limit: 返回数量限制
- sort_by: 排序字段
- format: 返回格式(json/csv/excel)

Response:
{
    "success": true,
    "data": [
        {
            "trade_date": "2023-12-01",
            "sector_id": "BK0001",
            "sector_name": "房地产",
            "main_net_inflow_1d": 125000.50,
            "rank_by_amount": 1,
            "data_source": "database"
        }
    ],
    "meta": {
        "total_count": 1000,
        "query_time_ms": 45,
        "data_source": "DuckDB",
        "cache_hit": true
    }
}
```

**获取单板块历史趋势**
```http
GET /api/sector/fund-flow/trend/{sector_id}
Parameters:
- start_date: 开始日期
- end_date: 结束日期
- aggregation: 聚合方式(daily/weekly/monthly)
- indicators: 指标列表

Response:
{
    "success": true,
    "data": {
        "sector_info": {
            "sector_id": "BK0001",
            "sector_name": "房地产"
        },
        "time_series": [
            {
                "date": "2023-12-01",
                "main_net_inflow_1d": 125000.50,
                "rank_by_amount": 1,
                "avg_change_pct": 2.34
            }
        ]
    }
}
```

#### 6.2 数据管理API
**数据导入导出接口：**

**批量数据导入**
```http
POST /api/sector/fund-flow/import
Content-Type: application/json

{
    "data_source": "akshare",
    "start_date": "2023-01-01",
    "end_date": "2023-12-31",
    "overwrite": false,
    "validation": true
}
```

**数据导出**
```http
GET /api/sector/fund-flow/export
Parameters:
- start_date: 开始日期
- end_date: 结束日期
- format: 导出格式(csv/excel/json)
- sectors: 板块列表(可选)
```

### 7. 性能优化措施

#### 7.1 查询性能优化
**缓存策略：**
- **查询结果缓存**：常用查询结果Redis缓存30分钟
- **计算结果缓存**：复杂聚合计算结果缓存1小时
- **元数据缓存**：表结构和索引信息缓存24小时

**分页优化：**
- **游标分页**：大数据量查询使用游标分页
- **预计算分页**：热门查询预计算分页结果
- **虚拟分页**：前端虚拟滚动，减少数据传输

#### 7.2 写入性能优化
**批量写入：**
- **批量大小优化**：每批1000-5000条记录
- **事务控制**：合理控制事务大小，避免长事务
- **并行写入**：不同板块数据并行写入
- **延迟写入**：非关键数据异步延迟写入

### 8. 监控与告警

#### 8.1 数据库监控指标
**性能监控：**
- 查询响应时间分布
- 数据库连接池使用率
- 磁盘I/O性能指标
- 内存使用率和缓存命中率

**数据质量监控：**
- 数据完整性检查结果
- 数据更新延迟监控
- 异常数据数量统计
- 数据源一致性检查

#### 8.2 自动化告警
**告警规则：**
- 查询响应时间 > 5秒
- 数据更新延迟 > 30分钟
- 数据库连接失败率 > 5%
- 磁盘空间使用率 > 85%
- 数据质量评分 < 0.8

### 9. 备份与恢复

#### 9.1 备份策略
**分层备份：**
- **实时备份**：Redis数据实时同步备份
- **增量备份**：DuckDB每日增量备份
- **全量备份**：每周全量备份到云存储
- **归档备份**：月度数据归档备份

#### 9.2 灾难恢复
**恢复流程：**
1. **故障检测**：自动检测数据库故障
2. **服务切换**：自动切换到备用数据库
3. **数据恢复**：从备份恢复最新数据
4. **一致性验证**：验证恢复数据的一致性
5. **服务恢复**：恢复正常服务

## 📊 实施效果预期

### 查询性能提升
- **热数据查询**：响应时间 < 100ms
- **温数据查询**：响应时间 < 2秒
- **冷数据查询**：响应时间 < 10秒
- **复杂聚合查询**：响应时间 < 5秒

### 存储效率优化
- **数据压缩比**：历史数据压缩率 > 70%
- **存储成本**：相比全内存存储降低 > 80%
- **查询命中率**：缓存命中率 > 90%

### 运维便利性
- **自动化程度**：日常维护自动化率 > 95%
- **故障恢复**：平均故障恢复时间 < 5分钟
- **扩容能力**：支持数据量增长10倍无性能下降

## 🎯 总结

这个历史数据库存储方案通过分层存储、智能缓存、查询优化等技术手段，实现了：

- **🚀 高性能**：多级缓存确保查询响应速度
- **📊 大容量**：支持海量历史数据存储
- **🔧 易维护**：自动化维护和监控
- **💰 低成本**：分层存储优化成本
- **🛡️ 高可靠**：完整的备份恢复机制

该方案完全融入现有TET框架，为板块资金流功能提供了强大的历史数据支撑能力。
